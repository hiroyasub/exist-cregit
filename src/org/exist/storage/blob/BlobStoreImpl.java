begin_unit|revision:1.0.0;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Copyright (C) 2018 Adam Retter  *  * This program is free software; you can redistribute it and/or  * modify it under the terms of the GNU Lesser General Public License  * as published by the Free Software Foundation; either version 2  * of the License, or (at your option) any later version.  *  * This program is distributed in the hope that it will be useful,  * but WITHOUT ANY WARRANTY; without even the implied warranty of  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the  * GNU Lesser General Public License for more details.  *  * You should have received a copy of the GNU Lesser General Public  * License along with this library; if not, write to the Free Software  * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA  */
end_comment

begin_package
package|package
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|blob
package|;
end_package

begin_import
import|import
name|com
operator|.
name|evolvedbinary
operator|.
name|j8fu
operator|.
name|Try
import|;
end_import

begin_import
import|import
name|com
operator|.
name|evolvedbinary
operator|.
name|j8fu
operator|.
name|tuple
operator|.
name|Tuple2
import|;
end_import

begin_import
import|import
name|com
operator|.
name|evolvedbinary
operator|.
name|j8fu
operator|.
name|tuple
operator|.
name|Tuple3
import|;
end_import

begin_import
import|import
name|net
operator|.
name|jcip
operator|.
name|annotations
operator|.
name|ThreadSafe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|io
operator|.
name|input
operator|.
name|CountingInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|logging
operator|.
name|log4j
operator|.
name|LogManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|logging
operator|.
name|log4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|Database
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|backup
operator|.
name|RawDataBackup
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|txn
operator|.
name|Txn
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|FileUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|crypto
operator|.
name|digest
operator|.
name|DigestInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|crypto
operator|.
name|digest
operator|.
name|DigestType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|crypto
operator|.
name|digest
operator|.
name|MessageDigest
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|crypto
operator|.
name|digest
operator|.
name|StreamableDigest
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FilterInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|ByteBuffer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|channels
operator|.
name|SeekableByteChannel
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|Files
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|UUID
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|*
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicReference
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|function
operator|.
name|Function
import|;
end_import

begin_import
import|import static
name|com
operator|.
name|evolvedbinary
operator|.
name|j8fu
operator|.
name|Try
operator|.
name|TaggedTryUnchecked
import|;
end_import

begin_import
import|import static
name|com
operator|.
name|evolvedbinary
operator|.
name|j8fu
operator|.
name|tuple
operator|.
name|Tuple
operator|.
name|Tuple
import|;
end_import

begin_import
import|import static
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|StandardCopyOption
operator|.
name|ATOMIC_MOVE
import|;
end_import

begin_import
import|import static
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|StandardCopyOption
operator|.
name|REPLACE_EXISTING
import|;
end_import

begin_import
import|import static
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|StandardOpenOption
operator|.
name|*
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|blob
operator|.
name|BlobStoreImpl
operator|.
name|BlobReference
operator|.
name|*
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|FileUtils
operator|.
name|fileName
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|HexEncoder
operator|.
name|bytesToHex
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|ThreadUtils
operator|.
name|nameInstanceThread
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|ThreadUtils
operator|.
name|newInstanceSubThreadGroup
import|;
end_import

begin_comment
comment|/**  * De-duplicating store for BLOBs (Binary Large Objects).  *  * Each unique BLOB is stored by checksum into a blob file on disk.  *  * For each BLOB a reference count and the number of active readers is maintained.  * Adding a BLOB which is already present increments the reference count only,  * it does not require any additional storage.  *  * Removing a BLOB decrements its reference count, BLOBs are only removed when  * their reference count reaches zero, the blob file itself is scheduled for deletion  * and will only be removed when there are no active readers and its reference is zero.  *  * The Blob Store is backed to disk by a persistent store file which  * reflects the in-memory state of BlobStore.  *  * The persistent store file will grow for each unqiue blob added to  * the system, space is not reclaimed in the persistent file until  * {@link #compactPersistentReferences(ByteBuffer, Path)} is called,  * which typically only happens the next time the blob store is re-opened.  *  * Each unique blob typically takes up only 36 bytes in the  * persistent store file, but this can vary if a smaller or larger  * digestType is specified.  *  * On-line compaction of the persistent file could be added in  * future with relative ease if deemed necessary.  *  * The persistent file for the blob store has the format:  *  * [fileHeader entry+]  *  * fileHeader:          [magicNumber blobStoreVersion].  * magicNumber:         4 bytes. See {@link #BLOB_STORE_MAGIC_NUMBER}.  * blobStoreVersion:    2 bytes. java.lang.short, see {@link #BLOB_STORE_VERSION}.  *  * entry:               [blobChecksum blobReferenceCount]  * blobChecksum:        n-bytes determined by the constructed {@link MessageDigest}.  * blobReferenceCount:  4 bytes. java.lang.int.  *  * Note the persistent file may contain more than one entry  * for the same blobChecksum, however all entries previous to  * the last entry will have a blobReferenceCount of zero. The last  * entry will have the current blobReferenceCount which may be  * zero or more.  *     The use of {@code orphanedBlobFileIds} in the  * {@link #compactPersistentReferences(ByteBuffer, Path)} method  * makes sure to only delete blob files which have a final  * blobReferenceCount of zero.  *  * @author Adam Retter<adam@evolvedbinary.com>  */
end_comment

begin_class
annotation|@
name|ThreadSafe
specifier|public
class|class
name|BlobStoreImpl
implements|implements
name|BlobStore
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LogManager
operator|.
name|getLogger
argument_list|(
name|BlobStoreImpl
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/**      * Length in bytes of the reference count.      */
specifier|static
specifier|final
name|int
name|REFERENCE_COUNT_LEN
init|=
literal|4
decl_stmt|;
comment|/**      * File header length      */
specifier|static
specifier|final
name|int
name|BLOB_STORE_HEADER_LEN
init|=
literal|6
decl_stmt|;
comment|/**      * File header - magic number      */
specifier|private
specifier|static
specifier|final
name|byte
index|[]
name|BLOB_STORE_MAGIC_NUMBER
init|=
block|{
literal|0x0E
block|,
literal|0x0D
block|,
literal|0x0B
block|,
literal|0x02
block|}
decl_stmt|;
comment|/**      * File header - blob store version      */
specifier|public
specifier|static
specifier|final
name|short
name|BLOB_STORE_VERSION
init|=
literal|1
decl_stmt|;
comment|/**      * In-memory representation of the Blob Store.      */
specifier|private
name|ConcurrentMap
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|>
name|references
decl_stmt|;
comment|/**      * Queue for communicating between the thread calling      * the BlobStore and the {@link #persistentWriter} thread.      *      * Holds blob references which need to be updated in the      * blob stores persistent dbx file ({@link #persistentFile})      * on disk.      */
specifier|private
specifier|final
name|BlockingQueue
argument_list|<
name|Tuple3
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|,
name|Integer
argument_list|>
argument_list|>
name|persistQueue
init|=
operator|new
name|LinkedBlockingQueue
argument_list|<>
argument_list|()
decl_stmt|;
comment|/**      * Queue for communicating between the thread calling      * the BlobStore and the {@link #blobVacuum} thread.      *      * Head of the queue is the blob with the least active readers.      *      * Holds blob references which are scheduled to have their blob file      * removed from the blob file store.      */
specifier|private
specifier|final
name|PriorityBlockingQueue
argument_list|<
name|Tuple2
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|>
argument_list|>
name|vacuumQueue
init|=
operator|new
name|PriorityBlockingQueue
argument_list|<>
argument_list|(
literal|11
argument_list|,
parameter_list|(
name|br1
parameter_list|,
name|br2
parameter_list|)
lambda|->
name|br2
operator|.
name|_2
operator|.
name|readers
operator|.
name|get
argument_list|()
operator|-
name|br1
operator|.
name|_2
operator|.
name|readers
operator|.
name|get
argument_list|()
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|Database
name|database
decl_stmt|;
specifier|private
specifier|final
name|Path
name|persistentFile
decl_stmt|;
specifier|private
specifier|final
name|Path
name|blobDir
decl_stmt|;
specifier|private
specifier|final
name|Path
name|stagingDir
decl_stmt|;
specifier|private
specifier|final
name|DigestType
name|digestType
decl_stmt|;
comment|/**      * Enumeration of possible      * Blob Store states.      */
specifier|private
enum|enum
name|State
block|{
name|CLOSED
block|,
name|CLOSING
block|,
name|OPEN
block|,
name|OPENING
block|}
comment|/**      * State of the Blob Store      */
specifier|private
specifier|final
name|AtomicReference
argument_list|<
name|State
argument_list|>
name|state
init|=
operator|new
name|AtomicReference
argument_list|<>
argument_list|(
name|State
operator|.
name|CLOSED
argument_list|)
decl_stmt|;
comment|/**      * Thread which updates the persistent blob      * store file on disk.      */
specifier|private
name|PersistentWriter
name|persistentWriter
decl_stmt|;
specifier|private
name|Thread
name|persistentWriterThread
decl_stmt|;
comment|/**      * Thread which deletes de-referenced      * blob files when there are no      * more readers.      */
specifier|private
name|BlobVacuum
name|blobVacuum
decl_stmt|;
specifier|private
name|Thread
name|blobVacuumThread
decl_stmt|;
comment|/**      * @param database the database that this BlobStore is operating within      * @param persistentFile the file path for the persistent blob store metadata.      * @param blobDir the directory to store BLOBs in.      * @param digestType the message digest type to use for creating checksums of the BLOBs.      */
specifier|public
name|BlobStoreImpl
parameter_list|(
specifier|final
name|Database
name|database
parameter_list|,
specifier|final
name|Path
name|persistentFile
parameter_list|,
specifier|final
name|Path
name|blobDir
parameter_list|,
specifier|final
name|DigestType
name|digestType
parameter_list|)
block|{
name|this
operator|.
name|database
operator|=
name|database
expr_stmt|;
name|this
operator|.
name|persistentFile
operator|=
name|persistentFile
expr_stmt|;
name|this
operator|.
name|blobDir
operator|=
name|blobDir
expr_stmt|;
name|this
operator|.
name|stagingDir
operator|=
name|blobDir
operator|.
name|resolve
argument_list|(
literal|"staging"
argument_list|)
expr_stmt|;
name|this
operator|.
name|digestType
operator|=
name|digestType
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|open
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|state
operator|.
name|get
argument_list|()
operator|==
name|State
operator|.
name|OPEN
condition|)
block|{
return|return;
block|}
if|if
condition|(
operator|!
name|state
operator|.
name|compareAndSet
argument_list|(
name|State
operator|.
name|CLOSED
argument_list|,
name|State
operator|.
name|OPENING
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"BlobStore is not open"
argument_list|)
throw|;
block|}
comment|// size the buffer to hold a complete entry
specifier|final
name|ByteBuffer
name|buffer
init|=
name|ByteBuffer
operator|.
name|allocate
argument_list|(
name|digestType
operator|.
name|getDigestLengthBytes
argument_list|()
operator|+
name|REFERENCE_COUNT_LEN
argument_list|)
decl_stmt|;
name|SeekableByteChannel
name|channel
init|=
literal|null
decl_stmt|;
try|try
block|{
comment|// open the dbx file
if|if
condition|(
name|Files
operator|.
name|exists
argument_list|(
name|persistentFile
argument_list|)
condition|)
block|{
comment|// compact existing blob store file and then open
name|this
operator|.
name|references
operator|=
name|compactPersistentReferences
argument_list|(
name|buffer
argument_list|,
name|persistentFile
argument_list|)
expr_stmt|;
name|channel
operator|=
name|Files
operator|.
name|newByteChannel
argument_list|(
name|persistentFile
argument_list|,
name|WRITE
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// open existing blob store file
name|this
operator|.
name|references
operator|=
operator|new
name|ConcurrentHashMap
argument_list|<>
argument_list|()
expr_stmt|;
name|channel
operator|=
name|Files
operator|.
name|newByteChannel
argument_list|(
name|persistentFile
argument_list|,
name|CREATE_NEW
argument_list|,
name|WRITE
argument_list|)
expr_stmt|;
name|writeFileHeader
argument_list|(
name|buffer
argument_list|,
name|channel
argument_list|)
expr_stmt|;
block|}
comment|// create the staging directory if it does not exist
name|Files
operator|.
name|createDirectories
argument_list|(
name|stagingDir
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
specifier|final
name|IOException
name|e
parameter_list|)
block|{
if|if
condition|(
name|channel
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|channel
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
specifier|final
name|IOException
name|ce
parameter_list|)
block|{
comment|// ignore
block|}
block|}
name|state
operator|.
name|set
argument_list|(
name|State
operator|.
name|CLOSED
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
comment|// thread group for the blob store
specifier|final
name|ThreadGroup
name|blobStoreThreadGroup
init|=
name|newInstanceSubThreadGroup
argument_list|(
name|database
argument_list|,
literal|"blob-store"
argument_list|)
decl_stmt|;
comment|// startup the persistent writer thread
name|this
operator|.
name|persistentWriter
operator|=
operator|new
name|PersistentWriter
argument_list|(
name|persistQueue
argument_list|,
name|buffer
argument_list|,
name|channel
argument_list|,
name|this
operator|::
name|abnormalPersistentWriterShutdown
argument_list|)
expr_stmt|;
name|this
operator|.
name|persistentWriterThread
operator|=
operator|new
name|Thread
argument_list|(
name|blobStoreThreadGroup
argument_list|,
name|persistentWriter
argument_list|,
name|nameInstanceThread
argument_list|(
name|database
argument_list|,
literal|"blob-store.persistent-writer"
argument_list|)
argument_list|)
expr_stmt|;
name|persistentWriterThread
operator|.
name|start
argument_list|()
expr_stmt|;
comment|// startup the blob vacuum thread
name|this
operator|.
name|blobVacuum
operator|=
operator|new
name|BlobVacuum
argument_list|()
expr_stmt|;
name|this
operator|.
name|blobVacuumThread
operator|=
operator|new
name|Thread
argument_list|(
name|blobStoreThreadGroup
argument_list|,
name|blobVacuum
argument_list|,
name|nameInstanceThread
argument_list|(
name|database
argument_list|,
literal|"blob-store.vacuum"
argument_list|)
argument_list|)
expr_stmt|;
name|blobVacuumThread
operator|.
name|start
argument_list|()
expr_stmt|;
comment|// we are now open!
name|state
operator|.
name|set
argument_list|(
name|State
operator|.
name|OPEN
argument_list|)
expr_stmt|;
block|}
comment|/**      * Compacts an existing Blob Store file.      *      * Reads the existing Blob Store file and copies non zero reference      * entries to a new Blob Store file. We call this compaction.      * Once complete, the existing file is replaced with the new file.      *      * @param persistentFile an existing persistentFile to compact.      *      * @return An in-memory representation of the compacted Blob Store      *      * @throws IOException if an error occurs during compaction.      */
specifier|private
name|ConcurrentMap
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|>
name|compactPersistentReferences
parameter_list|(
specifier|final
name|ByteBuffer
name|buffer
parameter_list|,
specifier|final
name|Path
name|persistentFile
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|ConcurrentMap
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|>
name|compactReferences
init|=
operator|new
name|ConcurrentHashMap
argument_list|<>
argument_list|()
decl_stmt|;
specifier|final
name|Path
name|compactPersistentFile
init|=
name|persistentFile
operator|.
name|getParent
argument_list|()
operator|.
name|resolve
argument_list|(
name|persistentFile
operator|.
name|getFileName
argument_list|()
operator|+
literal|".new."
operator|+
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
decl_stmt|;
comment|// tracks the BlobIds of Blob Files which have been orphaned
specifier|final
name|Set
argument_list|<
name|BlobId
argument_list|>
name|orphanedBlobFileIds
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
try|try
init|(
specifier|final
name|SeekableByteChannel
name|channel
init|=
name|Files
operator|.
name|newByteChannel
argument_list|(
name|persistentFile
argument_list|,
name|READ
argument_list|)
init|)
block|{
name|validateFileHeader
argument_list|(
name|buffer
argument_list|,
name|persistentFile
argument_list|,
name|channel
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|clear
argument_list|()
expr_stmt|;
try|try
init|(
specifier|final
name|SeekableByteChannel
name|compactChannel
init|=
name|Files
operator|.
name|newByteChannel
argument_list|(
name|compactPersistentFile
argument_list|,
name|CREATE_NEW
argument_list|,
name|APPEND
argument_list|)
init|)
block|{
name|writeFileHeader
argument_list|(
name|buffer
argument_list|,
name|compactChannel
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|clear
argument_list|()
expr_stmt|;
while|while
condition|(
name|channel
operator|.
name|read
argument_list|(
name|buffer
argument_list|)
operator|>
operator|-
literal|1
condition|)
block|{
specifier|final
name|byte
index|[]
name|id
init|=
operator|new
name|byte
index|[
name|digestType
operator|.
name|getDigestLengthBytes
argument_list|()
index|]
decl_stmt|;
name|buffer
operator|.
name|flip
argument_list|()
expr_stmt|;
name|buffer
operator|.
name|get
argument_list|(
name|id
argument_list|)
expr_stmt|;
specifier|final
name|BlobId
name|blobId
init|=
operator|new
name|BlobId
argument_list|(
name|id
argument_list|)
decl_stmt|;
specifier|final
name|int
name|count
init|=
name|buffer
operator|.
name|getInt
argument_list|()
decl_stmt|;
if|if
condition|(
name|count
operator|==
literal|0
condition|)
block|{
name|orphanedBlobFileIds
operator|.
name|add
argument_list|(
name|blobId
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|orphanedBlobFileIds
operator|.
name|remove
argument_list|(
name|blobId
argument_list|)
expr_stmt|;
name|compactReferences
operator|.
name|put
argument_list|(
name|blobId
argument_list|,
operator|new
name|BlobReference
argument_list|(
name|count
argument_list|,
name|compactChannel
operator|.
name|position
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|flip
argument_list|()
expr_stmt|;
name|compactChannel
operator|.
name|write
argument_list|(
name|buffer
argument_list|)
expr_stmt|;
block|}
name|buffer
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|// cleanup any orphaned Blob files
for|for
control|(
specifier|final
name|BlobId
name|orphanedBlobFileId
range|:
name|orphanedBlobFileIds
control|)
block|{
name|deleteBlob
argument_list|(
name|orphanedBlobFileId
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|// replace the persistent file with the new compact persistent file
name|Files
operator|.
name|move
argument_list|(
name|compactPersistentFile
argument_list|,
name|persistentFile
argument_list|,
name|ATOMIC_MOVE
argument_list|,
name|REPLACE_EXISTING
argument_list|)
expr_stmt|;
return|return
name|compactReferences
return|;
block|}
comment|/**      * Writes the persistent file header      *      * @param buffer a byte buffer to use      * @param channel the channel to write to      * @return the number of bytes written.      * @throws IOException if an error occurs whilst writing the header.      */
specifier|private
name|long
name|writeFileHeader
parameter_list|(
specifier|final
name|ByteBuffer
name|buffer
parameter_list|,
specifier|final
name|SeekableByteChannel
name|channel
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|long
name|start
init|=
name|channel
operator|.
name|position
argument_list|()
decl_stmt|;
name|buffer
operator|.
name|clear
argument_list|()
expr_stmt|;
name|writeFileHeader
argument_list|(
name|buffer
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|flip
argument_list|()
expr_stmt|;
name|buffer
operator|.
name|limit
argument_list|(
name|BLOB_STORE_HEADER_LEN
argument_list|)
expr_stmt|;
name|channel
operator|.
name|write
argument_list|(
name|buffer
argument_list|)
expr_stmt|;
return|return
name|channel
operator|.
name|position
argument_list|()
operator|-
name|start
return|;
block|}
comment|/**      * Writes the persistent file header      *      * @param buffer the buffer to write to      */
specifier|private
specifier|static
name|void
name|writeFileHeader
parameter_list|(
specifier|final
name|ByteBuffer
name|buffer
parameter_list|)
block|{
name|buffer
operator|.
name|put
argument_list|(
name|BLOB_STORE_MAGIC_NUMBER
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|putShort
argument_list|(
name|BLOB_STORE_VERSION
argument_list|)
expr_stmt|;
block|}
comment|/**      * Validates a file header.      *      * @param buffer a byte buffer to use      * @param file the file containing the header.      * @param channel the channel of the file to read from.      *      * @throws IOException if the header is invalid.      */
specifier|private
name|void
name|validateFileHeader
parameter_list|(
specifier|final
name|ByteBuffer
name|buffer
parameter_list|,
specifier|final
name|Path
name|file
parameter_list|,
specifier|final
name|SeekableByteChannel
name|channel
parameter_list|)
throws|throws
name|IOException
block|{
name|buffer
operator|.
name|clear
argument_list|()
expr_stmt|;
name|buffer
operator|.
name|limit
argument_list|(
name|BLOB_STORE_HEADER_LEN
argument_list|)
expr_stmt|;
name|channel
operator|.
name|read
argument_list|(
name|buffer
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|flip
argument_list|()
expr_stmt|;
specifier|final
name|boolean
name|validMagic
init|=
name|buffer
operator|.
name|get
argument_list|()
operator|==
name|BLOB_STORE_MAGIC_NUMBER
index|[
literal|0
index|]
operator|&&
name|buffer
operator|.
name|get
argument_list|()
operator|==
name|BLOB_STORE_MAGIC_NUMBER
index|[
literal|1
index|]
operator|&&
name|buffer
operator|.
name|get
argument_list|()
operator|==
name|BLOB_STORE_MAGIC_NUMBER
index|[
literal|2
index|]
operator|&&
name|buffer
operator|.
name|get
argument_list|()
operator|==
name|BLOB_STORE_MAGIC_NUMBER
index|[
literal|3
index|]
decl_stmt|;
if|if
condition|(
operator|!
name|validMagic
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"File was not recognised as a valid eXist-db Blob Store: "
operator|+
name|file
operator|.
name|toAbsolutePath
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
comment|// check the version of the blob store format
specifier|final
name|short
name|storedVersion
init|=
name|buffer
operator|.
name|getShort
argument_list|()
decl_stmt|;
specifier|final
name|boolean
name|validVersion
init|=
name|storedVersion
operator|==
name|BLOB_STORE_VERSION
decl_stmt|;
if|if
condition|(
operator|!
name|validVersion
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Blob Store file was version "
operator|+
name|storedVersion
operator|+
literal|", but required version "
operator|+
name|BLOB_STORE_VERSION
operator|+
literal|": "
operator|+
name|file
operator|.
name|toAbsolutePath
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|Tuple2
argument_list|<
name|BlobId
argument_list|,
name|Long
argument_list|>
name|add
parameter_list|(
specifier|final
name|Txn
name|transaction
parameter_list|,
specifier|final
name|InputStream
name|is
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|state
operator|.
name|get
argument_list|()
operator|!=
name|State
operator|.
name|OPEN
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Blob Store is not open!"
argument_list|)
throw|;
block|}
specifier|final
name|Tuple3
argument_list|<
name|Path
argument_list|,
name|Long
argument_list|,
name|MessageDigest
argument_list|>
name|staged
init|=
name|stage
argument_list|(
name|is
argument_list|)
decl_stmt|;
specifier|final
name|BlobId
name|blobId
init|=
operator|new
name|BlobId
argument_list|(
name|staged
operator|.
name|_3
operator|.
name|getValue
argument_list|()
argument_list|)
decl_stmt|;
comment|// if the blob entry does not exist, we exclusively compute it as STAGED.
name|BlobReference
name|blobReference
init|=
name|references
operator|.
name|computeIfAbsent
argument_list|(
name|blobId
argument_list|,
name|k
lambda|->
operator|new
name|BlobReference
argument_list|(
name|STAGED
argument_list|)
argument_list|)
decl_stmt|;
try|try
block|{
while|while
condition|(
literal|true
condition|)
block|{
if|if
condition|(
name|blobReference
operator|.
name|count
operator|.
name|compareAndSet
argument_list|(
name|STAGED
argument_list|,
name|PROMOTING
argument_list|)
condition|)
block|{
comment|// we are the only thread that can be in this branch for the blobId
name|promote
argument_list|(
name|staged
argument_list|)
expr_stmt|;
comment|// schedule disk persist of the new value
name|persistQueue
operator|.
name|put
argument_list|(
name|Tuple
argument_list|(
name|blobId
argument_list|,
name|blobReference
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
comment|// update memory with the new value
name|blobReference
operator|.
name|count
operator|.
name|set
argument_list|(
literal|1
argument_list|)
expr_stmt|;
comment|// done!
return|return
name|Tuple
argument_list|(
name|blobId
argument_list|,
name|staged
operator|.
name|_2
argument_list|)
return|;
block|}
specifier|final
name|int
name|count
init|=
name|blobReference
operator|.
name|count
operator|.
name|get
argument_list|()
decl_stmt|;
comment|// guard against a concurrent #add or #remove
if|if
condition|(
name|count
operator|==
name|PROMOTING
operator|||
name|count
operator|==
name|UPDATING_COUNT
condition|)
block|{
comment|// spin whilst another thread promotes the blob, or updates the reference count
comment|// sleep a small time to save CPU
name|Thread
operator|.
name|sleep
argument_list|(
literal|10
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|// guard against a concurrent vacuum operation
comment|// ...retry the blob reference until the vacuum has completed!
comment|// i.e. wait for the deletion of the blob to complete, and then we can add the blob again
if|if
condition|(
name|count
operator|==
name|DELETING
condition|)
block|{
name|blobReference
operator|=
name|references
operator|.
name|computeIfAbsent
argument_list|(
name|blobId
argument_list|,
name|k
lambda|->
operator|new
name|BlobReference
argument_list|(
name|STAGED
argument_list|)
argument_list|)
expr_stmt|;
continue|continue;
comment|// loop again
block|}
comment|// only increment the blob reference if the blob is active!
if|if
condition|(
name|count
operator|>=
literal|0
operator|&&
name|blobReference
operator|.
name|count
operator|.
name|compareAndSet
argument_list|(
name|count
argument_list|,
name|UPDATING_COUNT
argument_list|)
condition|)
block|{
comment|// we are the only thread that can be in this branch for the blobId
specifier|final
name|int
name|newCount
init|=
name|count
operator|+
literal|1
decl_stmt|;
comment|// persist the new value
name|persistQueue
operator|.
name|put
argument_list|(
name|Tuple
argument_list|(
name|blobId
argument_list|,
name|blobReference
argument_list|,
name|newCount
argument_list|)
argument_list|)
expr_stmt|;
comment|// update memory with the new value, and release other spinning threads
name|blobReference
operator|.
name|count
operator|.
name|set
argument_list|(
name|newCount
argument_list|)
expr_stmt|;
comment|// done!
return|return
name|Tuple
argument_list|(
name|blobId
argument_list|,
name|staged
operator|.
name|_2
argument_list|)
return|;
block|}
block|}
block|}
catch|catch
parameter_list|(
specifier|final
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// thrown by persistQueue.put or Thread.sleep
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
annotation|@
name|Nullable
specifier|public
name|InputStream
name|get
parameter_list|(
specifier|final
name|Txn
name|transaction
parameter_list|,
specifier|final
name|BlobId
name|blobId
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|BlobFileLease
name|blobFileLease
init|=
name|readLeaseBlobFile
argument_list|(
name|transaction
argument_list|,
name|blobId
argument_list|)
decl_stmt|;
if|if
condition|(
name|blobFileLease
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// blob file lease is released either when the input stream is closed, or if an error occurs opening the stream
try|try
block|{
return|return
operator|new
name|OnCloseInputStream
argument_list|(
name|Files
operator|.
name|newInputStream
argument_list|(
name|blobFileLease
operator|.
name|path
argument_list|)
argument_list|,
name|blobFileLease
operator|.
name|release
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
specifier|final
name|IOException
name|e
parameter_list|)
block|{
name|blobFileLease
operator|.
name|release
operator|.
name|run
argument_list|()
expr_stmt|;
comment|// MUST release the read lease!
throw|throw
name|e
throw|;
block|}
block|}
annotation|@
name|Override
annotation|@
name|Nullable
specifier|public
name|MessageDigest
name|getDigest
parameter_list|(
specifier|final
name|Txn
name|transaction
parameter_list|,
specifier|final
name|BlobId
name|blobId
parameter_list|,
specifier|final
name|DigestType
name|digestType
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|digestType
operator|.
name|equals
argument_list|(
name|digestType
argument_list|)
condition|)
block|{
comment|// optimisation, we can just return the BlobId as that is the digest for this digest type!
return|return
operator|new
name|MessageDigest
argument_list|(
name|digestType
argument_list|,
name|blobId
operator|.
name|getId
argument_list|()
argument_list|)
return|;
block|}
else|else
block|{
comment|// calculate the digest
specifier|final
name|StreamableDigest
name|streamableDigest
init|=
name|digestType
operator|.
name|newStreamableDigest
argument_list|()
decl_stmt|;
specifier|final
name|Try
argument_list|<
name|MessageDigest
argument_list|,
name|IOException
argument_list|>
name|result
init|=
name|with
argument_list|(
name|transaction
argument_list|,
name|blobId
argument_list|,
name|maybeBlobFile
lambda|->
name|maybeBlobFile
operator|==
literal|null
condition|?
literal|null
else|:
name|TaggedTryUnchecked
argument_list|(
name|IOException
operator|.
name|class
argument_list|,
parameter_list|()
lambda|->
block|{
name|FileUtils
operator|.
name|digest
argument_list|(
name|maybeBlobFile
argument_list|,
name|streamableDigest
argument_list|)
argument_list|;
return|return
operator|new
name|MessageDigest
argument_list|(
name|streamableDigest
operator|.
name|getDigestType
argument_list|()
argument_list|,
name|streamableDigest
operator|.
name|getMessageDigest
argument_list|()
argument_list|)
return|;
block|}
block_content|)
block|)
class|;
end_class

begin_return
return|return
name|result
operator|.
name|get
argument_list|()
return|;
end_return

begin_function
unit|}     }
annotation|@
name|Override
specifier|public
parameter_list|<
name|T
parameter_list|>
name|T
name|with
parameter_list|(
specifier|final
name|Txn
name|transaction
parameter_list|,
specifier|final
name|BlobId
name|blobId
parameter_list|,
specifier|final
name|Function
argument_list|<
name|Path
argument_list|,
name|T
argument_list|>
name|fnFile
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|BlobFileLease
name|blobFileLease
init|=
name|readLeaseBlobFile
argument_list|(
name|transaction
argument_list|,
name|blobId
argument_list|)
decl_stmt|;
try|try
block|{
return|return
name|fnFile
operator|.
name|apply
argument_list|(
name|blobFileLease
operator|.
name|path
argument_list|)
return|;
block|}
finally|finally
block|{
name|blobFileLease
operator|.
name|release
operator|.
name|run
argument_list|()
expr_stmt|;
comment|// MUST release the read lease!
block|}
block|}
end_function

begin_comment
comment|/**      * Lease a Blob file for reading from the Blob Store.      *      * @param transaction the current database transaction.      * @param blobId the identifier of the blob to lease the blob file from.      *      * @return the blob file lease, or null if the blob does not exist in the Blob Store      *      * @throws IOException if an error occurs whilst retrieving the BLOB file.      */
end_comment

begin_function
specifier|private
name|BlobFileLease
name|readLeaseBlobFile
parameter_list|(
specifier|final
name|Txn
name|transaction
parameter_list|,
specifier|final
name|BlobId
name|blobId
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|state
operator|.
name|get
argument_list|()
operator|!=
name|State
operator|.
name|OPEN
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Blob Store is not open!"
argument_list|)
throw|;
block|}
specifier|final
name|BlobReference
name|blobReference
init|=
name|references
operator|.
name|get
argument_list|(
name|blobId
argument_list|)
decl_stmt|;
if|if
condition|(
name|blobReference
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
try|try
block|{
while|while
condition|(
literal|true
condition|)
block|{
specifier|final
name|int
name|count
init|=
name|blobReference
operator|.
name|count
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|count
operator|==
literal|0
condition|)
block|{
comment|// can't return something with has zero references
return|return
literal|null
return|;
block|}
comment|// guard against a concurrent vacuum operation
if|if
condition|(
name|count
operator|==
name|DELETING
condition|)
block|{
comment|// can't return something with has zero references (because it is being deleted)
return|return
literal|null
return|;
block|}
comment|// guard against a concurrent #add doing staging
if|if
condition|(
name|count
operator|==
name|STAGED
operator|||
name|count
operator|==
name|PROMOTING
condition|)
block|{
comment|// spin whilst another thread promotes the blob
comment|// sleep a small time to save CPU
name|Thread
operator|.
name|sleep
argument_list|(
literal|10
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|// read a blob which has references
if|if
condition|(
name|count
operator|>
literal|0
condition|)
block|{
comment|// we are reading
name|blobReference
operator|.
name|readers
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
comment|// get the blob
specifier|final
name|Path
name|blobFile
init|=
name|blobDir
operator|.
name|resolve
argument_list|(
name|bytesToHex
argument_list|(
name|blobId
operator|.
name|getId
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
return|return
operator|new
name|BlobFileLease
argument_list|(
name|blobFile
argument_list|,
parameter_list|()
lambda|->
name|blobReference
operator|.
name|readers
operator|.
name|decrementAndGet
argument_list|()
argument_list|)
return|;
block|}
block|}
block|}
catch|catch
parameter_list|(
specifier|final
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// only thrown by Thread.sleep above
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|remove
parameter_list|(
specifier|final
name|Txn
name|transaction
parameter_list|,
specifier|final
name|BlobId
name|blobId
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|state
operator|.
name|get
argument_list|()
operator|!=
name|State
operator|.
name|OPEN
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Blob Store is not open!"
argument_list|)
throw|;
block|}
specifier|final
name|BlobReference
name|blobReference
init|=
name|references
operator|.
name|get
argument_list|(
name|blobId
argument_list|)
decl_stmt|;
if|if
condition|(
name|blobReference
operator|==
literal|null
condition|)
block|{
return|return;
block|}
try|try
block|{
while|while
condition|(
literal|true
condition|)
block|{
specifier|final
name|int
name|count
init|=
name|blobReference
operator|.
name|count
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|count
operator|==
literal|0
condition|)
block|{
comment|// can't remove something which has zero references
return|return;
block|}
comment|// guard against a concurrent vacuum operation
if|if
condition|(
name|count
operator|==
name|DELETING
condition|)
block|{
comment|// can't remove something which has zero references (because it is being deleted)
return|return;
block|}
comment|// guard against a concurrent #add or #remove
if|if
condition|(
name|count
operator|==
name|STAGED
operator|||
name|count
operator|==
name|PROMOTING
operator|||
name|count
operator|==
name|UPDATING_COUNT
condition|)
block|{
comment|// spin whilst another thread promotes the blob or updates the reference count
comment|// sleep a small time to save CPU
name|Thread
operator|.
name|sleep
argument_list|(
literal|10
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|// only decrement the blob reference if the blob has more than zero references
if|if
condition|(
name|count
operator|>
literal|0
operator|&&
name|blobReference
operator|.
name|count
operator|.
name|compareAndSet
argument_list|(
name|count
argument_list|,
name|UPDATING_COUNT
argument_list|)
condition|)
block|{
comment|// we are the only thread that can be in this branch for the blobId
specifier|final
name|int
name|newCount
init|=
name|count
operator|-
literal|1
decl_stmt|;
comment|// persist the new value
name|persistQueue
operator|.
name|put
argument_list|(
name|Tuple
argument_list|(
name|blobId
argument_list|,
name|blobReference
argument_list|,
name|newCount
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|newCount
operator|==
literal|0
condition|)
block|{
comment|// schedule blob file for vacuum.
name|vacuumQueue
operator|.
name|put
argument_list|(
name|Tuple
argument_list|(
name|blobId
argument_list|,
name|blobReference
argument_list|)
argument_list|)
expr_stmt|;
block|}
comment|// update memory with the new value, and release other spinning threads
name|blobReference
operator|.
name|count
operator|.
name|set
argument_list|(
name|newCount
argument_list|)
expr_stmt|;
comment|// done!
return|return;
block|}
block|}
block|}
catch|catch
parameter_list|(
specifier|final
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// thrown by persistQueue.put or Thread.sleep
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|backupToArchive
parameter_list|(
specifier|final
name|RawDataBackup
name|backup
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|state
operator|.
name|get
argument_list|()
operator|!=
name|State
operator|.
name|OPEN
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Blob Store is not open!"
argument_list|)
throw|;
block|}
comment|// TODO(AR) should we enter an exclusive backup state?
comment|// NOTE: do not use try-with-resources here, closing the OutputStream will close the entire backup
comment|// backup the blob.dbx
try|try
block|{
specifier|final
name|OutputStream
name|os
init|=
name|backup
operator|.
name|newEntry
argument_list|(
name|fileName
argument_list|(
name|persistentFile
argument_list|)
argument_list|)
decl_stmt|;
name|Files
operator|.
name|copy
argument_list|(
name|persistentFile
argument_list|,
name|os
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|backup
operator|.
name|closeEntry
argument_list|()
expr_stmt|;
block|}
comment|// backup the blob files
for|for
control|(
specifier|final
name|Path
name|blobFile
range|:
name|FileUtils
operator|.
name|list
argument_list|(
name|blobDir
argument_list|,
name|Files
operator|::
name|isRegularFile
argument_list|)
control|)
block|{
try|try
block|{
specifier|final
name|OutputStream
name|os
init|=
name|backup
operator|.
name|newEntry
argument_list|(
name|fileName
argument_list|(
name|blobDir
argument_list|)
operator|+
literal|'/'
operator|+
name|fileName
argument_list|(
name|blobFile
argument_list|)
argument_list|)
decl_stmt|;
name|Files
operator|.
name|copy
argument_list|(
name|persistentFile
argument_list|,
name|os
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|backup
operator|.
name|closeEntry
argument_list|()
expr_stmt|;
block|}
block|}
comment|// backup the staging area
for|for
control|(
specifier|final
name|Path
name|blobFile
range|:
name|FileUtils
operator|.
name|list
argument_list|(
name|stagingDir
argument_list|,
name|Files
operator|::
name|isRegularFile
argument_list|)
control|)
block|{
try|try
block|{
specifier|final
name|OutputStream
name|os
init|=
name|backup
operator|.
name|newEntry
argument_list|(
name|fileName
argument_list|(
name|blobDir
argument_list|)
operator|+
literal|'/'
operator|+
name|fileName
argument_list|(
name|stagingDir
argument_list|)
operator|+
literal|'/'
operator|+
name|fileName
argument_list|(
name|blobFile
argument_list|)
argument_list|)
decl_stmt|;
name|Files
operator|.
name|copy
argument_list|(
name|persistentFile
argument_list|,
name|os
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|backup
operator|.
name|closeEntry
argument_list|()
expr_stmt|;
block|}
block|}
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
comment|// check the blob store is open
if|if
condition|(
name|state
operator|.
name|get
argument_list|()
operator|==
name|State
operator|.
name|CLOSED
condition|)
block|{
return|return;
block|}
if|if
condition|(
operator|!
name|state
operator|.
name|compareAndSet
argument_list|(
name|State
operator|.
name|OPEN
argument_list|,
name|State
operator|.
name|CLOSING
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"BlobStore is not open"
argument_list|)
throw|;
block|}
try|try
block|{
comment|// shutdown the persistent writer
if|if
condition|(
name|persistentWriter
operator|!=
literal|null
condition|)
block|{
name|persistQueue
operator|.
name|put
argument_list|(
name|PersistentWriter
operator|.
name|POISON_PILL
argument_list|)
expr_stmt|;
block|}
name|persistentWriterThread
operator|.
name|join
argument_list|()
expr_stmt|;
comment|// shutdown the vacuum
if|if
condition|(
name|blobVacuum
operator|!=
literal|null
condition|)
block|{
name|blobVacuumThread
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
name|blobVacuumThread
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
specifier|final
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// Restore the interrupted status
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
finally|finally
block|{
comment|// we are now closed!
name|state
operator|.
name|set
argument_list|(
name|State
operator|.
name|CLOSED
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/**      * Closes the BlobStore if the {@link #persistentWriter} has      * to shutdown due to abnormal circumstances.      */
end_comment

begin_function
specifier|private
name|void
name|abnormalPersistentWriterShutdown
parameter_list|()
block|{
comment|// check the blob store is open
if|if
condition|(
name|state
operator|.
name|get
argument_list|()
operator|==
name|State
operator|.
name|CLOSED
condition|)
block|{
return|return;
block|}
if|if
condition|(
operator|!
name|state
operator|.
name|compareAndSet
argument_list|(
name|State
operator|.
name|OPEN
argument_list|,
name|State
operator|.
name|CLOSING
argument_list|)
condition|)
block|{
return|return;
block|}
try|try
block|{
comment|// NOTE: persistent writer thread will join when this method finished!
comment|// shutdown the vacuum
if|if
condition|(
name|blobVacuum
operator|!=
literal|null
condition|)
block|{
name|blobVacuumThread
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
name|blobVacuumThread
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
specifier|final
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// Restore the interrupted status
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
comment|// we are now closed!
name|state
operator|.
name|set
argument_list|(
name|State
operator|.
name|CLOSED
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/**      * Stages a BLOB file.      *      * Writes a BLOB to a file in the Blob Store staging area.      *      * @param is data stream for the BLOB.      * @return The file path, length and checksum of the staged BLOB      * @throws IOException if an error occurs whilst staging the BLOB.      */
end_comment

begin_function
specifier|private
name|Tuple3
argument_list|<
name|Path
argument_list|,
name|Long
argument_list|,
name|MessageDigest
argument_list|>
name|stage
parameter_list|(
specifier|final
name|InputStream
name|is
parameter_list|)
throws|throws
name|IOException
block|{
comment|// TODO(AR) upgrade to com.fasterxml.uuid.java-uuid-generator
specifier|final
name|Path
name|stageFile
init|=
name|stagingDir
operator|.
name|resolve
argument_list|(
name|UUID
operator|.
name|randomUUID
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|CountingInputStream
name|cis
init|=
operator|new
name|CountingInputStream
argument_list|(
name|is
argument_list|)
decl_stmt|;
specifier|final
name|StreamableDigest
name|streamableDigest
init|=
name|digestType
operator|.
name|newStreamableDigest
argument_list|()
decl_stmt|;
specifier|final
name|DigestInputStream
name|dis
init|=
operator|new
name|DigestInputStream
argument_list|(
name|cis
argument_list|,
name|streamableDigest
argument_list|)
decl_stmt|;
name|Files
operator|.
name|copy
argument_list|(
name|dis
argument_list|,
name|stageFile
argument_list|)
expr_stmt|;
return|return
name|Tuple
argument_list|(
name|stageFile
argument_list|,
name|cis
operator|.
name|getByteCount
argument_list|()
argument_list|,
name|streamableDigest
operator|.
name|copyMessageDigest
argument_list|()
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**      * Promotes a staged BLOB file to the BLOB store.      *      * Moves a staged BLOB file in the Blob Store staging area to      * the live Blob Store.      *      * @param staged the staged BLOB.      * @throws IOException if an error occurs whilst promoting the BLOB.      */
end_comment

begin_function
specifier|private
name|void
name|promote
parameter_list|(
specifier|final
name|Tuple3
argument_list|<
name|Path
argument_list|,
name|Long
argument_list|,
name|MessageDigest
argument_list|>
name|staged
parameter_list|)
throws|throws
name|IOException
block|{
name|Files
operator|.
name|move
argument_list|(
name|staged
operator|.
name|_1
argument_list|,
name|blobDir
operator|.
name|resolve
argument_list|(
name|staged
operator|.
name|_3
operator|.
name|toHexString
argument_list|()
argument_list|)
argument_list|,
name|ATOMIC_MOVE
argument_list|,
name|REPLACE_EXISTING
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**      * Deletes a BLOB file from the Blob Store.      *      * @param blobId the identifier of the BLOB file to delete.      * @param always true if we should always be able to delete the file,      *     false if the file may not exist.      *      * @throws IOException if the file cannot be deleted, for example if {@code always}      *                     is set to true and the BLOB does not exist.      */
end_comment

begin_function
specifier|private
name|void
name|deleteBlob
parameter_list|(
specifier|final
name|BlobId
name|blobId
parameter_list|,
specifier|final
name|boolean
name|always
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|Path
name|blobFile
init|=
name|blobDir
operator|.
name|resolve
argument_list|(
name|bytesToHex
argument_list|(
name|blobId
operator|.
name|getId
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|always
condition|)
block|{
name|Files
operator|.
name|delete
argument_list|(
name|blobFile
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Files
operator|.
name|deleteIfExists
argument_list|(
name|blobFile
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/**      * Value class which represents the reference      * count for a blob, the number of active readers,      * and the offset of its entry in the persistent file.      */
end_comment

begin_class
specifier|static
class|class
name|BlobReference
block|{
specifier|static
specifier|final
name|int
name|DELETING
init|=
operator|-
literal|4
decl_stmt|;
specifier|static
specifier|final
name|int
name|STAGED
init|=
operator|-
literal|3
decl_stmt|;
specifier|static
specifier|final
name|int
name|PROMOTING
init|=
operator|-
literal|2
decl_stmt|;
specifier|static
specifier|final
name|int
name|UPDATING_COUNT
init|=
operator|-
literal|1
decl_stmt|;
specifier|final
name|AtomicInteger
name|count
decl_stmt|;
specifier|final
name|AtomicInteger
name|readers
init|=
operator|new
name|AtomicInteger
argument_list|()
decl_stmt|;
specifier|static
specifier|final
name|long
name|NOT_PERSISTED
init|=
operator|-
literal|1
decl_stmt|;
comment|/**          * Is only read and written from a single          * thread in {@link PersistentWriter}          * so no synchronization needed.          */
name|long
name|persistentOffset
init|=
name|NOT_PERSISTED
decl_stmt|;
comment|/**          * Construct a new Blob Reference which has not yet          * been persisted.          *          * @param count the reference count          *          * The persistentOffset will be set to {@link #NOT_PERSISTED}          */
specifier|public
name|BlobReference
parameter_list|(
specifier|final
name|int
name|count
parameter_list|)
block|{
name|this
operator|.
name|count
operator|=
operator|new
name|AtomicInteger
argument_list|(
name|count
argument_list|)
expr_stmt|;
block|}
comment|/**          * Construct a new Blob Reference to a persistent          * blob.          *          * @param count the reference count          * @param persistentOffset the offset of the blob reference in the persistent file          */
specifier|public
name|BlobReference
parameter_list|(
specifier|final
name|int
name|count
parameter_list|,
specifier|final
name|long
name|persistentOffset
parameter_list|)
block|{
name|this
operator|.
name|count
operator|=
operator|new
name|AtomicInteger
argument_list|(
name|count
argument_list|)
expr_stmt|;
name|this
operator|.
name|persistentOffset
operator|=
name|persistentOffset
expr_stmt|;
block|}
block|}
end_class

begin_comment
comment|/**      * Value class which represents a lease      * of a Blob's file.      */
end_comment

begin_class
specifier|private
specifier|static
class|class
name|BlobFileLease
block|{
specifier|final
name|Path
name|path
decl_stmt|;
specifier|final
name|Runnable
name|release
decl_stmt|;
comment|/**          * @param path the blob file          * @param release the action to run to release the lease          */
specifier|public
name|BlobFileLease
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|,
specifier|final
name|Runnable
name|release
parameter_list|)
block|{
name|this
operator|.
name|path
operator|=
name|path
expr_stmt|;
name|this
operator|.
name|release
operator|=
name|release
expr_stmt|;
block|}
block|}
end_class

begin_comment
comment|/**      * A FilterInputStream which executes an action when      * the underlying stream is closed.      */
end_comment

begin_class
specifier|public
specifier|static
class|class
name|OnCloseInputStream
extends|extends
name|FilterInputStream
block|{
specifier|private
specifier|final
name|Runnable
name|closeAction
decl_stmt|;
comment|/**          * Ensures that the close action is only executed once.          */
specifier|private
specifier|final
name|AtomicBoolean
name|closed
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
comment|/**          * @param in  An input stream.          * @param closeAction an action to run after the stream is closed.          */
specifier|public
name|OnCloseInputStream
parameter_list|(
specifier|final
name|InputStream
name|in
parameter_list|,
specifier|final
name|Runnable
name|closeAction
parameter_list|)
block|{
name|super
argument_list|(
name|in
argument_list|)
expr_stmt|;
name|this
operator|.
name|closeAction
operator|=
name|closeAction
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|read
parameter_list|(
specifier|final
name|byte
index|[]
name|b
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|in
operator|.
name|read
argument_list|(
name|b
argument_list|)
return|;
block|}
comment|/**          * First, closes the underlying Input Stream          * by calling {@link super#close()} and then          * always executes the {@link #closeAction}.          *          * This method is idempotent, which is to say that          * the operation will only be          * applied once.          *          * @exception IOException if an I/O error occurs.          */
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|closed
operator|.
name|compareAndSet
argument_list|(
literal|false
argument_list|,
literal|true
argument_list|)
condition|)
block|{
try|try
block|{
name|super
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|closeAction
operator|.
name|run
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
end_class

begin_comment
comment|/**      * The PersistentWriter is designed to be run      * exclusively on its own single thread for a BlobStore      * and is solely responsible for writing updates to the      * persistent blob store file.      */
end_comment

begin_class
specifier|private
specifier|static
class|class
name|PersistentWriter
implements|implements
name|Runnable
block|{
comment|/**          * The Poison Pill can be placed on the {@link #persistQueue},          * when encountered the {@link PersistentWriter} will          * shutdown.          */
specifier|public
specifier|static
specifier|final
name|Tuple3
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|,
name|Integer
argument_list|>
name|POISON_PILL
init|=
name|Tuple
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|BlockingQueue
argument_list|<
name|Tuple3
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|,
name|Integer
argument_list|>
argument_list|>
name|persistQueue
decl_stmt|;
specifier|private
specifier|final
name|ByteBuffer
name|buffer
decl_stmt|;
specifier|private
specifier|final
name|SeekableByteChannel
name|channel
decl_stmt|;
specifier|private
specifier|final
name|Runnable
name|abnormalShutdownCallback
decl_stmt|;
name|PersistentWriter
parameter_list|(
specifier|final
name|BlockingQueue
argument_list|<
name|Tuple3
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|,
name|Integer
argument_list|>
argument_list|>
name|persistQueue
parameter_list|,
specifier|final
name|ByteBuffer
name|buffer
parameter_list|,
specifier|final
name|SeekableByteChannel
name|channel
parameter_list|,
specifier|final
name|Runnable
name|abnormalShutdownCallback
parameter_list|)
block|{
name|this
operator|.
name|persistQueue
operator|=
name|persistQueue
expr_stmt|;
name|this
operator|.
name|buffer
operator|=
name|buffer
expr_stmt|;
name|this
operator|.
name|channel
operator|=
name|channel
expr_stmt|;
name|this
operator|.
name|abnormalShutdownCallback
operator|=
name|abnormalShutdownCallback
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
while|while
condition|(
literal|true
condition|)
block|{
specifier|final
name|Tuple3
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|,
name|Integer
argument_list|>
name|blobData
init|=
name|persistQueue
operator|.
name|take
argument_list|()
decl_stmt|;
if|if
condition|(
name|blobData
operator|==
name|POISON_PILL
condition|)
block|{
comment|// if we received the Poison Pill, we should shutdown!
name|shutdown
argument_list|()
expr_stmt|;
break|break;
comment|// exit
block|}
comment|// write an entry
name|writeEntry
argument_list|(
name|blobData
operator|.
name|_1
argument_list|,
name|blobData
operator|.
name|_2
argument_list|,
name|blobData
operator|.
name|_3
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
specifier|final
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// Restore the interrupted status
name|LOG
operator|.
name|error
argument_list|(
literal|"PersistentWriter Shutting down due to interrupt: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
name|shutdown
argument_list|()
expr_stmt|;
name|abnormalShutdownCallback
operator|.
name|run
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
specifier|final
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"PersistentWriter Shutting down, received: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|shutdown
argument_list|()
expr_stmt|;
name|abnormalShutdownCallback
operator|.
name|run
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**          * Stores the reference count for a blob to the persistent blob store file.          *          * When a new reference count is written for the first time it updates          * the {@link BlobStoreImpl.BlobReference#persistentOffset} with the          * location of the reference in the persistent file.          *          * @param blobId the identifier of the blob.          * @param blobReference the reference details for the blob          * @param newCount the new reference count to store.          *          * @throws IOException if an error occurs whilst writing the persistent file.          */
specifier|private
name|void
name|writeEntry
parameter_list|(
specifier|final
name|BlobId
name|blobId
parameter_list|,
specifier|final
name|BlobReference
name|blobReference
parameter_list|,
specifier|final
name|int
name|newCount
parameter_list|)
throws|throws
name|IOException
block|{
comment|// if new record (i.e. not yet persisted), append to the end of the file
if|if
condition|(
name|blobReference
operator|.
name|persistentOffset
operator|==
name|NOT_PERSISTED
condition|)
block|{
name|blobReference
operator|.
name|persistentOffset
operator|=
name|channel
operator|.
name|size
argument_list|()
expr_stmt|;
block|}
name|channel
operator|.
name|position
argument_list|(
name|blobReference
operator|.
name|persistentOffset
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|clear
argument_list|()
expr_stmt|;
name|buffer
operator|.
name|put
argument_list|(
name|blobId
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|putInt
argument_list|(
name|newCount
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|flip
argument_list|()
expr_stmt|;
name|channel
operator|.
name|write
argument_list|(
name|buffer
argument_list|)
expr_stmt|;
block|}
comment|/**          * Cleans up the resources associated          * with the persistent writer.          *          * Closes the {@link #channel}.          */
specifier|private
name|void
name|shutdown
parameter_list|()
block|{
name|buffer
operator|.
name|clear
argument_list|()
expr_stmt|;
comment|// close the file channel
if|if
condition|(
name|channel
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|channel
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
specifier|final
name|IOException
name|e
parameter_list|)
block|{
comment|// non-critical error
name|LOG
operator|.
name|error
argument_list|(
literal|"Error whilst closing blob.dbx: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
end_class

begin_comment
comment|/**      * The BlobVacuum is designed to be run      * exclusively on its own single thread for a BlobStore      * and is solely responsible for deleting blob files from      * the blob file store.      */
end_comment

begin_class
specifier|private
class|class
name|BlobVacuum
implements|implements
name|Runnable
block|{
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
while|while
condition|(
literal|true
condition|)
block|{
name|Tuple2
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|>
name|blobData
init|=
name|vacuumQueue
operator|.
name|take
argument_list|()
decl_stmt|;
specifier|final
name|BlobId
name|blobId
init|=
name|blobData
operator|.
name|_1
decl_stmt|;
specifier|final
name|BlobReference
name|blobReference
init|=
name|blobData
operator|.
name|_2
decl_stmt|;
comment|// we can only delete if there are no references
if|if
condition|(
name|blobReference
operator|.
name|count
operator|.
name|compareAndSet
argument_list|(
literal|0
argument_list|,
name|DELETING
argument_list|)
condition|)
block|{
comment|// make sure there are no readers still actively reading
if|if
condition|(
name|blobReference
operator|.
name|readers
operator|.
name|get
argument_list|()
operator|==
literal|0
condition|)
block|{
comment|// no more readers can be taken whilst count == DELETING, so we can delete
try|try
block|{
name|deleteBlob
argument_list|(
name|blobId
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
specifier|final
name|IOException
name|ioe
parameter_list|)
block|{
comment|// non-critical error
name|LOG
operator|.
name|error
argument_list|(
literal|"Unable to delete blob file: "
operator|+
name|bytesToHex
argument_list|(
name|blobId
operator|.
name|getId
argument_list|()
argument_list|)
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
comment|// remove from shared map
name|references
operator|.
name|remove
argument_list|(
name|blobId
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// reschedule the blob vacuum for later (when hopefully there are no active readers)
name|vacuumQueue
operator|.
name|put
argument_list|(
name|blobData
argument_list|)
expr_stmt|;
block|}
comment|// NOTE: DELETING is the last state of a BlobReference#count -- there is no future change from this!
block|}
comment|//else {
comment|// ignore this blob and continue as there are now again active references, so we don't need to dalete
comment|//}
block|}
block|}
catch|catch
parameter_list|(
specifier|final
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// expected when we are shutting down, only thrown by vacuumQueue.take.
comment|// Any remaining objects in the queue which we have not yet vacuumed will
comment|// be taken care of by {@link #compactPersistentReferences(ByteBuffer, Path)
comment|// when the persistent blob store file is next opened
comment|// Restore the interrupted status
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
block|}
end_class

unit|}
end_unit

