begin_unit|revision:1.0.0;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  *  eXist Open Source Native XML Database  *  Copyright (C) 2001-04 Wolfgang M. Meier  *  wolfgang@exist-db.org  *  http://exist-db.org  *  *  This program is free software; you can redistribute it and/or  *  modify it under the terms of the GNU Lesser General Public License  *  as published by the Free Software Foundation; either version 2  *  of the License, or (at your option) any later version.  *  *  This program is distributed in the hope that it will be useful,  *  but WITHOUT ANY WARRANTY; without even the implied warranty of  *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the  *  GNU Lesser General Public License for more details.  *  *  You should have received a copy of the GNU Lesser General Public License  *  along with this program; if not, write to the Free Software  *  Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.  *   *  $Id$  */
end_comment

begin_package
package|package
name|org
operator|.
name|exist
operator|.
name|storage
package|;
end_package

begin_comment
comment|//import java.io.EOFException;
end_comment

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|UnsupportedEncodingException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeSet
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|EXistException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|numbering
operator|.
name|NodeId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|collections
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|dom
operator|.
name|AttrImpl
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|dom
operator|.
name|DocumentImpl
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|dom
operator|.
name|DocumentSet
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|dom
operator|.
name|ElementImpl
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|dom
operator|.
name|ExtArrayNodeSet
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|dom
operator|.
name|Match
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|dom
operator|.
name|NodeProxy
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|dom
operator|.
name|NodeSet
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|dom
operator|.
name|NodeSetHelper
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|dom
operator|.
name|StoredNode
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|dom
operator|.
name|TextImpl
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|dom
operator|.
name|VirtualNodeSet
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|security
operator|.
name|PermissionDeniedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|analysis
operator|.
name|TextToken
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|btree
operator|.
name|BTreeCallback
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|btree
operator|.
name|BTreeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|btree
operator|.
name|DBException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|btree
operator|.
name|IndexQuery
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|btree
operator|.
name|Value
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|index
operator|.
name|BFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|io
operator|.
name|VariableByteArrayInput
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|io
operator|.
name|VariableByteInput
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|io
operator|.
name|VariableByteOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|lock
operator|.
name|Lock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|ByteArray
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|ByteConversion
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|LockException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|Occurrences
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|ProgressIndicator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|ReadOnlyException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|UTF8
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|XMLString
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|xquery
operator|.
name|Constants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|xquery
operator|.
name|TerminatedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|xquery
operator|.
name|XQueryContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|w3c
operator|.
name|dom
operator|.
name|Node
import|;
end_import

begin_import
import|import
name|org
operator|.
name|w3c
operator|.
name|dom
operator|.
name|NodeList
import|;
end_import

begin_comment
comment|/**  * This class is responsible for fulltext-indexing. Text-nodes are handed over  * to this class to be fulltext-indexed. Method storeText() is called by  * RelationalBroker whenever it finds a TextNode. Method getNodeIDsContaining()  * is used by the XPath-engine to process queries where a fulltext-operator is  * involved. The class keeps two database tables: table<code>dbTokens</code> stores the words  * found with their unique id. Table<code>invertedIndex</code> contains the word occurrences for  * every word-id per document.  *   * TODO: store node type (attribute or text) with each entry  *   * @author Wolfgang Meier  */
end_comment

begin_class
specifier|public
class|class
name|NativeTextEngine
extends|extends
name|TextSearchEngine
implements|implements
name|ContentLoadingObserver
block|{
specifier|public
specifier|final
specifier|static
name|byte
name|TEXT_SECTION
init|=
literal|0
decl_stmt|;
specifier|public
specifier|final
specifier|static
name|byte
name|ATTRIBUTE_SECTION
init|=
literal|1
decl_stmt|;
comment|/** Length limit for the tokens */
specifier|public
specifier|final
specifier|static
name|int
name|MAX_TOKEN_LENGTH
init|=
literal|2048
decl_stmt|;
comment|/** The datastore for this token index */
specifier|protected
name|BFile
name|dbTokens
decl_stmt|;
specifier|protected
name|InvertedIndex
name|invertedIndex
decl_stmt|;
comment|/** Work output Stream that should be cleared before every use */
specifier|private
name|VariableByteOutputStream
name|os
init|=
operator|new
name|VariableByteOutputStream
argument_list|()
decl_stmt|;
specifier|public
name|NativeTextEngine
parameter_list|(
name|DBBroker
name|broker
parameter_list|,
name|Configuration
name|config
parameter_list|,
name|BFile
name|db
parameter_list|)
block|{
name|super
argument_list|(
name|broker
argument_list|,
name|config
argument_list|)
expr_stmt|;
name|this
operator|.
name|dbTokens
operator|=
name|db
expr_stmt|;
name|this
operator|.
name|invertedIndex
operator|=
operator|new
name|InvertedIndex
argument_list|()
expr_stmt|;
block|}
comment|/** 	 * Checks if the given string could be a regular expression. 	 *  	 * @param str The string 	 */
specifier|public
specifier|final
specifier|static
name|boolean
name|containsWildcards
parameter_list|(
name|String
name|str
parameter_list|)
block|{
if|if
condition|(
name|str
operator|==
literal|null
operator|||
name|str
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
return|return
literal|false
return|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|str
operator|.
name|length
argument_list|()
condition|;
name|i
operator|++
control|)
switch|switch
condition|(
name|str
operator|.
name|charAt
argument_list|(
name|i
argument_list|)
condition|)
block|{
case|case
literal|'*'
case|:
case|case
literal|'?'
case|:
case|case
literal|'\\'
case|:
case|case
literal|'['
case|:
case|case
literal|']'
case|:
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
specifier|public
specifier|final
specifier|static
name|boolean
name|startsWithWildcard
parameter_list|(
name|String
name|str
parameter_list|)
block|{
if|if
condition|(
name|str
operator|==
literal|null
operator|||
name|str
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
return|return
literal|false
return|;
switch|switch
condition|(
name|str
operator|.
name|charAt
argument_list|(
literal|0
argument_list|)
condition|)
block|{
case|case
literal|'*'
case|:
case|case
literal|'?'
case|:
case|case
literal|'\\'
case|:
case|case
literal|'['
case|:
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
specifier|public
name|int
name|getTrackMatches
parameter_list|()
block|{
return|return
name|trackMatches
return|;
block|}
specifier|public
name|void
name|setTrackMatches
parameter_list|(
name|int
name|flags
parameter_list|)
block|{
name|trackMatches
operator|=
name|flags
expr_stmt|;
block|}
specifier|public
name|void
name|setDocument
parameter_list|(
name|DocumentImpl
name|document
parameter_list|)
block|{
comment|//TODO Auto-generated method stub
block|}
comment|/**      * Indexes the tokens contained in an attribute.      *       * @param attr The attribute to be indexed      */
comment|//TODO : unify functionalities with storeText -pb
specifier|public
name|void
name|storeAttribute
parameter_list|(
name|FulltextIndexSpec
name|indexSpec
parameter_list|,
name|AttrImpl
name|attr
parameter_list|)
block|{
specifier|final
name|DocumentImpl
name|doc
init|=
operator|(
name|DocumentImpl
operator|)
name|attr
operator|.
name|getOwnerDocument
argument_list|()
decl_stmt|;
comment|//TODO : case conversion should be handled by the tokenizer -pb
name|tokenizer
operator|.
name|setText
argument_list|(
name|attr
operator|.
name|getValue
argument_list|()
operator|.
name|toLowerCase
argument_list|()
argument_list|)
expr_stmt|;
name|TextToken
name|token
decl_stmt|;
while|while
condition|(
literal|null
operator|!=
operator|(
name|token
operator|=
name|tokenizer
operator|.
name|nextToken
argument_list|()
operator|)
condition|)
block|{
if|if
condition|(
name|token
operator|.
name|length
argument_list|()
operator|>
name|MAX_TOKEN_LENGTH
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|stoplist
operator|.
name|contains
argument_list|(
name|token
argument_list|)
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|indexSpec
operator|!=
literal|null
condition|)
block|{
comment|//TODO : the tokenizer should strip unwanted token types itself -pb
if|if
condition|(
operator|!
name|indexSpec
operator|.
name|getIncludeAlphaNum
argument_list|()
operator|&&
operator|!
name|token
operator|.
name|isAlpha
argument_list|()
condition|)
block|{
continue|continue;
block|}
block|}
name|invertedIndex
operator|.
name|setDocument
argument_list|(
name|doc
argument_list|)
expr_stmt|;
name|invertedIndex
operator|.
name|addAttribute
argument_list|(
name|token
argument_list|,
name|attr
operator|.
name|getNodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Indexes the tokens contained in a text node.      *       * @param indexSpec The index configuration      * @param text The text node to be indexed      * @param noTokenizing      *                if<code>true</code>, given text is indexed as a single token      *                if<code>false</code>, it is tokenized before being indexed      */
comment|//TODO : use an indexSpec member in order to get rid of<code>noTokenizing</code>
specifier|public
name|void
name|storeText
parameter_list|(
name|FulltextIndexSpec
name|indexSpec
parameter_list|,
name|TextImpl
name|text
parameter_list|,
name|boolean
name|noTokenizing
parameter_list|)
block|{
specifier|final
name|DocumentImpl
name|doc
init|=
operator|(
name|DocumentImpl
operator|)
name|text
operator|.
name|getOwnerDocument
argument_list|()
decl_stmt|;
comment|//TODO : case conversion should be handled by the tokenizer -pb
specifier|final
name|XMLString
name|t
init|=
name|text
operator|.
name|getXMLString
argument_list|()
operator|.
name|transformToLower
argument_list|()
decl_stmt|;
name|TextToken
name|token
decl_stmt|;
if|if
condition|(
name|noTokenizing
condition|)
block|{
name|token
operator|=
operator|new
name|TextToken
argument_list|(
name|TextToken
operator|.
name|ALPHA
argument_list|,
name|t
argument_list|,
literal|0
argument_list|,
name|t
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
name|invertedIndex
operator|.
name|setDocument
argument_list|(
name|doc
argument_list|)
expr_stmt|;
name|invertedIndex
operator|.
name|addText
argument_list|(
name|t
argument_list|,
name|token
argument_list|,
name|text
operator|.
name|getNodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|tokenizer
operator|.
name|setText
argument_list|(
name|t
argument_list|)
expr_stmt|;
while|while
condition|(
literal|null
operator|!=
operator|(
name|token
operator|=
name|tokenizer
operator|.
name|nextToken
argument_list|()
operator|)
condition|)
block|{
if|if
condition|(
name|token
operator|.
name|length
argument_list|()
operator|>
name|MAX_TOKEN_LENGTH
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|stoplist
operator|.
name|contains
argument_list|(
name|token
argument_list|)
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|indexSpec
operator|!=
literal|null
condition|)
block|{
comment|//TODO : the tokenizer should strip unwanted token types itself -pb
if|if
condition|(
operator|!
name|indexSpec
operator|.
name|getIncludeAlphaNum
argument_list|()
operator|&&
operator|!
name|token
operator|.
name|isAlpha
argument_list|()
condition|)
block|{
continue|continue;
block|}
block|}
name|invertedIndex
operator|.
name|setDocument
argument_list|(
name|doc
argument_list|)
expr_stmt|;
name|invertedIndex
operator|.
name|addText
argument_list|(
name|t
argument_list|,
name|token
argument_list|,
name|text
operator|.
name|getNodeId
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|public
name|void
name|storeAttribute
parameter_list|(
name|RangeIndexSpec
name|spec
parameter_list|,
name|AttrImpl
name|node
parameter_list|)
block|{
comment|// TODO Auto-generated method stub
block|}
specifier|public
name|void
name|storeAttribute
parameter_list|(
name|AttrImpl
name|node
parameter_list|,
name|NodePath
name|currentPath
parameter_list|,
name|boolean
name|fullTextIndexSwitch
parameter_list|)
block|{
comment|//TODO Auto-generated method stub
block|}
specifier|public
name|void
name|storeText
parameter_list|(
name|TextImpl
name|node
parameter_list|,
name|NodePath
name|currentPath
parameter_list|,
name|boolean
name|fullTextIndexSwitch
parameter_list|)
block|{
comment|// TODO Auto-generated method stub
block|}
specifier|public
name|void
name|startElement
parameter_list|(
name|ElementImpl
name|impl
parameter_list|,
name|NodePath
name|currentPath
parameter_list|,
name|boolean
name|index
parameter_list|)
block|{
comment|// TODO Auto-generated method stub
block|}
specifier|public
name|void
name|endElement
parameter_list|(
name|int
name|xpathType
parameter_list|,
name|ElementImpl
name|node
parameter_list|,
name|String
name|content
parameter_list|)
block|{
comment|// TODO Auto-generated method stub
block|}
specifier|public
name|void
name|removeElement
parameter_list|(
name|ElementImpl
name|node
parameter_list|,
name|NodePath
name|currentPath
parameter_list|,
name|String
name|content
parameter_list|)
block|{
comment|// TODO Auto-generated method stub
block|}
comment|/* (non-Javadoc)      * @see org.exist.storage.ContentLoadingObserver#sync()      */
specifier|public
name|void
name|sync
parameter_list|()
block|{
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|(
name|Lock
operator|.
name|WRITE_LOCK
argument_list|)
expr_stmt|;
name|dbTokens
operator|.
name|flush
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|//TODO : throw an exception ? -pb
block|}
catch|catch
parameter_list|(
name|DBException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|//TODO : throw an exception ? -pb
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|()
expr_stmt|;
block|}
block|}
comment|/* (non-Javadoc)      * @see org.exist.storage.ContentLoadingObserver#flush()      */
specifier|public
name|void
name|flush
parameter_list|()
block|{
name|invertedIndex
operator|.
name|flush
argument_list|()
expr_stmt|;
block|}
specifier|public
name|void
name|reindex
parameter_list|(
name|DocumentImpl
name|document
parameter_list|,
name|StoredNode
name|node
parameter_list|)
block|{
name|invertedIndex
operator|.
name|reindex
argument_list|(
name|document
argument_list|,
name|node
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|remove
parameter_list|()
block|{
name|invertedIndex
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
comment|/* Drop all index entries for the given collection.      * @see org.exist.storage.ContentLoadingObserver#dropIndex(org.exist.collections.Collection)      */
specifier|public
name|void
name|dropIndex
parameter_list|(
name|Collection
name|collection
parameter_list|)
block|{
specifier|final
name|WordRef
name|value
init|=
operator|new
name|WordRef
argument_list|(
name|collection
operator|.
name|getId
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|IndexQuery
name|query
init|=
operator|new
name|IndexQuery
argument_list|(
name|IndexQuery
operator|.
name|TRUNC_RIGHT
argument_list|,
name|value
argument_list|)
decl_stmt|;
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|(
name|Lock
operator|.
name|WRITE_LOCK
argument_list|)
expr_stmt|;
name|dbTokens
operator|.
name|removeAll
argument_list|(
name|query
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|BTreeException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|(
name|Lock
operator|.
name|WRITE_LOCK
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* Drop all index entries for the given document.      * @see org.exist.storage.ContentLoadingObserver#dropIndex(org.exist.dom.DocumentImpl)      */
specifier|public
name|void
name|dropIndex
parameter_list|(
name|DocumentImpl
name|document
parameter_list|)
block|{
comment|//Collect document's tokens
specifier|final
name|TreeSet
name|tokens
init|=
operator|new
name|TreeSet
argument_list|()
decl_stmt|;
specifier|final
name|NodeList
name|children
init|=
name|document
operator|.
name|getChildNodes
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|children
operator|.
name|getLength
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
name|StoredNode
name|node
init|=
operator|(
name|StoredNode
operator|)
name|children
operator|.
name|item
argument_list|(
name|i
argument_list|)
decl_stmt|;
name|Iterator
name|j
init|=
name|broker
operator|.
name|getDOMIterator
argument_list|(
name|node
argument_list|)
decl_stmt|;
name|collect
argument_list|(
name|tokens
argument_list|,
name|j
argument_list|)
expr_stmt|;
block|}
specifier|final
name|short
name|collectionId
init|=
name|document
operator|.
name|getCollection
argument_list|()
operator|.
name|getId
argument_list|()
decl_stmt|;
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
for|for
control|(
name|Iterator
name|iter
init|=
name|tokens
operator|.
name|iterator
argument_list|()
init|;
name|iter
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
name|String
name|token
init|=
operator|(
name|String
operator|)
name|iter
operator|.
name|next
argument_list|()
decl_stmt|;
name|WordRef
name|key
init|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|,
name|token
argument_list|)
decl_stmt|;
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|(
name|Lock
operator|.
name|WRITE_LOCK
argument_list|)
expr_stmt|;
name|boolean
name|changed
init|=
literal|false
decl_stmt|;
name|os
operator|.
name|clear
argument_list|()
expr_stmt|;
name|VariableByteInput
name|is
init|=
name|dbTokens
operator|.
name|getAsStream
argument_list|(
name|key
argument_list|)
decl_stmt|;
comment|//Does the token already has data in the index ?
if|if
condition|(
name|is
operator|==
literal|null
condition|)
continue|continue;
comment|//try {
while|while
condition|(
name|is
operator|.
name|available
argument_list|()
operator|>
literal|0
condition|)
block|{
name|int
name|storedDocId
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
name|byte
name|section
init|=
name|is
operator|.
name|readByte
argument_list|()
decl_stmt|;
name|int
name|gidsCount
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
comment|//TOUNDERSTAND -pb
name|int
name|size
init|=
name|is
operator|.
name|readFixedInt
argument_list|()
decl_stmt|;
if|if
condition|(
name|storedDocId
operator|!=
name|document
operator|.
name|getDocId
argument_list|()
condition|)
block|{
comment|// data are related to another document:
comment|// copy them to any existing data
name|os
operator|.
name|writeInt
argument_list|(
name|storedDocId
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeByte
argument_list|(
name|section
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeInt
argument_list|(
name|gidsCount
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeFixedInt
argument_list|(
name|size
argument_list|)
expr_stmt|;
name|is
operator|.
name|copyRaw
argument_list|(
name|os
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// data are related to our document:
comment|// skip them
name|changed
operator|=
literal|true
expr_stmt|;
name|is
operator|.
name|skipBytes
argument_list|(
name|size
argument_list|)
expr_stmt|;
block|}
block|}
comment|//} catch (EOFException e) {
comment|//EOF is expected here
comment|//}
comment|//Store new data, if relevant
if|if
condition|(
name|changed
condition|)
block|{
comment|//Well, nothing to store : remove the existing data
if|if
condition|(
name|os
operator|.
name|data
argument_list|()
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
name|dbTokens
operator|.
name|remove
argument_list|(
name|key
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|dbTokens
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|os
operator|.
name|data
argument_list|()
argument_list|)
operator|==
name|BFile
operator|.
name|UNKNOWN_ADDRESS
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Could not put index data for token '"
operator|+
name|token
operator|+
literal|"' in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
operator|+
literal|" in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ReadOnlyException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
operator|+
literal|" in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|()
expr_stmt|;
block|}
block|}
block|}
specifier|public
name|NodeSet
name|getNodesContaining
parameter_list|(
name|XQueryContext
name|context
parameter_list|,
name|DocumentSet
name|docs
parameter_list|,
name|NodeSet
name|contextSet
parameter_list|,
name|String
name|expr
parameter_list|,
name|int
name|type
parameter_list|)
throws|throws
name|TerminatedException
block|{
if|if
condition|(
name|type
operator|==
name|DBBroker
operator|.
name|MATCH_EXACT
operator|&&
name|containsWildcards
argument_list|(
name|expr
argument_list|)
condition|)
block|{
comment|//TODO : log this fallback ? -pb
name|type
operator|=
name|DBBroker
operator|.
name|MATCH_WILDCARDS
expr_stmt|;
block|}
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|DBBroker
operator|.
name|MATCH_EXACT
case|:
return|return
name|getNodesExact
argument_list|(
name|context
argument_list|,
name|docs
argument_list|,
name|contextSet
argument_list|,
name|expr
argument_list|)
return|;
comment|//TODO : stricter control -pb
default|default :
return|return
name|getNodesRegexp
argument_list|(
name|context
argument_list|,
name|docs
argument_list|,
name|contextSet
argument_list|,
name|expr
argument_list|,
name|type
argument_list|)
return|;
block|}
block|}
comment|/** Get all nodes whose content exactly matches the give expression. 	 * @param context 	 * @param docs 	 * @param contextSet 	 * @param expr 	 * @return 	 * @throws TerminatedException 	 */
specifier|public
name|NodeSet
name|getNodesExact
parameter_list|(
name|XQueryContext
name|context
parameter_list|,
name|DocumentSet
name|docs
parameter_list|,
name|NodeSet
name|contextSet
parameter_list|,
name|String
name|expr
parameter_list|)
throws|throws
name|TerminatedException
block|{
comment|//Return early
if|if
condition|(
name|expr
operator|==
literal|null
condition|)
return|return
literal|null
return|;
comment|//TODO : filter the expression *before* -pb
if|if
condition|(
name|stoplist
operator|.
name|contains
argument_list|(
name|expr
argument_list|)
condition|)
return|return
literal|null
return|;
comment|//TODO : case conversion should be handled by the tokenizer -pb
name|expr
operator|=
name|expr
operator|.
name|toLowerCase
argument_list|()
expr_stmt|;
comment|//TODO : use an indexSpec member in order to get rid of this or do the job *before* -pb
name|String
name|token
decl_stmt|;
if|if
condition|(
name|stem
condition|)
name|token
operator|=
name|stemmer
operator|.
name|stem
argument_list|(
name|expr
argument_list|)
expr_stmt|;
else|else
name|token
operator|=
name|expr
expr_stmt|;
specifier|final
name|NodeSet
name|result
init|=
operator|new
name|ExtArrayNodeSet
argument_list|(
name|docs
operator|.
name|getLength
argument_list|()
argument_list|,
literal|250
argument_list|)
decl_stmt|;
for|for
control|(
name|Iterator
name|iter
init|=
name|docs
operator|.
name|getCollectionIterator
argument_list|()
init|;
name|iter
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
specifier|final
name|short
name|collectionId
init|=
operator|(
operator|(
name|Collection
operator|)
name|iter
operator|.
name|next
argument_list|()
operator|)
operator|.
name|getId
argument_list|()
decl_stmt|;
specifier|final
name|Value
name|key
init|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|,
name|token
argument_list|)
decl_stmt|;
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|()
expr_stmt|;
name|VariableByteInput
name|is
init|=
name|dbTokens
operator|.
name|getAsStream
argument_list|(
name|key
argument_list|)
decl_stmt|;
comment|//Does the token already has data in the index ?
if|if
condition|(
name|is
operator|==
literal|null
condition|)
continue|continue;
while|while
condition|(
name|is
operator|.
name|available
argument_list|()
operator|>
literal|0
condition|)
block|{
name|int
name|storedDocId
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
name|int
name|storedSection
init|=
name|is
operator|.
name|readByte
argument_list|()
decl_stmt|;
name|int
name|gidsCount
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
comment|//TOUNDERSTAND -pb
name|int
name|size
init|=
name|is
operator|.
name|readFixedInt
argument_list|()
decl_stmt|;
name|DocumentImpl
name|storedDocument
init|=
name|docs
operator|.
name|getDoc
argument_list|(
name|storedDocId
argument_list|)
decl_stmt|;
comment|//Exit if the document is not concerned
if|if
condition|(
name|storedDocument
operator|==
literal|null
condition|)
block|{
name|is
operator|.
name|skipBytes
argument_list|(
name|size
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|contextSet
operator|!=
literal|null
condition|)
block|{
comment|//Exit if the document is not concerned
if|if
condition|(
operator|!
name|contextSet
operator|.
name|containsDoc
argument_list|(
name|storedDocument
argument_list|)
condition|)
block|{
name|is
operator|.
name|skipBytes
argument_list|(
name|size
argument_list|)
expr_stmt|;
continue|continue;
block|}
block|}
comment|//Process the nodes
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|gidsCount
condition|;
name|j
operator|++
control|)
block|{
name|NodeId
name|nodeId
init|=
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getNodeFactory
argument_list|()
operator|.
name|createFromStream
argument_list|(
name|is
argument_list|)
decl_stmt|;
name|int
name|freq
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
name|NodeProxy
name|storedNode
decl_stmt|;
switch|switch
condition|(
name|storedSection
condition|)
block|{
case|case
name|ATTRIBUTE_SECTION
case|:
name|storedNode
operator|=
operator|new
name|NodeProxy
argument_list|(
name|storedDocument
argument_list|,
name|nodeId
argument_list|,
name|Node
operator|.
name|ATTRIBUTE_NODE
argument_list|)
expr_stmt|;
break|break;
case|case
name|TEXT_SECTION
case|:
name|storedNode
operator|=
operator|new
name|NodeProxy
argument_list|(
name|storedDocument
argument_list|,
name|nodeId
argument_list|,
name|Node
operator|.
name|TEXT_NODE
argument_list|)
expr_stmt|;
break|break;
default|default :
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid section type in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|)
throw|;
block|}
comment|// if a context set is specified, we can directly check if the
comment|// matching text node is a descendant of one of the nodes
comment|// in the context set.
if|if
condition|(
name|contextSet
operator|!=
literal|null
condition|)
block|{
name|NodeProxy
name|parent
decl_stmt|;
switch|switch
condition|(
name|storedSection
condition|)
block|{
case|case
name|ATTRIBUTE_SECTION
case|:
if|if
condition|(
name|contextSet
operator|instanceof
name|VirtualNodeSet
condition|)
block|{
name|parent
operator|=
name|contextSet
operator|.
name|parentWithChild
argument_list|(
name|storedNode
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|,
name|NodeProxy
operator|.
name|UNKNOWN_NODE_LEVEL
argument_list|)
expr_stmt|;
if|if
condition|(
name|parent
operator|!=
literal|null
operator|&&
operator|!
name|parent
operator|.
name|getNodeId
argument_list|()
operator|.
name|equals
argument_list|(
name|storedNode
operator|.
name|getNodeId
argument_list|()
argument_list|)
condition|)
name|parent
operator|=
literal|null
expr_stmt|;
block|}
else|else
name|parent
operator|=
name|contextSet
operator|.
name|get
argument_list|(
name|storedNode
argument_list|)
expr_stmt|;
break|break;
case|case
name|TEXT_SECTION
case|:
name|parent
operator|=
name|contextSet
operator|.
name|parentWithChild
argument_list|(
name|storedNode
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|,
name|NodeProxy
operator|.
name|UNKNOWN_NODE_LEVEL
argument_list|)
expr_stmt|;
break|break;
default|default :
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid section type in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|)
throw|;
block|}
if|if
condition|(
name|parent
operator|!=
literal|null
condition|)
block|{
name|Match
name|match
init|=
operator|new
name|Match
argument_list|(
name|nodeId
argument_list|,
name|token
argument_list|,
name|freq
argument_list|)
decl_stmt|;
name|readOccurrences
argument_list|(
name|freq
argument_list|,
name|is
argument_list|,
name|match
argument_list|,
name|token
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
name|parent
operator|.
name|addMatch
argument_list|(
name|match
argument_list|)
expr_stmt|;
name|int
name|sizeHint
init|=
name|contextSet
operator|.
name|getSizeHint
argument_list|(
name|storedDocument
argument_list|)
decl_stmt|;
name|result
operator|.
name|add
argument_list|(
name|parent
argument_list|,
name|sizeHint
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|is
operator|.
name|skip
argument_list|(
name|freq
argument_list|)
expr_stmt|;
block|}
comment|// otherwise, we add all text nodes without check
block|}
else|else
block|{
name|Match
name|match
init|=
operator|new
name|Match
argument_list|(
name|nodeId
argument_list|,
name|token
argument_list|,
name|freq
argument_list|)
decl_stmt|;
name|readOccurrences
argument_list|(
name|freq
argument_list|,
name|is
argument_list|,
name|match
argument_list|,
name|token
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
name|storedNode
operator|.
name|addMatch
argument_list|(
name|match
argument_list|)
expr_stmt|;
name|result
operator|.
name|add
argument_list|(
name|storedNode
argument_list|,
name|Constants
operator|.
name|NO_SIZE_HINT
argument_list|)
expr_stmt|;
block|}
name|context
operator|.
name|proceed
argument_list|()
expr_stmt|;
block|}
block|}
comment|//} catch (EOFException e) {
comment|//    // EOF is expected here
comment|//    LOG.warn("REPORT ME for confirmation " + e.getMessage(), e);
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
operator|+
literal|" in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|//TODO : return ?
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|result
return|;
block|}
specifier|private
name|NodeSet
name|getNodesRegexp
parameter_list|(
name|XQueryContext
name|context
parameter_list|,
name|DocumentSet
name|docs
parameter_list|,
name|NodeSet
name|contextSet
parameter_list|,
name|String
name|expr
parameter_list|,
name|int
name|type
parameter_list|)
throws|throws
name|TerminatedException
block|{
comment|//Return early
if|if
condition|(
name|expr
operator|==
literal|null
condition|)
return|return
literal|null
return|;
if|if
condition|(
name|stoplist
operator|.
name|contains
argument_list|(
name|expr
argument_list|)
condition|)
return|return
literal|null
return|;
comment|//TODO : case conversion should be handled by the tokenizer -pb
name|expr
operator|=
name|expr
operator|.
name|toLowerCase
argument_list|()
expr_stmt|;
comment|// if the regexp starts with a char sequence, we restrict the index scan to entries starting with
comment|// the same sequence. Otherwise, we have to scan the whole index.
specifier|final
name|StringBuffer
name|token
init|=
operator|new
name|StringBuffer
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expr
operator|.
name|length
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|Character
operator|.
name|isLetterOrDigit
argument_list|(
name|expr
operator|.
name|charAt
argument_list|(
name|i
argument_list|)
argument_list|)
condition|)
name|token
operator|.
name|append
argument_list|(
name|expr
operator|.
name|charAt
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
else|else
break|break;
block|}
try|try
block|{
name|TermMatcher
name|comparator
init|=
operator|new
name|RegexMatcher
argument_list|(
name|expr
argument_list|,
name|type
argument_list|,
name|Pattern
operator|.
name|CASE_INSENSITIVE
operator||
name|Pattern
operator|.
name|UNICODE_CASE
argument_list|)
decl_stmt|;
return|return
name|getNodes
argument_list|(
name|context
argument_list|,
name|docs
argument_list|,
name|contextSet
argument_list|,
name|comparator
argument_list|,
name|token
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|EXistException
name|e
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
block|}
comment|/* Return all nodes for wich the matcher matches. 	 * @see org.exist.storage.TextSearchEngine#getNodes(org.exist.xquery.XQueryContext, org.exist.dom.DocumentSet, org.exist.dom.NodeSet, org.exist.storage.TermMatcher, java.lang.CharSequence) 	 */
specifier|public
name|NodeSet
name|getNodes
parameter_list|(
name|XQueryContext
name|context
parameter_list|,
name|DocumentSet
name|docs
parameter_list|,
name|NodeSet
name|contextSet
parameter_list|,
name|TermMatcher
name|matcher
parameter_list|,
name|CharSequence
name|startTerm
parameter_list|)
throws|throws
name|TerminatedException
block|{
specifier|final
name|NodeSet
name|result
init|=
operator|new
name|ExtArrayNodeSet
argument_list|()
decl_stmt|;
specifier|final
name|SearchCallback
name|cb
init|=
operator|new
name|SearchCallback
argument_list|(
name|context
argument_list|,
name|matcher
argument_list|,
name|result
argument_list|,
name|contextSet
argument_list|,
name|docs
argument_list|)
decl_stmt|;
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
for|for
control|(
name|Iterator
name|iter
init|=
name|docs
operator|.
name|getCollectionIterator
argument_list|()
init|;
name|iter
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
specifier|final
name|short
name|collectionId
init|=
operator|(
operator|(
name|Collection
operator|)
name|iter
operator|.
name|next
argument_list|()
operator|)
operator|.
name|getId
argument_list|()
decl_stmt|;
comment|//Compute a key for the token
name|Value
name|value
decl_stmt|;
if|if
condition|(
name|startTerm
operator|!=
literal|null
operator|&&
name|startTerm
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
comment|//TODO : case conversion should be handled by the tokenizer -pb
name|value
operator|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|,
name|startTerm
operator|.
name|toString
argument_list|()
operator|.
name|toLowerCase
argument_list|()
argument_list|)
expr_stmt|;
else|else
name|value
operator|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|)
expr_stmt|;
name|IndexQuery
name|query
init|=
operator|new
name|IndexQuery
argument_list|(
name|IndexQuery
operator|.
name|TRUNC_RIGHT
argument_list|,
name|value
argument_list|)
decl_stmt|;
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|()
expr_stmt|;
name|dbTokens
operator|.
name|query
argument_list|(
name|query
argument_list|,
name|cb
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|BTreeException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|//TODO return null ? rethrow ? -pb
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|//TODO return null ? rethrow ? -pb
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|result
return|;
block|}
specifier|public
name|String
index|[]
name|getIndexTerms
parameter_list|(
name|DocumentSet
name|docs
parameter_list|,
name|TermMatcher
name|matcher
parameter_list|)
block|{
specifier|final
name|IndexCallback
name|cb
init|=
operator|new
name|IndexCallback
argument_list|(
literal|null
argument_list|,
name|matcher
argument_list|)
decl_stmt|;
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
for|for
control|(
name|Iterator
name|iter
init|=
name|docs
operator|.
name|getCollectionIterator
argument_list|()
init|;
name|iter
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
specifier|final
name|short
name|collectionId
init|=
operator|(
operator|(
name|Collection
operator|)
name|iter
operator|.
name|next
argument_list|()
operator|)
operator|.
name|getId
argument_list|()
decl_stmt|;
comment|//Compute a key for the token
name|Value
name|value
init|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|)
decl_stmt|;
name|IndexQuery
name|query
init|=
operator|new
name|IndexQuery
argument_list|(
name|IndexQuery
operator|.
name|TRUNC_RIGHT
argument_list|,
name|value
argument_list|)
decl_stmt|;
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|()
expr_stmt|;
name|dbTokens
operator|.
name|query
argument_list|(
name|query
argument_list|,
name|cb
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|BTreeException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TerminatedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|()
expr_stmt|;
block|}
block|}
return|return
name|cb
operator|.
name|getMatches
argument_list|()
return|;
block|}
specifier|public
name|Occurrences
index|[]
name|scanIndexTerms
parameter_list|(
name|DocumentSet
name|docs
parameter_list|,
name|NodeSet
name|contextSet
parameter_list|,
name|String
name|start
parameter_list|,
name|String
name|end
parameter_list|)
throws|throws
name|PermissionDeniedException
block|{
specifier|final
name|IndexScanCallback
name|cb
init|=
operator|new
name|IndexScanCallback
argument_list|(
name|docs
argument_list|,
name|contextSet
argument_list|)
decl_stmt|;
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
for|for
control|(
name|Iterator
name|i
init|=
name|docs
operator|.
name|getCollectionIterator
argument_list|()
init|;
name|i
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
specifier|final
name|short
name|collectionId
init|=
operator|(
operator|(
name|Collection
operator|)
name|i
operator|.
name|next
argument_list|()
operator|)
operator|.
name|getId
argument_list|()
decl_stmt|;
specifier|final
name|IndexQuery
name|query
decl_stmt|;
if|if
condition|(
name|end
operator|==
literal|null
condition|)
block|{
name|Value
name|startRef
init|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|,
name|start
operator|.
name|toLowerCase
argument_list|()
argument_list|)
decl_stmt|;
name|query
operator|=
operator|new
name|IndexQuery
argument_list|(
name|IndexQuery
operator|.
name|TRUNC_RIGHT
argument_list|,
name|startRef
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Value
name|startRef
init|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|,
name|start
operator|.
name|toLowerCase
argument_list|()
argument_list|)
decl_stmt|;
name|Value
name|endRef
init|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|,
name|end
operator|.
name|toLowerCase
argument_list|()
argument_list|)
decl_stmt|;
name|query
operator|=
operator|new
name|IndexQuery
argument_list|(
name|IndexQuery
operator|.
name|BW
argument_list|,
name|startRef
argument_list|,
name|endRef
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|()
expr_stmt|;
name|dbTokens
operator|.
name|query
argument_list|(
name|query
argument_list|,
name|cb
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|BTreeException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TerminatedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|()
expr_stmt|;
block|}
block|}
name|Occurrences
index|[]
name|result
init|=
operator|new
name|Occurrences
index|[
name|cb
operator|.
name|map
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
return|return
operator|(
name|Occurrences
index|[]
operator|)
name|cb
operator|.
name|map
operator|.
name|values
argument_list|()
operator|.
name|toArray
argument_list|(
name|result
argument_list|)
return|;
block|}
comment|/**      * @param freq      * @param is      * @param match      * @throws IOException      */
specifier|private
name|void
name|readOccurrences
parameter_list|(
name|int
name|freq
parameter_list|,
name|VariableByteInput
name|is
parameter_list|,
name|Match
name|match
parameter_list|,
name|int
name|length
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|int
name|k
init|=
literal|0
init|;
name|k
operator|<
name|freq
condition|;
name|k
operator|++
control|)
block|{
name|match
operator|.
name|addOffset
argument_list|(
name|is
operator|.
name|readInt
argument_list|()
argument_list|,
name|length
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Collect all words in a document to be removed      *       * @param words      *                Description of the Parameter      * @param domIterator      *                Description of the Parameter      */
comment|//TODO : unify functionalities with storeText -pb
specifier|private
name|void
name|collect
parameter_list|(
name|Set
name|words
parameter_list|,
name|Iterator
name|domIterator
parameter_list|)
block|{
name|byte
index|[]
name|data
init|=
operator|(
operator|(
name|Value
operator|)
name|domIterator
operator|.
name|next
argument_list|()
operator|)
operator|.
name|getData
argument_list|()
decl_stmt|;
name|short
name|type
init|=
name|Signatures
operator|.
name|getType
argument_list|(
name|data
index|[
literal|0
index|]
argument_list|)
decl_stmt|;
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|Node
operator|.
name|ELEMENT_NODE
case|:
name|int
name|children
init|=
name|ByteConversion
operator|.
name|byteToInt
argument_list|(
name|data
argument_list|,
literal|1
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|children
condition|;
name|i
operator|++
control|)
name|collect
argument_list|(
name|words
argument_list|,
name|domIterator
argument_list|)
expr_stmt|;
break|break;
case|case
name|Node
operator|.
name|TEXT_NODE
case|:
name|int
name|dlnLen
init|=
name|ByteConversion
operator|.
name|byteToShort
argument_list|(
name|data
argument_list|,
literal|1
argument_list|)
decl_stmt|;
name|int
name|nodeIdLen
init|=
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getNodeFactory
argument_list|()
operator|.
name|lengthInBytes
argument_list|(
name|dlnLen
argument_list|,
name|data
argument_list|,
literal|3
argument_list|)
decl_stmt|;
name|String
name|s
decl_stmt|;
try|try
block|{
name|s
operator|=
operator|new
name|String
argument_list|(
name|data
argument_list|,
name|nodeIdLen
operator|+
literal|3
argument_list|,
name|data
operator|.
name|length
operator|-
name|nodeIdLen
operator|-
literal|3
argument_list|,
literal|"UTF-8"
argument_list|)
expr_stmt|;
name|tokenizer
operator|.
name|setText
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|TextToken
name|token
decl_stmt|;
while|while
condition|(
literal|null
operator|!=
operator|(
name|token
operator|=
name|tokenizer
operator|.
name|nextToken
argument_list|()
operator|)
condition|)
block|{
name|String
name|word
init|=
name|token
operator|.
name|getText
argument_list|()
decl_stmt|;
if|if
condition|(
name|stoplist
operator|.
name|contains
argument_list|(
name|word
argument_list|)
condition|)
continue|continue;
name|words
operator|.
name|add
argument_list|(
name|word
operator|.
name|toLowerCase
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|UnsupportedEncodingException
name|e
parameter_list|)
block|{
comment|//s = new String(data, 1, data.length - 1);
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|s
operator|=
literal|null
expr_stmt|;
block|}
break|break;
case|case
name|Node
operator|.
name|ATTRIBUTE_NODE
case|:
name|byte
name|idSizeType
init|=
operator|(
name|byte
operator|)
operator|(
name|data
index|[
literal|0
index|]
operator|&
literal|0x3
operator|)
decl_stmt|;
name|boolean
name|hasNamespace
init|=
operator|(
name|data
index|[
literal|0
index|]
operator|&
literal|0x10
operator|)
operator|==
literal|0x10
decl_stmt|;
name|dlnLen
operator|=
name|ByteConversion
operator|.
name|byteToShort
argument_list|(
name|data
argument_list|,
literal|1
argument_list|)
expr_stmt|;
name|nodeIdLen
operator|=
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getNodeFactory
argument_list|()
operator|.
name|lengthInBytes
argument_list|(
name|dlnLen
argument_list|,
name|data
argument_list|,
literal|3
argument_list|)
expr_stmt|;
name|int
name|readOffset
init|=
name|Signatures
operator|.
name|getLength
argument_list|(
name|idSizeType
argument_list|)
operator|+
name|nodeIdLen
operator|+
literal|3
decl_stmt|;
if|if
condition|(
name|hasNamespace
condition|)
block|{
name|readOffset
operator|+=
literal|2
expr_stmt|;
comment|// skip namespace id
specifier|final
name|short
name|prefixLen
init|=
name|ByteConversion
operator|.
name|byteToShort
argument_list|(
name|data
argument_list|,
name|readOffset
argument_list|)
decl_stmt|;
name|readOffset
operator|+=
name|prefixLen
operator|+
literal|2
expr_stmt|;
comment|// skip prefix
block|}
name|String
name|val
decl_stmt|;
try|try
block|{
name|val
operator|=
operator|new
name|String
argument_list|(
name|data
argument_list|,
name|readOffset
argument_list|,
name|data
operator|.
name|length
operator|-
name|readOffset
argument_list|,
literal|"UTF-8"
argument_list|)
expr_stmt|;
name|tokenizer
operator|.
name|setText
argument_list|(
name|val
argument_list|)
expr_stmt|;
name|TextToken
name|token
decl_stmt|;
while|while
condition|(
literal|null
operator|!=
operator|(
name|token
operator|=
name|tokenizer
operator|.
name|nextToken
argument_list|()
operator|)
condition|)
block|{
name|String
name|word
init|=
name|token
operator|.
name|getText
argument_list|()
decl_stmt|;
if|if
condition|(
name|stoplist
operator|.
name|contains
argument_list|(
name|word
argument_list|)
condition|)
continue|continue;
name|words
operator|.
name|add
argument_list|(
name|word
operator|.
name|toLowerCase
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|UnsupportedEncodingException
name|e
parameter_list|)
block|{
comment|//val = new String(data,
comment|//        1 + Signatures.getLength(idSizeType), data.length
comment|//                - 1 - Signatures.getLength(idSizeType));
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|val
operator|=
literal|null
expr_stmt|;
block|}
break|break;
default|default :
comment|//Other types are ignored : some may be useful though -pb
comment|//TOUNDERSTAND : it looks like other types (got : Node.PROCESSING_INSTRUCTION_NODE)
comment|//are stored in the index ??? -pb
block|}
block|}
specifier|public
name|boolean
name|close
parameter_list|()
throws|throws
name|DBException
block|{
return|return
name|dbTokens
operator|.
name|close
argument_list|()
return|;
block|}
specifier|public
name|void
name|printStatistics
parameter_list|()
block|{
name|dbTokens
operator|.
name|printStatistics
argument_list|()
expr_stmt|;
block|}
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|this
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" at "
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" owned by "
operator|+
name|broker
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/** 	 * This inner class is responsible for actually storing the list of 	 * occurrences. 	 *  	 * @author Wolfgang Meier<meier@ifs.tu-darmstadt.de> 	 */
specifier|final
class|class
name|InvertedIndex
block|{
specifier|private
name|DocumentImpl
name|doc
init|=
literal|null
decl_stmt|;
comment|// To distinguish between attribute values and text, we use
comment|// two maps: words[0] collects text, words[1] stores attribute
comment|// values.
comment|//TODO : very tricky. Why not 2 inverted indexes ??? -pb
specifier|private
name|Map
name|words
index|[]
init|=
operator|new
name|HashMap
index|[
literal|2
index|]
decl_stmt|;
specifier|private
name|VariableByteOutputStream
name|os
init|=
operator|new
name|VariableByteOutputStream
argument_list|(
literal|7
argument_list|)
decl_stmt|;
specifier|public
name|InvertedIndex
parameter_list|()
block|{
name|words
index|[
literal|0
index|]
operator|=
operator|new
name|HashMap
argument_list|(
literal|512
argument_list|)
expr_stmt|;
name|words
index|[
literal|1
index|]
operator|=
operator|new
name|HashMap
argument_list|(
literal|256
argument_list|)
expr_stmt|;
block|}
specifier|public
name|void
name|setDocument
parameter_list|(
name|DocumentImpl
name|document
parameter_list|)
block|{
if|if
condition|(
name|this
operator|.
name|doc
operator|!=
literal|null
operator|&&
name|this
operator|.
name|doc
operator|.
name|getDocId
argument_list|()
operator|!=
name|document
operator|.
name|getDocId
argument_list|()
condition|)
name|flush
argument_list|()
expr_stmt|;
name|this
operator|.
name|doc
operator|=
name|document
expr_stmt|;
block|}
specifier|public
name|void
name|addText
parameter_list|(
name|XMLString
name|text
parameter_list|,
name|TextToken
name|token
parameter_list|,
name|NodeId
name|nodeId
parameter_list|)
block|{
comment|//Is this token already pending ?
name|OccurrenceList
name|list
init|=
operator|(
name|OccurrenceList
operator|)
name|words
index|[
literal|0
index|]
operator|.
name|get
argument_list|(
name|token
argument_list|)
decl_stmt|;
comment|//Create a GIDs list
if|if
condition|(
name|list
operator|==
literal|null
condition|)
block|{
name|list
operator|=
operator|new
name|OccurrenceList
argument_list|()
expr_stmt|;
name|list
operator|.
name|add
argument_list|(
name|nodeId
argument_list|,
name|token
operator|.
name|startOffset
argument_list|()
argument_list|)
expr_stmt|;
name|words
index|[
literal|0
index|]
operator|.
name|put
argument_list|(
name|token
operator|.
name|getText
argument_list|()
argument_list|,
name|list
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|//Add node's GID to the list
name|list
operator|.
name|add
argument_list|(
name|nodeId
argument_list|,
name|token
operator|.
name|startOffset
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
comment|//TODO : unify functionalities with addText -pb
specifier|public
name|void
name|addAttribute
parameter_list|(
name|TextToken
name|token
parameter_list|,
name|NodeId
name|nodeId
parameter_list|)
block|{
comment|//Is this token already pending ?
name|OccurrenceList
name|list
init|=
operator|(
name|OccurrenceList
operator|)
name|words
index|[
literal|1
index|]
operator|.
name|get
argument_list|(
name|token
argument_list|)
decl_stmt|;
comment|//Create a GIDs list
if|if
condition|(
name|list
operator|==
literal|null
condition|)
block|{
name|list
operator|=
operator|new
name|OccurrenceList
argument_list|()
expr_stmt|;
name|list
operator|.
name|add
argument_list|(
name|nodeId
argument_list|,
name|token
operator|.
name|startOffset
argument_list|()
argument_list|)
expr_stmt|;
name|words
index|[
literal|1
index|]
operator|.
name|put
argument_list|(
name|token
operator|.
name|getText
argument_list|()
argument_list|,
name|list
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|//Add node's GID to the list
name|list
operator|.
name|add
argument_list|(
name|nodeId
argument_list|,
name|token
operator|.
name|startOffset
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|flush
parameter_list|()
block|{
comment|//return early
if|if
condition|(
name|this
operator|.
name|doc
operator|==
literal|null
condition|)
return|return;
specifier|final
name|int
name|wordsCount
init|=
name|words
index|[
literal|0
index|]
operator|.
name|size
argument_list|()
operator|+
name|words
index|[
literal|1
index|]
operator|.
name|size
argument_list|()
decl_stmt|;
if|if
condition|(
name|wordsCount
operator|==
literal|0
condition|)
return|return;
specifier|final
name|ProgressIndicator
name|progress
init|=
operator|new
name|ProgressIndicator
argument_list|(
name|wordsCount
argument_list|,
literal|100
argument_list|)
decl_stmt|;
specifier|final
name|short
name|collectionId
init|=
name|this
operator|.
name|doc
operator|.
name|getCollection
argument_list|()
operator|.
name|getId
argument_list|()
decl_stmt|;
name|int
name|count
init|=
literal|0
decl_stmt|;
for|for
control|(
name|byte
name|currentSection
init|=
literal|0
init|;
name|currentSection
operator|<=
name|ATTRIBUTE_SECTION
condition|;
name|currentSection
operator|++
control|)
block|{
comment|//Not very necessary, but anyway...
switch|switch
condition|(
name|currentSection
condition|)
block|{
case|case
name|TEXT_SECTION
case|:
case|case
name|ATTRIBUTE_SECTION
case|:
break|break;
default|default :
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid section type in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|)
throw|;
block|}
for|for
control|(
name|Iterator
name|i
init|=
name|words
index|[
name|currentSection
index|]
operator|.
name|entrySet
argument_list|()
operator|.
name|iterator
argument_list|()
init|;
name|i
operator|.
name|hasNext
argument_list|()
condition|;
name|count
operator|++
control|)
block|{
name|Map
operator|.
name|Entry
name|entry
init|=
operator|(
name|Map
operator|.
name|Entry
operator|)
name|i
operator|.
name|next
argument_list|()
decl_stmt|;
name|String
name|token
init|=
operator|(
name|String
operator|)
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|OccurrenceList
name|occurences
init|=
operator|(
name|OccurrenceList
operator|)
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
comment|//Don't forget this one
name|occurences
operator|.
name|sort
argument_list|()
expr_stmt|;
name|os
operator|.
name|clear
argument_list|()
expr_stmt|;
name|os
operator|.
name|writeInt
argument_list|(
name|this
operator|.
name|doc
operator|.
name|getDocId
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeByte
argument_list|(
name|currentSection
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeInt
argument_list|(
name|occurences
operator|.
name|getTermCount
argument_list|()
argument_list|)
expr_stmt|;
comment|//TOUNDERSTAND -pb
name|int
name|lenOffset
init|=
name|os
operator|.
name|position
argument_list|()
decl_stmt|;
name|os
operator|.
name|writeFixedInt
argument_list|(
literal|0
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|occurences
operator|.
name|getSize
argument_list|()
condition|;
control|)
block|{
try|try
block|{
name|occurences
operator|.
name|nodes
index|[
name|j
index|]
operator|.
name|write
argument_list|(
name|os
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"IOException while writing fulltext index: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|int
name|freq
init|=
name|occurences
operator|.
name|getOccurrences
argument_list|(
name|j
argument_list|)
decl_stmt|;
name|os
operator|.
name|writeInt
argument_list|(
name|freq
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|k
init|=
literal|0
init|;
name|k
operator|<
name|freq
condition|;
name|k
operator|++
control|)
block|{
name|os
operator|.
name|writeInt
argument_list|(
name|occurences
operator|.
name|offsets
index|[
name|j
operator|+
name|k
index|]
argument_list|)
expr_stmt|;
block|}
name|j
operator|+=
name|freq
expr_stmt|;
block|}
name|os
operator|.
name|writeFixedInt
argument_list|(
name|lenOffset
argument_list|,
name|os
operator|.
name|position
argument_list|()
operator|-
name|lenOffset
operator|-
literal|4
argument_list|)
expr_stmt|;
name|flushWord
argument_list|(
name|collectionId
argument_list|,
name|token
argument_list|,
name|os
operator|.
name|data
argument_list|()
argument_list|)
expr_stmt|;
name|progress
operator|.
name|setValue
argument_list|(
name|count
argument_list|)
expr_stmt|;
if|if
condition|(
name|progress
operator|.
name|changed
argument_list|()
condition|)
block|{
name|setChanged
argument_list|()
expr_stmt|;
name|notifyObservers
argument_list|(
name|progress
argument_list|)
expr_stmt|;
block|}
block|}
comment|//TOUNDERSTAND : is this a flush ?
comment|//If so, the ProgressIndicator should be reinitialized -pb
if|if
condition|(
name|wordsCount
operator|>
literal|100
condition|)
block|{
name|progress
operator|.
name|finish
argument_list|()
expr_stmt|;
name|setChanged
argument_list|()
expr_stmt|;
name|notifyObservers
argument_list|(
name|progress
argument_list|)
expr_stmt|;
block|}
name|words
index|[
name|currentSection
index|]
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|flushWord
parameter_list|(
name|short
name|collectionId
parameter_list|,
name|String
name|token
parameter_list|,
name|ByteArray
name|data
parameter_list|)
block|{
comment|//return early
comment|//TODO : is this ever called ? -pb
if|if
condition|(
name|data
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
return|return;
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|(
name|Lock
operator|.
name|WRITE_LOCK
argument_list|)
expr_stmt|;
name|WordRef
name|key
init|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|,
name|token
argument_list|)
decl_stmt|;
name|dbTokens
operator|.
name|append
argument_list|(
name|key
argument_list|,
name|data
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ReadOnlyException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Read-only error on '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
operator|+
literal|"' in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|()
expr_stmt|;
block|}
block|}
comment|/** 		 * Remove the entries in the current list from the index. 		 */
comment|//TODO: use VariableInputStream
specifier|public
name|void
name|remove
parameter_list|()
block|{
comment|//Return early
if|if
condition|(
name|doc
operator|==
literal|null
condition|)
return|return;
specifier|final
name|short
name|collectionId
init|=
name|this
operator|.
name|doc
operator|.
name|getCollection
argument_list|()
operator|.
name|getId
argument_list|()
decl_stmt|;
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
for|for
control|(
name|byte
name|currentSection
init|=
literal|0
init|;
name|currentSection
operator|<=
name|ATTRIBUTE_SECTION
condition|;
name|currentSection
operator|++
control|)
block|{
comment|//Not very necessary, but anyway...
switch|switch
condition|(
name|currentSection
condition|)
block|{
case|case
name|TEXT_SECTION
case|:
case|case
name|ATTRIBUTE_SECTION
case|:
break|break;
default|default :
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid section type in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|)
throw|;
block|}
for|for
control|(
name|Iterator
name|i
init|=
name|words
index|[
name|currentSection
index|]
operator|.
name|entrySet
argument_list|()
operator|.
name|iterator
argument_list|()
init|;
name|i
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
comment|//Compute a key for the token
name|Map
operator|.
name|Entry
name|entry
init|=
operator|(
name|Map
operator|.
name|Entry
operator|)
name|i
operator|.
name|next
argument_list|()
decl_stmt|;
name|OccurrenceList
name|storedOccurencesList
init|=
operator|(
name|OccurrenceList
operator|)
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|String
name|token
init|=
operator|(
name|String
operator|)
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|WordRef
name|key
init|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|,
name|token
argument_list|)
decl_stmt|;
name|OccurrenceList
name|newOccurencesList
init|=
operator|new
name|OccurrenceList
argument_list|()
decl_stmt|;
name|os
operator|.
name|clear
argument_list|()
expr_stmt|;
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|(
name|Lock
operator|.
name|WRITE_LOCK
argument_list|)
expr_stmt|;
name|Value
name|value
init|=
name|dbTokens
operator|.
name|get
argument_list|(
name|key
argument_list|)
decl_stmt|;
comment|//Does the token already has data in the index ?
if|if
condition|(
name|value
operator|!=
literal|null
condition|)
block|{
comment|//Add its data to the new list
name|VariableByteArrayInput
name|is
init|=
operator|new
name|VariableByteArrayInput
argument_list|(
name|value
operator|.
name|getData
argument_list|()
argument_list|)
decl_stmt|;
comment|//try {
while|while
condition|(
name|is
operator|.
name|available
argument_list|()
operator|>
literal|0
condition|)
block|{
name|int
name|storedDocId
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
name|byte
name|storedSection
init|=
name|is
operator|.
name|readByte
argument_list|()
decl_stmt|;
name|int
name|termCount
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
comment|//TOUNDERSTAND -pb
name|int
name|size
init|=
name|is
operator|.
name|readFixedInt
argument_list|()
decl_stmt|;
if|if
condition|(
name|storedSection
operator|!=
name|currentSection
operator|||
name|storedDocId
operator|!=
name|this
operator|.
name|doc
operator|.
name|getDocId
argument_list|()
condition|)
block|{
comment|// data are related to another section or document:
comment|// append them to any existing data
name|os
operator|.
name|writeInt
argument_list|(
name|storedDocId
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeByte
argument_list|(
name|storedSection
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeInt
argument_list|(
name|termCount
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeFixedInt
argument_list|(
name|size
argument_list|)
expr_stmt|;
name|is
operator|.
name|copyRaw
argument_list|(
name|os
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// data are related to our section and document:
comment|// feed the new list with the GIDs
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|termCount
condition|;
name|j
operator|++
control|)
block|{
name|NodeId
name|nodeId
init|=
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getNodeFactory
argument_list|()
operator|.
name|createFromStream
argument_list|(
name|is
argument_list|)
decl_stmt|;
name|int
name|freq
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
comment|// add the node to the new list if it is not
comment|// in the list of removed nodes
if|if
condition|(
operator|!
name|storedOccurencesList
operator|.
name|contains
argument_list|(
name|nodeId
argument_list|)
condition|)
block|{
for|for
control|(
name|int
name|k
init|=
literal|0
init|;
name|k
operator|<
name|freq
condition|;
name|k
operator|++
control|)
block|{
name|newOccurencesList
operator|.
name|add
argument_list|(
name|nodeId
argument_list|,
name|is
operator|.
name|readInt
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|is
operator|.
name|skip
argument_list|(
name|freq
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|//} catch (EOFException e) {
comment|//Is it expected ? -pb
comment|//LOG.warn("REPORT ME " + e.getMessage(), e);
comment|//}
comment|//append the data from the new list
if|if
condition|(
name|newOccurencesList
operator|.
name|getSize
argument_list|()
operator|>
literal|0
condition|)
block|{
comment|//Don't forget this one
name|newOccurencesList
operator|.
name|sort
argument_list|()
expr_stmt|;
name|os
operator|.
name|writeInt
argument_list|(
name|this
operator|.
name|doc
operator|.
name|getDocId
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeByte
argument_list|(
name|currentSection
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeInt
argument_list|(
name|newOccurencesList
operator|.
name|getTermCount
argument_list|()
argument_list|)
expr_stmt|;
comment|//TOUNDERSTAND -pb
name|int
name|lenOffset
init|=
name|os
operator|.
name|position
argument_list|()
decl_stmt|;
name|os
operator|.
name|writeFixedInt
argument_list|(
literal|0
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|m
init|=
literal|0
init|;
name|m
operator|<
name|newOccurencesList
operator|.
name|getSize
argument_list|()
condition|;
control|)
block|{
name|newOccurencesList
operator|.
name|nodes
index|[
name|m
index|]
operator|.
name|write
argument_list|(
name|os
argument_list|)
expr_stmt|;
name|int
name|freq
init|=
name|newOccurencesList
operator|.
name|getOccurrences
argument_list|(
name|m
argument_list|)
decl_stmt|;
name|os
operator|.
name|writeInt
argument_list|(
name|freq
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|n
init|=
literal|0
init|;
name|n
operator|<
name|freq
condition|;
name|n
operator|++
control|)
block|{
name|os
operator|.
name|writeInt
argument_list|(
name|newOccurencesList
operator|.
name|offsets
index|[
name|m
operator|+
name|n
index|]
argument_list|)
expr_stmt|;
block|}
name|m
operator|+=
name|freq
expr_stmt|;
block|}
name|os
operator|.
name|writeFixedInt
argument_list|(
name|lenOffset
argument_list|,
name|os
operator|.
name|position
argument_list|()
operator|-
name|lenOffset
operator|-
literal|4
argument_list|)
expr_stmt|;
block|}
comment|//Store the data
if|if
condition|(
name|os
operator|.
name|data
argument_list|()
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
name|dbTokens
operator|.
name|remove
argument_list|(
name|key
argument_list|)
expr_stmt|;
if|else 					            if
condition|(
name|dbTokens
operator|.
name|update
argument_list|(
name|value
operator|.
name|getAddress
argument_list|()
argument_list|,
name|key
argument_list|,
name|os
operator|.
name|data
argument_list|()
argument_list|)
operator|==
name|BFile
operator|.
name|UNKNOWN_ADDRESS
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Could not update index data for token '"
operator|+
name|token
operator|+
literal|"' in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|dbTokens
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|os
operator|.
name|data
argument_list|()
argument_list|)
operator|==
name|BFile
operator|.
name|UNKNOWN_ADDRESS
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Could not put index data for token '"
operator|+
name|token
operator|+
literal|"' in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ReadOnlyException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Read-only error on '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
operator|+
literal|"' in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|()
expr_stmt|;
block|}
block|}
name|words
index|[
name|currentSection
index|]
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|reindex
parameter_list|(
name|DocumentImpl
name|document
parameter_list|,
name|StoredNode
name|node
parameter_list|)
block|{
specifier|final
name|short
name|collectionId
init|=
name|document
operator|.
name|getCollection
argument_list|()
operator|.
name|getId
argument_list|()
decl_stmt|;
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
for|for
control|(
name|byte
name|currentSection
init|=
literal|0
init|;
name|currentSection
operator|<=
name|ATTRIBUTE_SECTION
condition|;
name|currentSection
operator|++
control|)
block|{
comment|//Not very necessary, but anyway...
switch|switch
condition|(
name|currentSection
condition|)
block|{
case|case
name|TEXT_SECTION
case|:
case|case
name|ATTRIBUTE_SECTION
case|:
break|break;
default|default :
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid section type in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|)
throw|;
block|}
for|for
control|(
name|Iterator
name|i
init|=
name|words
index|[
name|currentSection
index|]
operator|.
name|entrySet
argument_list|()
operator|.
name|iterator
argument_list|()
init|;
name|i
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
comment|//Compute a key for the token
name|Map
operator|.
name|Entry
name|entry
init|=
operator|(
name|Map
operator|.
name|Entry
operator|)
name|i
operator|.
name|next
argument_list|()
decl_stmt|;
name|String
name|token
init|=
operator|(
name|String
operator|)
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|WordRef
name|key
init|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|,
name|token
argument_list|)
decl_stmt|;
name|OccurrenceList
name|storedOccurencesList
init|=
operator|(
name|OccurrenceList
operator|)
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|os
operator|.
name|clear
argument_list|()
expr_stmt|;
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|(
name|Lock
operator|.
name|WRITE_LOCK
argument_list|)
expr_stmt|;
name|VariableByteInput
name|is
init|=
name|dbTokens
operator|.
name|getAsStream
argument_list|(
name|key
argument_list|)
decl_stmt|;
comment|//Does the token already has data in the index ?
if|if
condition|(
name|is
operator|!=
literal|null
condition|)
block|{
comment|//Add its data to the new list
comment|//try {
while|while
condition|(
name|is
operator|.
name|available
argument_list|()
operator|>
literal|0
condition|)
block|{
name|int
name|storedDocId
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
name|byte
name|storedSection
init|=
name|is
operator|.
name|readByte
argument_list|()
decl_stmt|;
name|int
name|termCount
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
comment|//TOUNDERSTAND -pb
name|int
name|size
init|=
name|is
operator|.
name|readFixedInt
argument_list|()
decl_stmt|;
if|if
condition|(
name|storedSection
operator|!=
name|currentSection
operator|||
name|storedDocId
operator|!=
name|document
operator|.
name|getDocId
argument_list|()
condition|)
block|{
comment|// data are related to another section or document:
comment|// append them to any existing data
name|os
operator|.
name|writeInt
argument_list|(
name|storedDocId
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeByte
argument_list|(
name|storedSection
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeInt
argument_list|(
name|termCount
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeFixedInt
argument_list|(
name|size
argument_list|)
expr_stmt|;
name|is
operator|.
name|copyRaw
argument_list|(
name|os
argument_list|,
name|size
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// data are related to our section and document:
comment|// feed the new list with the GIDs
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|termCount
condition|;
name|j
operator|++
control|)
block|{
name|NodeId
name|nodeId
init|=
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getNodeFactory
argument_list|()
operator|.
name|createFromStream
argument_list|(
name|is
argument_list|)
decl_stmt|;
name|int
name|freq
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
if|if
condition|(
name|node
operator|==
literal|null
condition|)
block|{
if|if
condition|(
name|nodeId
operator|.
name|getTreeLevel
argument_list|()
operator|<
name|document
operator|.
name|getMetadata
argument_list|()
operator|.
name|reindexRequired
argument_list|()
condition|)
block|{
for|for
control|(
name|int
name|l
init|=
literal|0
init|;
name|l
operator|<
name|freq
condition|;
name|l
operator|++
control|)
block|{
comment|//Note that we use the existing list
name|storedOccurencesList
operator|.
name|add
argument_list|(
name|nodeId
argument_list|,
name|is
operator|.
name|readInt
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
name|is
operator|.
name|skip
argument_list|(
name|freq
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|document
operator|.
name|getDocId
argument_list|()
operator|!=
operator|(
operator|(
name|DocumentImpl
operator|)
name|node
operator|.
name|getOwnerDocument
argument_list|()
operator|)
operator|.
name|getDocId
argument_list|()
operator|||
operator|!
name|nodeId
operator|.
name|isDescendantOrSelfOf
argument_list|(
name|node
operator|.
name|getNodeId
argument_list|()
argument_list|)
condition|)
block|{
for|for
control|(
name|int
name|l
init|=
literal|0
init|;
name|l
operator|<
name|freq
condition|;
name|l
operator|++
control|)
block|{
comment|//Note that we use the existing list
name|storedOccurencesList
operator|.
name|add
argument_list|(
name|nodeId
argument_list|,
name|is
operator|.
name|readInt
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
name|is
operator|.
name|skip
argument_list|(
name|freq
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|//} catch (EOFException e) {
comment|//EOF is expected here
comment|//}
block|}
if|if
condition|(
name|storedOccurencesList
operator|.
name|getSize
argument_list|()
operator|>
literal|0
condition|)
block|{
comment|//append the data from the new list
name|storedOccurencesList
operator|.
name|sort
argument_list|()
expr_stmt|;
name|os
operator|.
name|writeInt
argument_list|(
name|document
operator|.
name|getDocId
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeByte
argument_list|(
name|currentSection
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeInt
argument_list|(
name|storedOccurencesList
operator|.
name|getTermCount
argument_list|()
argument_list|)
expr_stmt|;
comment|//TOUNDERSTAND -pb
name|int
name|lenOffset
init|=
name|os
operator|.
name|position
argument_list|()
decl_stmt|;
name|os
operator|.
name|writeFixedInt
argument_list|(
literal|0
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|m
init|=
literal|0
init|;
name|m
operator|<
name|storedOccurencesList
operator|.
name|getSize
argument_list|()
condition|;
control|)
block|{
name|storedOccurencesList
operator|.
name|nodes
index|[
name|m
index|]
operator|.
name|write
argument_list|(
name|os
argument_list|)
expr_stmt|;
name|int
name|freq
init|=
name|storedOccurencesList
operator|.
name|getOccurrences
argument_list|(
name|m
argument_list|)
decl_stmt|;
name|os
operator|.
name|writeInt
argument_list|(
name|freq
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|n
init|=
literal|0
init|;
name|n
operator|<
name|freq
condition|;
name|n
operator|++
control|)
block|{
name|os
operator|.
name|writeInt
argument_list|(
name|storedOccurencesList
operator|.
name|offsets
index|[
name|m
operator|+
name|n
index|]
argument_list|)
expr_stmt|;
block|}
name|m
operator|+=
name|freq
expr_stmt|;
block|}
name|os
operator|.
name|writeFixedInt
argument_list|(
name|lenOffset
argument_list|,
name|os
operator|.
name|position
argument_list|()
operator|-
name|lenOffset
operator|-
literal|4
argument_list|)
expr_stmt|;
block|}
comment|//Store the data
if|if
condition|(
name|is
operator|==
literal|null
condition|)
block|{
comment|//TOUNDERSTAND : Should is be null, what will there be in os.data() ? -pb
if|if
condition|(
name|dbTokens
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|os
operator|.
name|data
argument_list|()
argument_list|)
operator|==
name|BFile
operator|.
name|UNKNOWN_ADDRESS
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Could not put index data for token '"
operator|+
name|token
operator|+
literal|"' in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|long
name|address
init|=
operator|(
operator|(
name|BFile
operator|.
name|PageInputStream
operator|)
name|is
operator|)
operator|.
name|getAddress
argument_list|()
decl_stmt|;
if|if
condition|(
name|dbTokens
operator|.
name|update
argument_list|(
name|address
argument_list|,
name|key
argument_list|,
name|os
operator|.
name|data
argument_list|()
argument_list|)
operator|==
name|BFile
operator|.
name|UNKNOWN_ADDRESS
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Could not update index data for value '"
operator|+
name|token
operator|+
literal|"' in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|)
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ReadOnlyException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Read-only error on '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"io error while reindexing word '"
operator|+
name|token
operator|+
literal|"' in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|(
name|Lock
operator|.
name|WRITE_LOCK
argument_list|)
expr_stmt|;
block|}
block|}
name|words
index|[
name|currentSection
index|]
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
block|}
specifier|private
class|class
name|IndexCallback
implements|implements
name|BTreeCallback
block|{
name|List
name|matches
init|=
operator|new
name|ArrayList
argument_list|()
decl_stmt|;
name|TermMatcher
name|matcher
decl_stmt|;
name|XQueryContext
name|context
decl_stmt|;
specifier|public
name|IndexCallback
parameter_list|(
name|XQueryContext
name|context
parameter_list|,
name|TermMatcher
name|matcher
parameter_list|)
block|{
name|this
operator|.
name|matcher
operator|=
name|matcher
expr_stmt|;
name|this
operator|.
name|context
operator|=
name|context
expr_stmt|;
block|}
specifier|public
name|String
index|[]
name|getMatches
parameter_list|()
block|{
name|String
index|[]
name|a
init|=
operator|new
name|String
index|[
name|matches
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
return|return
operator|(
name|String
index|[]
operator|)
name|matches
operator|.
name|toArray
argument_list|(
name|a
argument_list|)
return|;
block|}
comment|/* (non-Javadoc) 		 * @see org.dbxml.core.filer.BTreeCallback#indexInfo(org.dbxml.core.data.Value, long) 		 */
specifier|public
name|boolean
name|indexInfo
parameter_list|(
name|Value
name|key
parameter_list|,
name|long
name|pointer
parameter_list|)
throws|throws
name|TerminatedException
block|{
if|if
condition|(
name|context
operator|!=
literal|null
condition|)
name|context
operator|.
name|proceed
argument_list|()
expr_stmt|;
try|try
block|{
specifier|final
name|String
name|word
init|=
operator|new
name|String
argument_list|(
name|key
operator|.
name|getData
argument_list|()
argument_list|,
literal|2
argument_list|,
name|key
operator|.
name|getLength
argument_list|()
operator|-
literal|2
argument_list|,
literal|"UTF-8"
argument_list|)
decl_stmt|;
if|if
condition|(
name|matcher
operator|.
name|matches
argument_list|(
name|word
argument_list|)
condition|)
name|matches
operator|.
name|add
argument_list|(
name|word
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
catch|catch
parameter_list|(
name|UnsupportedEncodingException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|//word = new String(key.getData(), 2, key.getLength() - 2);
return|return
literal|true
return|;
block|}
block|}
block|}
specifier|private
specifier|final
class|class
name|SearchCallback
implements|implements
name|BTreeCallback
block|{
name|DocumentSet
name|docs
decl_stmt|;
name|TermMatcher
name|matcher
decl_stmt|;
name|NodeSet
name|result
decl_stmt|;
name|NodeSet
name|contextSet
decl_stmt|;
name|XQueryContext
name|context
decl_stmt|;
name|XMLString
name|word
init|=
operator|new
name|XMLString
argument_list|(
literal|64
argument_list|)
decl_stmt|;
specifier|public
name|SearchCallback
parameter_list|(
name|XQueryContext
name|context
parameter_list|,
name|TermMatcher
name|comparator
parameter_list|,
name|NodeSet
name|result
parameter_list|,
name|NodeSet
name|contextSet
parameter_list|,
name|DocumentSet
name|docs
parameter_list|)
block|{
name|this
operator|.
name|matcher
operator|=
name|comparator
expr_stmt|;
name|this
operator|.
name|result
operator|=
name|result
expr_stmt|;
name|this
operator|.
name|docs
operator|=
name|docs
expr_stmt|;
name|this
operator|.
name|contextSet
operator|=
name|contextSet
expr_stmt|;
name|this
operator|.
name|context
operator|=
name|context
expr_stmt|;
block|}
specifier|public
name|boolean
name|indexInfo
parameter_list|(
name|Value
name|key
parameter_list|,
name|long
name|pointer
parameter_list|)
throws|throws
name|TerminatedException
block|{
name|VariableByteInput
name|is
decl_stmt|;
try|try
block|{
name|is
operator|=
name|dbTokens
operator|.
name|getAsStream
argument_list|(
name|pointer
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
name|word
operator|.
name|reuse
argument_list|()
expr_stmt|;
name|word
operator|=
name|UTF8
operator|.
name|decode
argument_list|(
name|key
operator|.
name|getData
argument_list|()
argument_list|,
literal|2
argument_list|,
name|key
operator|.
name|getLength
argument_list|()
operator|-
literal|2
argument_list|,
name|word
argument_list|)
expr_stmt|;
if|if
condition|(
name|matcher
operator|.
name|matches
argument_list|(
name|word
argument_list|)
condition|)
block|{
try|try
block|{
while|while
condition|(
name|is
operator|.
name|available
argument_list|()
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|context
operator|!=
literal|null
condition|)
name|context
operator|.
name|proceed
argument_list|()
expr_stmt|;
name|int
name|storedDocId
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
name|byte
name|storedSection
init|=
name|is
operator|.
name|readByte
argument_list|()
decl_stmt|;
name|int
name|termCount
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
comment|//TOUNDERSTAND -pb
name|int
name|size
init|=
name|is
operator|.
name|readFixedInt
argument_list|()
decl_stmt|;
name|DocumentImpl
name|storedDocument
init|=
name|docs
operator|.
name|getDoc
argument_list|(
name|storedDocId
argument_list|)
decl_stmt|;
comment|//Exit if the document is not concerned
if|if
condition|(
name|storedDocument
operator|==
literal|null
condition|)
block|{
name|is
operator|.
name|skipBytes
argument_list|(
name|size
argument_list|)
expr_stmt|;
continue|continue;
block|}
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|termCount
condition|;
name|j
operator|++
control|)
block|{
name|NodeId
name|nodeId
init|=
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getNodeFactory
argument_list|()
operator|.
name|createFromStream
argument_list|(
name|is
argument_list|)
decl_stmt|;
name|int
name|freq
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
name|NodeProxy
name|storedNode
decl_stmt|;
switch|switch
condition|(
name|storedSection
condition|)
block|{
case|case
name|TEXT_SECTION
case|:
name|storedNode
operator|=
operator|new
name|NodeProxy
argument_list|(
name|storedDocument
argument_list|,
name|nodeId
argument_list|,
name|Node
operator|.
name|TEXT_NODE
argument_list|)
expr_stmt|;
break|break;
case|case
name|ATTRIBUTE_SECTION
case|:
name|storedNode
operator|=
operator|new
name|NodeProxy
argument_list|(
name|storedDocument
argument_list|,
name|nodeId
argument_list|,
name|Node
operator|.
name|ATTRIBUTE_NODE
argument_list|)
expr_stmt|;
break|break;
default|default :
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid section type in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|)
throw|;
block|}
if|if
condition|(
name|contextSet
operator|!=
literal|null
condition|)
block|{
name|NodeProxy
name|parentNode
decl_stmt|;
switch|switch
condition|(
name|storedSection
condition|)
block|{
case|case
name|TEXT_SECTION
case|:
name|parentNode
operator|=
name|contextSet
operator|.
name|parentWithChild
argument_list|(
name|storedNode
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|,
name|NodeProxy
operator|.
name|UNKNOWN_NODE_LEVEL
argument_list|)
expr_stmt|;
break|break;
case|case
name|ATTRIBUTE_SECTION
case|:
if|if
condition|(
name|contextSet
operator|instanceof
name|VirtualNodeSet
condition|)
block|{
name|parentNode
operator|=
name|contextSet
operator|.
name|parentWithChild
argument_list|(
name|storedNode
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|,
name|NodeProxy
operator|.
name|UNKNOWN_NODE_LEVEL
argument_list|)
expr_stmt|;
if|if
condition|(
name|parentNode
operator|!=
literal|null
operator|&&
name|parentNode
operator|.
name|getNodeId
argument_list|()
operator|.
name|equals
argument_list|(
name|nodeId
argument_list|)
condition|)
name|parentNode
operator|=
literal|null
expr_stmt|;
block|}
else|else
block|{
name|parentNode
operator|=
name|contextSet
operator|.
name|get
argument_list|(
name|storedNode
argument_list|)
expr_stmt|;
block|}
break|break;
default|default :
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid section type in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|)
throw|;
block|}
if|if
condition|(
name|parentNode
operator|!=
literal|null
condition|)
block|{
name|Match
name|match
init|=
operator|new
name|Match
argument_list|(
name|nodeId
argument_list|,
name|word
operator|.
name|toString
argument_list|()
argument_list|,
name|freq
argument_list|)
decl_stmt|;
name|readOccurrences
argument_list|(
name|freq
argument_list|,
name|is
argument_list|,
name|match
argument_list|,
name|word
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
name|parentNode
operator|.
name|addMatch
argument_list|(
name|match
argument_list|)
expr_stmt|;
name|int
name|sizeHint
init|=
name|contextSet
operator|.
name|getSizeHint
argument_list|(
name|storedDocument
argument_list|)
decl_stmt|;
name|result
operator|.
name|add
argument_list|(
name|parentNode
argument_list|,
name|sizeHint
argument_list|)
expr_stmt|;
block|}
else|else
name|is
operator|.
name|skip
argument_list|(
name|freq
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Match
name|match
init|=
operator|new
name|Match
argument_list|(
literal|null
argument_list|,
name|word
operator|.
name|toString
argument_list|()
argument_list|,
name|freq
argument_list|)
decl_stmt|;
name|readOccurrences
argument_list|(
name|freq
argument_list|,
name|is
argument_list|,
name|match
argument_list|,
name|word
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
name|storedNode
operator|.
name|addMatch
argument_list|(
name|match
argument_list|)
expr_stmt|;
name|result
operator|.
name|add
argument_list|(
name|storedNode
argument_list|,
name|Constants
operator|.
name|NO_SIZE_HINT
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|//} catch (EOFException e) {
comment|// EOFExceptions are normal
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
operator|+
literal|" in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|//TODO : return early -pb
block|}
block|}
comment|//TOUNDERSTAND : why sort here ? -pb
if|if
condition|(
name|contextSet
operator|!=
literal|null
condition|)
operator|(
operator|(
name|ExtArrayNodeSet
operator|)
name|result
operator|)
operator|.
name|sort
argument_list|()
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
specifier|private
specifier|final
class|class
name|IndexScanCallback
implements|implements
name|BTreeCallback
block|{
specifier|private
name|DocumentSet
name|docs
decl_stmt|;
specifier|private
name|NodeSet
name|contextSet
decl_stmt|;
specifier|private
name|Map
name|map
init|=
operator|new
name|TreeMap
argument_list|()
decl_stmt|;
name|IndexScanCallback
parameter_list|(
name|DocumentSet
name|docs
parameter_list|,
name|NodeSet
name|contextSet
parameter_list|)
block|{
name|this
operator|.
name|docs
operator|=
name|docs
expr_stmt|;
name|this
operator|.
name|contextSet
operator|=
name|contextSet
expr_stmt|;
block|}
comment|/* (non-Javadoc) 		 * @see org.dbxml.core.filer.BTreeCallback#indexInfo(org.dbxml.core.data.Value, long) 		 */
specifier|public
name|boolean
name|indexInfo
parameter_list|(
name|Value
name|key
parameter_list|,
name|long
name|pointer
parameter_list|)
throws|throws
name|TerminatedException
block|{
name|String
name|term
decl_stmt|;
try|try
block|{
name|term
operator|=
operator|new
name|String
argument_list|(
name|key
operator|.
name|getData
argument_list|()
argument_list|,
literal|2
argument_list|,
name|key
operator|.
name|getLength
argument_list|()
operator|-
literal|2
argument_list|,
literal|"UTF-8"
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|UnsupportedEncodingException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|//term = new String(key.getData(), 2, key.getLength() - 2);
return|return
literal|true
return|;
block|}
name|VariableByteInput
name|is
decl_stmt|;
try|try
block|{
name|is
operator|=
name|dbTokens
operator|.
name|getAsStream
argument_list|(
name|pointer
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
try|try
block|{
while|while
condition|(
name|is
operator|.
name|available
argument_list|()
operator|>
literal|0
condition|)
block|{
name|boolean
name|docAdded
init|=
literal|false
decl_stmt|;
name|int
name|storedDocId
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
name|byte
name|storedSection
init|=
name|is
operator|.
name|readByte
argument_list|()
decl_stmt|;
name|int
name|termCount
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
comment|//TOUNDERSTAND -pb
name|int
name|size
init|=
name|is
operator|.
name|readFixedInt
argument_list|()
decl_stmt|;
name|DocumentImpl
name|storedDocument
init|=
name|docs
operator|.
name|getDoc
argument_list|(
name|storedDocId
argument_list|)
decl_stmt|;
comment|//Exit if the document is not concerned
if|if
condition|(
name|storedDocument
operator|==
literal|null
condition|)
block|{
name|is
operator|.
name|skipBytes
argument_list|(
name|size
argument_list|)
expr_stmt|;
continue|continue;
block|}
for|for
control|(
name|int
name|j
init|=
literal|0
init|;
name|j
operator|<
name|termCount
condition|;
name|j
operator|++
control|)
block|{
name|NodeId
name|nodeId
init|=
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getNodeFactory
argument_list|()
operator|.
name|createFromStream
argument_list|(
name|is
argument_list|)
decl_stmt|;
name|int
name|freq
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
name|is
operator|.
name|skip
argument_list|(
name|freq
argument_list|)
expr_stmt|;
if|if
condition|(
name|contextSet
operator|!=
literal|null
condition|)
block|{
name|boolean
name|include
init|=
literal|false
decl_stmt|;
name|NodeProxy
name|parentNode
init|=
name|contextSet
operator|.
name|parentWithChild
argument_list|(
name|storedDocument
argument_list|,
name|nodeId
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|)
decl_stmt|;
switch|switch
condition|(
name|storedSection
condition|)
block|{
case|case
name|TEXT_SECTION
case|:
comment|//TODO : also test on Node.TEXT_NODE like below ? -pb
name|include
operator|=
operator|(
name|parentNode
operator|!=
literal|null
operator|)
expr_stmt|;
break|break;
case|case
name|ATTRIBUTE_SECTION
case|:
name|include
operator|=
operator|(
name|parentNode
operator|!=
literal|null
operator|&&
name|parentNode
operator|.
name|getNodeType
argument_list|()
operator|==
name|Node
operator|.
name|ATTRIBUTE_NODE
operator|)
expr_stmt|;
break|break;
default|default :
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid section type  in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|)
throw|;
block|}
if|if
condition|(
name|include
condition|)
block|{
name|Occurrences
name|oc
init|=
operator|(
name|Occurrences
operator|)
name|map
operator|.
name|get
argument_list|(
name|term
argument_list|)
decl_stmt|;
if|if
condition|(
name|oc
operator|==
literal|null
condition|)
block|{
name|oc
operator|=
operator|new
name|Occurrences
argument_list|(
name|term
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
name|term
argument_list|,
name|oc
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|docAdded
condition|)
block|{
name|oc
operator|.
name|addDocument
argument_list|(
name|storedDocument
argument_list|)
expr_stmt|;
name|docAdded
operator|=
literal|true
expr_stmt|;
block|}
name|oc
operator|.
name|addOccurrences
argument_list|(
name|freq
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|//} catch(EOFException e) {
comment|//EOFExceptions are expected
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
operator|+
literal|" in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|//TODO : return early -pb
block|}
return|return
literal|true
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|OccurrenceList
block|{
specifier|private
name|NodeId
name|nodes
index|[]
init|=
operator|new
name|NodeId
index|[
literal|4
index|]
decl_stmt|;
specifier|private
name|int
name|offsets
index|[]
init|=
operator|new
name|int
index|[
literal|4
index|]
decl_stmt|;
specifier|private
name|int
name|position
init|=
literal|0
decl_stmt|;
name|void
name|add
parameter_list|(
name|NodeId
name|id
parameter_list|,
name|int
name|offset
parameter_list|)
block|{
name|ensureCapacity
argument_list|(
name|position
argument_list|)
expr_stmt|;
name|nodes
index|[
name|position
index|]
operator|=
name|id
expr_stmt|;
name|offsets
index|[
name|position
operator|++
index|]
operator|=
name|offset
expr_stmt|;
block|}
name|int
name|getSize
parameter_list|()
block|{
return|return
name|position
return|;
block|}
name|int
name|getTermCount
parameter_list|()
block|{
name|int
name|count
init|=
literal|1
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|1
init|;
name|i
operator|<
name|position
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|nodes
index|[
name|i
index|]
operator|!=
name|nodes
index|[
name|i
operator|-
literal|1
index|]
condition|)
name|count
operator|++
expr_stmt|;
block|}
return|return
name|count
return|;
block|}
name|int
name|getOccurrences
parameter_list|(
name|int
name|start
parameter_list|)
block|{
name|int
name|count
init|=
literal|1
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
name|start
operator|+
literal|1
init|;
name|i
operator|<
name|position
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|nodes
index|[
name|i
index|]
operator|==
name|nodes
index|[
name|start
index|]
condition|)
name|count
operator|++
expr_stmt|;
else|else
break|break;
block|}
return|return
name|count
return|;
block|}
name|boolean
name|contains
parameter_list|(
name|NodeId
name|id
parameter_list|)
block|{
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|position
condition|;
name|i
operator|++
control|)
if|if
condition|(
name|nodes
index|[
name|i
index|]
operator|==
name|id
condition|)
return|return
literal|true
return|;
return|return
literal|false
return|;
block|}
specifier|private
name|void
name|ensureCapacity
parameter_list|(
name|int
name|count
parameter_list|)
block|{
if|if
condition|(
name|count
operator|==
name|nodes
operator|.
name|length
condition|)
block|{
name|NodeId
index|[]
name|nn
init|=
operator|new
name|NodeId
index|[
name|count
operator|*
literal|2
index|]
decl_stmt|;
name|int
index|[]
name|no
init|=
operator|new
name|int
index|[
name|nn
operator|.
name|length
index|]
decl_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|nodes
argument_list|,
literal|0
argument_list|,
name|nn
argument_list|,
literal|0
argument_list|,
name|count
argument_list|)
expr_stmt|;
name|System
operator|.
name|arraycopy
argument_list|(
name|offsets
argument_list|,
literal|0
argument_list|,
name|no
argument_list|,
literal|0
argument_list|,
name|count
argument_list|)
expr_stmt|;
name|nodes
operator|=
name|nn
expr_stmt|;
name|offsets
operator|=
name|no
expr_stmt|;
block|}
block|}
name|void
name|sort
parameter_list|()
block|{
name|sort
argument_list|(
literal|0
argument_list|,
name|position
operator|-
literal|1
argument_list|)
expr_stmt|;
block|}
comment|/** Standard quicksort */
comment|//TODO : use methods in org.exist.util ?
specifier|private
name|void
name|sort
parameter_list|(
name|int
name|lo0
parameter_list|,
name|int
name|hi0
parameter_list|)
block|{
name|int
name|lo
init|=
name|lo0
decl_stmt|;
name|int
name|hi
init|=
name|hi0
decl_stmt|;
if|if
condition|(
name|hi0
operator|>
name|lo0
condition|)
block|{
name|int
name|mid
init|=
operator|(
name|lo0
operator|+
name|hi0
operator|)
operator|/
literal|2
decl_stmt|;
while|while
condition|(
name|lo
operator|<=
name|hi
condition|)
block|{
while|while
condition|(
operator|(
name|lo
operator|<
name|hi0
operator|)
operator|&&
operator|(
name|nodes
index|[
name|lo
index|]
operator|.
name|compareTo
argument_list|(
name|nodes
index|[
name|mid
index|]
argument_list|)
operator|<
literal|0
operator|)
condition|)
operator|++
name|lo
expr_stmt|;
while|while
condition|(
operator|(
name|hi
operator|>
name|lo0
operator|)
operator|&&
operator|(
name|nodes
index|[
name|hi
index|]
operator|.
name|compareTo
argument_list|(
name|nodes
index|[
name|mid
index|]
argument_list|)
operator|>
literal|0
operator|)
condition|)
operator|--
name|hi
expr_stmt|;
if|if
condition|(
name|lo
operator|<=
name|hi
condition|)
block|{
if|if
condition|(
name|lo
operator|!=
name|hi
condition|)
block|{
comment|// swap
name|NodeId
name|id
init|=
name|nodes
index|[
name|lo
index|]
decl_stmt|;
name|nodes
index|[
name|lo
index|]
operator|=
name|nodes
index|[
name|hi
index|]
expr_stmt|;
name|nodes
index|[
name|hi
index|]
operator|=
name|id
expr_stmt|;
name|int
name|i
init|=
name|offsets
index|[
name|lo
index|]
decl_stmt|;
name|offsets
index|[
name|lo
index|]
operator|=
name|offsets
index|[
name|hi
index|]
expr_stmt|;
name|offsets
index|[
name|hi
index|]
operator|=
name|i
expr_stmt|;
if|if
condition|(
name|lo
operator|==
name|mid
condition|)
block|{
name|mid
operator|=
name|hi
expr_stmt|;
block|}
if|else if
condition|(
name|hi
operator|==
name|mid
condition|)
block|{
name|mid
operator|=
name|lo
expr_stmt|;
block|}
block|}
operator|++
name|lo
expr_stmt|;
operator|--
name|hi
expr_stmt|;
block|}
block|}
if|if
condition|(
name|lo0
operator|<
name|hi
condition|)
name|sort
argument_list|(
name|lo0
argument_list|,
name|hi
argument_list|)
expr_stmt|;
if|if
condition|(
name|lo
operator|<
name|hi0
condition|)
name|sort
argument_list|(
name|lo
argument_list|,
name|hi0
argument_list|)
expr_stmt|;
block|}
block|}
block|}
specifier|private
specifier|static
class|class
name|TermFrequencyList
block|{
specifier|protected
specifier|static
class|class
name|TermFreq
implements|implements
name|Comparable
block|{
name|long
name|l
decl_stmt|;
name|int
name|count
init|=
literal|1
decl_stmt|;
name|TermFreq
name|next
init|=
literal|null
decl_stmt|;
specifier|public
name|TermFreq
parameter_list|(
name|long
name|l
parameter_list|)
block|{
name|this
operator|.
name|l
operator|=
name|l
expr_stmt|;
block|}
specifier|public
name|void
name|increment
parameter_list|()
block|{
operator|++
name|count
expr_stmt|;
block|}
specifier|public
name|int
name|compareTo
parameter_list|(
name|Object
name|o
parameter_list|)
block|{
specifier|final
name|TermFreq
name|other
init|=
operator|(
name|TermFreq
operator|)
name|o
decl_stmt|;
if|if
condition|(
name|l
operator|==
name|other
operator|.
name|l
condition|)
return|return
name|Constants
operator|.
name|EQUAL
return|;
else|else
return|return
name|l
operator|<
name|other
operator|.
name|l
condition|?
name|Constants
operator|.
name|INFERIOR
else|:
name|Constants
operator|.
name|SUPERIOR
return|;
block|}
block|}
specifier|private
name|TermFreq
name|first
init|=
literal|null
decl_stmt|;
specifier|private
name|TermFreq
name|last
init|=
literal|null
decl_stmt|;
specifier|private
name|int
name|count
init|=
literal|0
decl_stmt|;
specifier|public
name|void
name|add
parameter_list|(
name|long
name|l
parameter_list|)
block|{
if|if
condition|(
name|first
operator|==
literal|null
condition|)
block|{
name|first
operator|=
operator|new
name|TermFreq
argument_list|(
name|l
argument_list|)
expr_stmt|;
name|last
operator|=
name|first
expr_stmt|;
block|}
else|else
block|{
name|TermFreq
name|next
init|=
operator|new
name|TermFreq
argument_list|(
name|l
argument_list|)
decl_stmt|;
name|last
operator|.
name|next
operator|=
name|next
expr_stmt|;
name|last
operator|=
name|next
expr_stmt|;
block|}
operator|++
name|count
expr_stmt|;
block|}
specifier|public
name|void
name|incLastTerm
parameter_list|()
block|{
if|if
condition|(
name|last
operator|!=
literal|null
condition|)
name|last
operator|.
name|increment
argument_list|()
expr_stmt|;
block|}
specifier|public
name|void
name|setLastTermFreq
parameter_list|(
name|int
name|freq
parameter_list|)
block|{
if|if
condition|(
name|last
operator|!=
literal|null
condition|)
name|last
operator|.
name|count
operator|=
name|freq
expr_stmt|;
block|}
specifier|public
name|long
name|getLast
parameter_list|()
block|{
if|if
condition|(
name|last
operator|!=
literal|null
condition|)
return|return
name|last
operator|.
name|l
return|;
else|else
return|return
operator|-
literal|1
return|;
block|}
specifier|public
name|boolean
name|contains
parameter_list|(
name|long
name|l
parameter_list|)
block|{
name|TermFreq
name|next
init|=
name|first
decl_stmt|;
while|while
condition|(
name|next
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|next
operator|.
name|l
operator|==
name|l
condition|)
return|return
literal|true
return|;
name|next
operator|=
name|next
operator|.
name|next
expr_stmt|;
block|}
return|return
literal|false
return|;
block|}
specifier|public
name|int
name|getSize
parameter_list|()
block|{
return|return
name|count
return|;
block|}
specifier|public
name|TermFreq
index|[]
name|toArray
parameter_list|()
block|{
name|TermFreq
index|[]
name|data
init|=
operator|new
name|TermFreq
index|[
name|count
index|]
decl_stmt|;
name|TermFreq
name|next
init|=
name|first
decl_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|next
operator|!=
literal|null
condition|)
block|{
name|data
index|[
name|i
operator|++
index|]
operator|=
name|next
expr_stmt|;
name|next
operator|=
name|next
operator|.
name|next
expr_stmt|;
block|}
return|return
name|data
return|;
block|}
block|}
specifier|private
specifier|final
specifier|static
class|class
name|WordRef
extends|extends
name|Value
block|{
specifier|public
name|WordRef
parameter_list|(
name|short
name|collectionId
parameter_list|)
block|{
name|data
operator|=
operator|new
name|byte
index|[
literal|2
index|]
expr_stmt|;
name|ByteConversion
operator|.
name|shortToByte
argument_list|(
name|collectionId
argument_list|,
name|data
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|len
operator|=
literal|2
expr_stmt|;
block|}
specifier|public
name|WordRef
parameter_list|(
name|short
name|collectionId
parameter_list|,
name|String
name|word
parameter_list|)
block|{
name|len
operator|=
name|UTF8
operator|.
name|encoded
argument_list|(
name|word
argument_list|)
operator|+
literal|2
expr_stmt|;
name|data
operator|=
operator|new
name|byte
index|[
name|len
index|]
expr_stmt|;
name|ByteConversion
operator|.
name|shortToByte
argument_list|(
name|collectionId
argument_list|,
name|data
argument_list|,
literal|0
argument_list|)
expr_stmt|;
name|UTF8
operator|.
name|encode
argument_list|(
name|word
argument_list|,
name|data
argument_list|,
literal|2
argument_list|)
expr_stmt|;
block|}
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|ByteConversion
operator|.
name|byteToShort
argument_list|(
name|data
argument_list|,
name|pos
argument_list|)
operator|+
operator|new
name|String
argument_list|(
name|data
argument_list|,
name|pos
argument_list|,
name|len
argument_list|)
return|;
block|}
block|}
block|}
end_class

end_unit

