begin_unit|revision:1.0.0;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  *  eXist Open Source Native XML Database  *  Copyright (C) 2001-07 The eXist Project  *  http://exist-db.org  *    *  This program is free software; you can redistribute it and/or  *  modify it under the terms of the GNU Lesser General Public License  *  as published by the Free Software Foundation; either version 2  *  of the License, or (at your option) any later version.  *    *  This program is distributed in the hope that it will be useful,  *  but WITHOUT ANY WARRANTY; without even the implied warranty of  *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the  *  GNU Lesser General Public License for more details.  *    *  You should have received a copy of the GNU Lesser General Public License  *  along with this program; if not, write to the Free Software  *  Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.  *    *  $Id$  */
end_comment

begin_package
package|package
name|org
operator|.
name|exist
operator|.
name|storage
package|;
end_package

begin_comment
comment|//import java.io.EOFException;
end_comment

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|EXistException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|collections
operator|.
name|Collection
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|dom
operator|.
name|*
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|fulltext
operator|.
name|ElementContent
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|fulltext
operator|.
name|FTMatch
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|numbering
operator|.
name|NodeId
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|security
operator|.
name|PermissionDeniedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|analysis
operator|.
name|TextToken
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|btree
operator|.
name|BTreeCallback
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|btree
operator|.
name|BTreeException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|btree
operator|.
name|DBException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|btree
operator|.
name|IndexQuery
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|btree
operator|.
name|Value
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|index
operator|.
name|BFile
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|io
operator|.
name|VariableByteArrayInput
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|io
operator|.
name|VariableByteInput
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|io
operator|.
name|VariableByteOutputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|lock
operator|.
name|Lock
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|ByteArray
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|ByteConversion
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|Configuration
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|LockException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|Occurrences
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|ProgressIndicator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|ReadOnlyException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|UTF8
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|XMLString
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|xquery
operator|.
name|Constants
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|xquery
operator|.
name|TerminatedException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|xquery
operator|.
name|XQueryContext
import|;
end_import

begin_import
import|import
name|org
operator|.
name|w3c
operator|.
name|dom
operator|.
name|Node
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|UnsupportedEncodingException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|ArrayList
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|HashMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Iterator
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|List
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Map
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|Set
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|TreeMap
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|regex
operator|.
name|Pattern
import|;
end_import

begin_comment
comment|/**  * This class is responsible for fulltext-indexing. Text-nodes are handed over  * to this class to be fulltext-indexed. Method storeText() is called by  * RelationalBroker whenever it finds a TextNode. Method getNodeIDsContaining()  * is used by the XPath-engine to process queries where a fulltext-operator is  * involved. The class keeps two database tables: table<code>dbTokens</code> stores the words  * found with their unique id. Table<code>invertedIndex</code> contains the word occurrences for  * every word-id per document.  *   * TODO: store node type (attribute or text) with each entry  *   * @author Wolfgang Meier  */
end_comment

begin_class
specifier|public
class|class
name|NativeTextEngine
extends|extends
name|TextSearchEngine
implements|implements
name|ContentLoadingObserver
block|{
specifier|public
specifier|static
specifier|final
name|String
name|FILE_NAME
init|=
literal|"words.dbx"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|String
name|FILE_KEY_IN_CONFIG
init|=
literal|"db-connection.words"
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|double
name|DEFAULT_WORD_CACHE_GROWTH
init|=
literal|1.4
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|double
name|DEFAULT_WORD_KEY_THRESHOLD
init|=
literal|0.01
decl_stmt|;
specifier|public
specifier|static
specifier|final
name|double
name|DEFAULT_WORD_VALUE_THRESHOLD
init|=
literal|0.015
decl_stmt|;
specifier|public
specifier|final
specifier|static
name|byte
name|TEXT_SECTION
init|=
literal|0
decl_stmt|;
specifier|public
specifier|final
specifier|static
name|byte
name|ATTRIBUTE_SECTION
init|=
literal|1
decl_stmt|;
specifier|public
specifier|final
specifier|static
name|byte
name|QNAME_SECTION
init|=
literal|2
decl_stmt|;
specifier|private
specifier|final
specifier|static
name|byte
name|IDX_GENERIC
init|=
literal|0
decl_stmt|;
specifier|private
specifier|final
specifier|static
name|byte
name|IDX_QNAME
init|=
literal|1
decl_stmt|;
specifier|public
specifier|static
name|int
name|ATTRIBUTE_BY_QNAME
init|=
literal|0
decl_stmt|;
specifier|public
specifier|static
name|int
name|ATTRIBUTE_NOT_BY_QNAME
init|=
literal|1
decl_stmt|;
specifier|public
specifier|static
name|int
name|TOKENIZE
init|=
literal|0
decl_stmt|;
specifier|public
specifier|static
name|int
name|DO_NOT_TOKENIZE
init|=
literal|1
decl_stmt|;
specifier|public
specifier|static
name|int
name|TEXT_BY_QNAME
init|=
literal|2
decl_stmt|;
specifier|public
specifier|static
name|int
name|FOURTH_OPTION
init|=
literal|3
decl_stmt|;
specifier|public
specifier|final
specifier|static
name|int
name|LENGTH_NODE_TYPE
init|=
literal|1
decl_stmt|;
comment|//sizeof byte
specifier|public
specifier|final
specifier|static
name|int
name|LENGTH_NODE_IDS_FREQ_OFFSETS
init|=
literal|4
decl_stmt|;
comment|//sizeof int
specifier|public
specifier|final
specifier|static
name|int
name|OFFSET_NODE_TYPE
init|=
literal|0
decl_stmt|;
specifier|public
specifier|final
specifier|static
name|int
name|OFFSET_ELEMENT_CHILDREN_COUNT
init|=
name|OFFSET_NODE_TYPE
operator|+
name|LENGTH_NODE_TYPE
decl_stmt|;
comment|//1
specifier|public
specifier|final
specifier|static
name|int
name|OFFSET_ATTRIBUTE_DLN_LENGTH
init|=
name|OFFSET_NODE_TYPE
operator|+
name|LENGTH_NODE_TYPE
decl_stmt|;
comment|//1
specifier|public
specifier|final
specifier|static
name|int
name|OFFSET_TEXT_DLN_LENGTH
init|=
name|OFFSET_NODE_TYPE
operator|+
name|LENGTH_NODE_TYPE
decl_stmt|;
comment|//1
specifier|public
specifier|final
specifier|static
name|int
name|OFFSET_DLN
init|=
name|OFFSET_TEXT_DLN_LENGTH
operator|+
name|NodeId
operator|.
name|LENGTH_NODE_ID_UNITS
decl_stmt|;
comment|//3
comment|/** Length limit for the tokens */
specifier|public
specifier|final
specifier|static
name|int
name|MAX_TOKEN_LENGTH
init|=
literal|2048
decl_stmt|;
comment|/** The datastore for this token index */
specifier|protected
name|BFile
name|dbTokens
decl_stmt|;
specifier|protected
name|InvertedIndex
name|invertedIndex
decl_stmt|;
comment|/** The current document */
specifier|private
name|DocumentImpl
name|doc
decl_stmt|;
comment|/** Work output Stream that should be cleared before every use */
specifier|private
name|VariableByteOutputStream
name|os
init|=
operator|new
name|VariableByteOutputStream
argument_list|(
literal|7
argument_list|)
decl_stmt|;
specifier|public
name|NativeTextEngine
parameter_list|(
name|DBBroker
name|broker
parameter_list|,
name|BFile
name|dbFile
parameter_list|,
name|Configuration
name|config
parameter_list|)
throws|throws
name|DBException
block|{
name|super
argument_list|(
name|broker
argument_list|,
name|config
argument_list|)
expr_stmt|;
name|this
operator|.
name|invertedIndex
operator|=
operator|new
name|InvertedIndex
argument_list|()
expr_stmt|;
name|this
operator|.
name|dbTokens
operator|=
name|dbFile
expr_stmt|;
block|}
specifier|public
name|String
name|getFileName
parameter_list|()
block|{
return|return
name|FILE_NAME
return|;
block|}
specifier|public
name|String
name|getConfigKeyForFile
parameter_list|()
block|{
return|return
name|FILE_KEY_IN_CONFIG
return|;
block|}
specifier|public
name|NativeTextEngine
name|getInstance
parameter_list|()
block|{
return|return
name|this
return|;
block|}
comment|/** 	 * Checks if the given string could be a regular expression. 	 *  	 * @param str The string 	 */
specifier|public
specifier|final
specifier|static
name|boolean
name|containsWildcards
parameter_list|(
name|String
name|str
parameter_list|)
block|{
if|if
condition|(
name|str
operator|==
literal|null
operator|||
name|str
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
return|return
literal|false
return|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|str
operator|.
name|length
argument_list|()
condition|;
name|i
operator|++
control|)
switch|switch
condition|(
name|str
operator|.
name|charAt
argument_list|(
name|i
argument_list|)
condition|)
block|{
case|case
literal|'*'
case|:
case|case
literal|'?'
case|:
case|case
literal|'\\'
case|:
case|case
literal|'['
case|:
case|case
literal|']'
case|:
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
specifier|public
specifier|final
specifier|static
name|boolean
name|startsWithWildcard
parameter_list|(
name|String
name|str
parameter_list|)
block|{
if|if
condition|(
name|str
operator|==
literal|null
operator|||
name|str
operator|.
name|length
argument_list|()
operator|==
literal|0
condition|)
return|return
literal|false
return|;
switch|switch
condition|(
name|str
operator|.
name|charAt
argument_list|(
literal|0
argument_list|)
condition|)
block|{
case|case
literal|'*'
case|:
case|case
literal|'?'
case|:
case|case
literal|'\\'
case|:
case|case
literal|'['
case|:
return|return
literal|true
return|;
block|}
return|return
literal|false
return|;
block|}
specifier|public
name|int
name|getTrackMatches
parameter_list|()
block|{
return|return
name|trackMatches
return|;
block|}
specifier|public
name|void
name|setTrackMatches
parameter_list|(
name|int
name|flags
parameter_list|)
block|{
name|trackMatches
operator|=
name|flags
expr_stmt|;
block|}
specifier|public
name|void
name|setDocument
parameter_list|(
name|DocumentImpl
name|document
parameter_list|)
block|{
if|if
condition|(
name|this
operator|.
name|doc
operator|!=
literal|null
operator|&&
name|this
operator|.
name|doc
operator|.
name|getDocId
argument_list|()
operator|!=
name|document
operator|.
name|getDocId
argument_list|()
condition|)
name|flush
argument_list|()
expr_stmt|;
name|this
operator|.
name|doc
operator|=
name|document
expr_stmt|;
name|invertedIndex
operator|.
name|setDocument
argument_list|(
name|doc
argument_list|)
expr_stmt|;
block|}
comment|/**      * Indexes the tokens contained in an attribute.      *       * @param node The attribute to be indexed      */
comment|//TODO : unify functionalities with storeText -pb
specifier|public
name|void
name|storeAttribute
parameter_list|(
name|AttrImpl
name|node
parameter_list|,
name|NodePath
name|currentPath
parameter_list|,
name|int
name|indexingHint
parameter_list|,
name|FulltextIndexSpec
name|indexSpec
parameter_list|,
name|boolean
name|remove
parameter_list|)
block|{
if|if
condition|(
operator|(
name|indexingHint
operator|&
name|ATTRIBUTE_BY_QNAME
operator|)
operator|==
name|ATTRIBUTE_BY_QNAME
operator|||
operator|(
name|indexingHint
operator|&
name|ATTRIBUTE_NOT_BY_QNAME
operator|)
operator|==
name|ATTRIBUTE_NOT_BY_QNAME
condition|)
block|{
comment|//final DocumentImpl doc = (DocumentImpl)node.getOwnerDocument();
comment|//TODO : case conversion should be handled by the tokenizer -pb
name|tokenizer
operator|.
name|setText
argument_list|(
name|node
operator|.
name|getValue
argument_list|()
operator|.
name|toLowerCase
argument_list|()
argument_list|)
expr_stmt|;
name|TextToken
name|token
decl_stmt|;
while|while
condition|(
literal|null
operator|!=
operator|(
name|token
operator|=
name|tokenizer
operator|.
name|nextToken
argument_list|()
operator|)
condition|)
block|{
if|if
condition|(
name|token
operator|.
name|length
argument_list|()
operator|>
name|MAX_TOKEN_LENGTH
condition|)
block|{
comment|//	            	LOG.warn("Token length exceeded " + MAX_TOKEN_LENGTH + ": " + token.getText().substring(0,20) + "...");
continue|continue;
block|}
if|if
condition|(
name|stoplist
operator|.
name|contains
argument_list|(
name|token
argument_list|)
condition|)
block|{
continue|continue;
block|}
comment|//TODO : the tokenizer should strip unwanted token types itself -pb
if|if
condition|(
operator|!
name|token
operator|.
name|isAlpha
argument_list|()
operator|&&
name|indexSpec
operator|!=
literal|null
operator|&&
operator|!
name|indexSpec
operator|.
name|getIncludeAlphaNum
argument_list|()
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|indexingHint
operator|==
name|ATTRIBUTE_BY_QNAME
condition|)
name|invertedIndex
operator|.
name|addAttribute
argument_list|(
name|token
argument_list|,
name|node
argument_list|,
name|remove
argument_list|)
expr_stmt|;
else|else
name|invertedIndex
operator|.
name|addAttribute
argument_list|(
name|token
argument_list|,
name|node
operator|.
name|getNodeId
argument_list|()
argument_list|,
name|remove
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|//TODO : unify with above choosing one of these 2 strategies :
comment|//1) compute the indexing strategy from thhe broker (introduce some kind of dependency)
comment|//2) read the configuration from the indexer (possible performance loss)
specifier|public
name|void
name|storeAttribute
parameter_list|(
name|AttrImpl
name|node
parameter_list|,
name|NodePath
name|currentPath
parameter_list|,
name|int
name|indexingHint
parameter_list|,
name|RangeIndexSpec
name|idx
parameter_list|,
name|boolean
name|remove
parameter_list|)
block|{
block|}
comment|/**      * Indexes the tokens contained in a text node.      *       * @param indexSpec The index configuration      * @param node The text node to be indexed      * @param indexingHint      *                if<code>true</code>, given text is indexed as a single token      *                if<code>false</code>, it is tokenized before being indexed      */
comment|//TODO : use an indexSpec member in order to get rid of<code>noTokenizing</code>
specifier|public
name|void
name|storeText
parameter_list|(
name|CharacterDataImpl
name|node
parameter_list|,
name|int
name|indexingHint
parameter_list|,
name|FulltextIndexSpec
name|indexSpec
parameter_list|,
name|boolean
name|remove
parameter_list|)
block|{
if|if
condition|(
name|indexingHint
operator|==
name|TOKENIZE
operator|||
name|indexingHint
operator|==
name|DO_NOT_TOKENIZE
condition|)
block|{
comment|//final DocumentImpl doc = (DocumentImpl)node.getOwnerDocument();
comment|//TODO : case conversion should be handled by the tokenizer -pb
specifier|final
name|XMLString
name|t
init|=
name|node
operator|.
name|getXMLString
argument_list|()
operator|.
name|transformToLower
argument_list|()
decl_stmt|;
name|TextToken
name|token
decl_stmt|;
if|if
condition|(
name|indexingHint
operator|==
name|DO_NOT_TOKENIZE
condition|)
block|{
name|token
operator|=
operator|new
name|TextToken
argument_list|(
name|TextToken
operator|.
name|ALPHA
argument_list|,
name|t
argument_list|,
literal|0
argument_list|,
name|t
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
comment|//invertedIndex.setDocument(doc);
name|invertedIndex
operator|.
name|addText
argument_list|(
name|token
argument_list|,
name|node
operator|.
name|getNodeId
argument_list|()
argument_list|,
name|remove
argument_list|)
expr_stmt|;
block|}
if|else if
condition|(
name|indexingHint
operator|==
name|TOKENIZE
condition|)
block|{
name|tokenizer
operator|.
name|setText
argument_list|(
name|t
argument_list|)
expr_stmt|;
while|while
condition|(
literal|null
operator|!=
operator|(
name|token
operator|=
name|tokenizer
operator|.
name|nextToken
argument_list|()
operator|)
condition|)
block|{
if|if
condition|(
name|token
operator|.
name|length
argument_list|()
operator|>
name|MAX_TOKEN_LENGTH
condition|)
block|{
comment|//	                	LOG.warn("Token length exceeded " + MAX_TOKEN_LENGTH + ": " + token.getText().substring(0,20) + "...");
continue|continue;
block|}
if|if
condition|(
name|stoplist
operator|.
name|contains
argument_list|(
name|token
argument_list|)
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|indexSpec
operator|!=
literal|null
condition|)
block|{
comment|//TODO : the tokenizer should strip unwanted token types itself -pb
if|if
condition|(
operator|!
name|indexSpec
operator|.
name|getIncludeAlphaNum
argument_list|()
operator|&&
operator|!
name|token
operator|.
name|isAlpha
argument_list|()
condition|)
block|{
continue|continue;
block|}
block|}
comment|//invertedIndex.setDocument(doc);
name|invertedIndex
operator|.
name|addText
argument_list|(
name|token
argument_list|,
name|node
operator|.
name|getNodeId
argument_list|()
argument_list|,
name|remove
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
specifier|public
name|void
name|storeText
parameter_list|(
name|StoredNode
name|parent
parameter_list|,
name|ElementContent
name|text
parameter_list|,
name|int
name|indexingHint
parameter_list|,
name|FulltextIndexSpec
name|indexSpec
parameter_list|,
name|boolean
name|remove
parameter_list|)
block|{
comment|//final DocumentImpl doc = (DocumentImpl)parent.getOwnerDocument();
comment|//TODO : case conversion should be handled by the tokenizer -pb
name|TextToken
name|token
decl_stmt|;
name|ElementContent
operator|.
name|TextSpan
name|span
init|=
name|text
operator|.
name|getFirst
argument_list|()
decl_stmt|;
name|XMLString
name|data
init|=
literal|null
decl_stmt|;
name|int
name|currentOffset
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|span
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|data
operator|==
literal|null
condition|)
name|data
operator|=
name|span
operator|.
name|getContent
argument_list|()
operator|.
name|transformToLower
argument_list|()
expr_stmt|;
else|else
block|{
name|currentOffset
operator|=
name|data
operator|.
name|length
argument_list|()
expr_stmt|;
name|data
operator|.
name|append
argument_list|(
name|span
operator|.
name|getContent
argument_list|()
operator|.
name|transformToLower
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|tokenizer
operator|.
name|setText
argument_list|(
name|data
argument_list|,
name|currentOffset
argument_list|)
expr_stmt|;
while|while
condition|(
literal|null
operator|!=
operator|(
name|token
operator|=
name|tokenizer
operator|.
name|nextToken
argument_list|()
operator|)
condition|)
block|{
if|if
condition|(
name|token
operator|.
name|length
argument_list|()
operator|>
name|MAX_TOKEN_LENGTH
condition|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Token length exceeded "
operator|+
name|MAX_TOKEN_LENGTH
operator|+
literal|": "
operator|+
name|token
operator|.
name|getText
argument_list|()
operator|.
name|substring
argument_list|(
literal|0
argument_list|,
literal|20
argument_list|)
operator|+
literal|"..."
argument_list|)
expr_stmt|;
continue|continue;
block|}
if|if
condition|(
name|stoplist
operator|.
name|contains
argument_list|(
name|token
argument_list|)
condition|)
block|{
continue|continue;
block|}
if|if
condition|(
name|indexSpec
operator|!=
literal|null
condition|)
block|{
comment|//TODO : the tokenizer should strip unwanted token types itself -pb
if|if
condition|(
operator|!
name|indexSpec
operator|.
name|getIncludeAlphaNum
argument_list|()
operator|&&
operator|!
name|token
operator|.
name|isAlpha
argument_list|()
condition|)
block|{
continue|continue;
block|}
block|}
comment|//invertedIndex.setDocument(doc);
if|if
condition|(
name|indexingHint
operator|==
name|TEXT_BY_QNAME
condition|)
name|invertedIndex
operator|.
name|addText
argument_list|(
name|token
argument_list|,
operator|(
name|ElementImpl
operator|)
name|parent
argument_list|,
name|remove
argument_list|)
expr_stmt|;
else|else
name|invertedIndex
operator|.
name|addText
argument_list|(
name|token
argument_list|,
name|parent
operator|.
name|getNodeId
argument_list|()
argument_list|,
name|remove
argument_list|)
expr_stmt|;
block|}
name|span
operator|=
name|span
operator|.
name|getNext
argument_list|()
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|storeText
parameter_list|(
name|TextImpl
name|node
parameter_list|,
name|NodePath
name|currentPath
parameter_list|,
name|int
name|indexingHint
parameter_list|)
block|{
comment|// TODO Auto-generated method stub
block|}
specifier|public
name|void
name|removeNode
parameter_list|(
name|StoredNode
name|node
parameter_list|,
name|NodePath
name|currentPath
parameter_list|,
name|String
name|content
parameter_list|)
block|{
comment|// TODO Auto-generated method stub
block|}
comment|/* (non-Javadoc)      * @see org.exist.storage.ContentLoadingObserver#sync()      */
specifier|public
name|void
name|sync
parameter_list|()
block|{
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|(
name|Lock
operator|.
name|WRITE_LOCK
argument_list|)
expr_stmt|;
name|dbTokens
operator|.
name|flush
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|//TODO : throw an exception ? -pb
block|}
catch|catch
parameter_list|(
name|DBException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|//TODO : throw an exception ? -pb
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|(
name|Lock
operator|.
name|WRITE_LOCK
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* (non-Javadoc)      * @see org.exist.storage.ContentLoadingObserver#flush()      */
specifier|public
name|void
name|flush
parameter_list|()
block|{
name|invertedIndex
operator|.
name|flush
argument_list|()
expr_stmt|;
block|}
specifier|public
name|void
name|remove
parameter_list|()
block|{
name|invertedIndex
operator|.
name|remove
argument_list|()
expr_stmt|;
block|}
comment|/* Drop all index entries for the given collection.      * @see org.exist.storage.ContentLoadingObserver#dropIndex(org.exist.collections.Collection)      */
specifier|public
name|void
name|dropIndex
parameter_list|(
name|Collection
name|collection
parameter_list|)
block|{
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|(
name|Lock
operator|.
name|WRITE_LOCK
argument_list|)
expr_stmt|;
comment|// remove generic index
name|Value
name|value
init|=
operator|new
name|WordRef
argument_list|(
name|collection
operator|.
name|getId
argument_list|()
argument_list|)
decl_stmt|;
name|dbTokens
operator|.
name|removeAll
argument_list|(
literal|null
argument_list|,
operator|new
name|IndexQuery
argument_list|(
name|IndexQuery
operator|.
name|TRUNC_RIGHT
argument_list|,
name|value
argument_list|)
argument_list|)
expr_stmt|;
comment|// remove QName index
name|value
operator|=
operator|new
name|QNameWordRef
argument_list|(
name|collection
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
name|dbTokens
operator|.
name|removeAll
argument_list|(
literal|null
argument_list|,
operator|new
name|IndexQuery
argument_list|(
name|IndexQuery
operator|.
name|TRUNC_RIGHT
argument_list|,
name|value
argument_list|)
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|BTreeException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|(
name|Lock
operator|.
name|WRITE_LOCK
argument_list|)
expr_stmt|;
block|}
block|}
comment|/* Drop all index entries for the given document.      * @see org.exist.storage.ContentLoadingObserver#dropIndex(org.exist.dom.DocumentImpl)      */
specifier|public
name|void
name|dropIndex
parameter_list|(
name|DocumentImpl
name|document
parameter_list|)
block|{
name|invertedIndex
operator|.
name|dropIndex
argument_list|(
name|document
argument_list|)
expr_stmt|;
block|}
specifier|public
name|NodeSet
name|getNodesContaining
parameter_list|(
name|XQueryContext
name|context
parameter_list|,
name|DocumentSet
name|docs
parameter_list|,
name|NodeSet
name|contextSet
parameter_list|,
name|int
name|axis
parameter_list|,
name|QName
name|qname
parameter_list|,
name|String
name|expr
parameter_list|,
name|int
name|type
parameter_list|,
name|boolean
name|matchAll
parameter_list|)
throws|throws
name|TerminatedException
block|{
if|if
condition|(
name|type
operator|==
name|DBBroker
operator|.
name|MATCH_EXACT
operator|&&
name|containsWildcards
argument_list|(
name|expr
argument_list|)
condition|)
block|{
comment|//TODO : log this fallback ? -pb
name|type
operator|=
name|DBBroker
operator|.
name|MATCH_WILDCARDS
expr_stmt|;
block|}
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|DBBroker
operator|.
name|MATCH_EXACT
case|:
return|return
name|getNodesExact
argument_list|(
name|context
argument_list|,
name|docs
argument_list|,
name|contextSet
argument_list|,
name|axis
argument_list|,
name|qname
argument_list|,
name|expr
argument_list|)
return|;
comment|//TODO : stricter control -pb
default|default :
return|return
name|getNodesRegexp
argument_list|(
name|context
argument_list|,
name|docs
argument_list|,
name|contextSet
argument_list|,
name|axis
argument_list|,
name|qname
argument_list|,
name|expr
argument_list|,
name|type
argument_list|,
name|matchAll
argument_list|)
return|;
block|}
block|}
comment|/**           * Get all nodes whose content exactly matches the give expression. 	 */
specifier|public
name|NodeSet
name|getNodesExact
parameter_list|(
name|XQueryContext
name|context
parameter_list|,
name|DocumentSet
name|docs
parameter_list|,
name|NodeSet
name|contextSet
parameter_list|,
name|int
name|axis
parameter_list|,
name|QName
name|qname
parameter_list|,
name|String
name|expr
parameter_list|)
throws|throws
name|TerminatedException
block|{
comment|//Return early
if|if
condition|(
name|expr
operator|==
literal|null
condition|)
return|return
literal|null
return|;
comment|//TODO : filter the expression *before* -pb
if|if
condition|(
name|stoplist
operator|.
name|contains
argument_list|(
name|expr
argument_list|)
condition|)
return|return
literal|null
return|;
comment|//TODO : case conversion should be handled by the tokenizer -pb
name|expr
operator|=
name|expr
operator|.
name|toLowerCase
argument_list|()
expr_stmt|;
comment|//TODO : use an indexSpec member in order to get rid of this or do the job *before* -pb
name|String
name|token
decl_stmt|;
if|if
condition|(
name|stem
condition|)
name|token
operator|=
name|stemmer
operator|.
name|stem
argument_list|(
name|expr
argument_list|)
expr_stmt|;
else|else
name|token
operator|=
name|expr
expr_stmt|;
specifier|final
name|NodeSet
name|result
init|=
operator|new
name|NewArrayNodeSet
argument_list|(
name|docs
operator|.
name|getDocumentCount
argument_list|()
argument_list|,
literal|250
argument_list|)
decl_stmt|;
for|for
control|(
name|Iterator
argument_list|<
name|Collection
argument_list|>
name|iter
init|=
name|docs
operator|.
name|getCollectionIterator
argument_list|()
init|;
name|iter
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
specifier|final
name|int
name|collectionId
init|=
operator|(
name|iter
operator|.
name|next
argument_list|()
operator|)
operator|.
name|getId
argument_list|()
decl_stmt|;
name|Value
name|key
decl_stmt|;
if|if
condition|(
name|qname
operator|==
literal|null
condition|)
name|key
operator|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|,
name|token
argument_list|)
expr_stmt|;
else|else
block|{
name|key
operator|=
operator|new
name|QNameWordRef
argument_list|(
name|collectionId
argument_list|,
name|qname
argument_list|,
name|token
argument_list|,
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getSymbols
argument_list|()
argument_list|)
expr_stmt|;
comment|//                LOG.debug("Using qname: " + qname.toString() + " " + key.dump() + " '" + key.toString() + "'");
block|}
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|(
name|Lock
operator|.
name|READ_LOCK
argument_list|)
expr_stmt|;
name|VariableByteInput
name|is
init|=
name|dbTokens
operator|.
name|getAsStream
argument_list|(
name|key
argument_list|)
decl_stmt|;
comment|//Does the token already has data in the index ?
if|if
condition|(
name|is
operator|==
literal|null
condition|)
continue|continue;
while|while
condition|(
name|is
operator|.
name|available
argument_list|()
operator|>
literal|0
condition|)
block|{
name|int
name|storedDocId
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
name|int
name|storedSection
init|=
name|is
operator|.
name|readByte
argument_list|()
decl_stmt|;
name|int
name|gidsCount
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
comment|//Read (variable) length of node IDs + frequency + offsets
name|int
name|length
init|=
name|is
operator|.
name|readFixedInt
argument_list|()
decl_stmt|;
name|DocumentImpl
name|storedDocument
init|=
name|docs
operator|.
name|getDoc
argument_list|(
name|storedDocId
argument_list|)
decl_stmt|;
comment|//Exit if the document is not concerned
if|if
condition|(
name|storedDocument
operator|==
literal|null
condition|)
block|{
name|is
operator|.
name|skipBytes
argument_list|(
name|length
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|//Process the nodes
name|NodeId
name|previous
init|=
literal|null
decl_stmt|;
for|for
control|(
name|int
name|m
init|=
literal|0
init|;
name|m
operator|<
name|gidsCount
condition|;
name|m
operator|++
control|)
block|{
comment|//                        NodeId nodeId = broker.getBrokerPool().getNodeFactory().createFromStream(is);
name|NodeId
name|nodeId
init|=
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getNodeFactory
argument_list|()
operator|.
name|createFromStream
argument_list|(
name|previous
argument_list|,
name|is
argument_list|)
decl_stmt|;
name|previous
operator|=
name|nodeId
expr_stmt|;
name|int
name|freq
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
name|NodeProxy
name|storedNode
decl_stmt|;
switch|switch
condition|(
name|storedSection
condition|)
block|{
case|case
name|ATTRIBUTE_SECTION
case|:
name|storedNode
operator|=
operator|new
name|NodeProxy
argument_list|(
name|storedDocument
argument_list|,
name|nodeId
argument_list|,
name|Node
operator|.
name|ATTRIBUTE_NODE
argument_list|)
expr_stmt|;
break|break;
case|case
name|TEXT_SECTION
case|:
name|storedNode
operator|=
operator|new
name|NodeProxy
argument_list|(
name|storedDocument
argument_list|,
name|nodeId
argument_list|,
name|Node
operator|.
name|TEXT_NODE
argument_list|)
expr_stmt|;
break|break;
case|case
name|QNAME_SECTION
case|:
name|storedNode
operator|=
operator|new
name|NodeProxy
argument_list|(
name|storedDocument
argument_list|,
name|nodeId
argument_list|,
name|qname
operator|.
name|getNameType
argument_list|()
operator|==
name|ElementValue
operator|.
name|ATTRIBUTE
condition|?
name|Node
operator|.
name|ATTRIBUTE_NODE
else|:
name|Node
operator|.
name|ELEMENT_NODE
argument_list|)
expr_stmt|;
break|break;
default|default :
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid section type in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|)
throw|;
block|}
comment|// if a context set is specified, we can directly check if the
comment|// matching text node is a descendant of one of the nodes
comment|// in the context set.
if|if
condition|(
name|contextSet
operator|!=
literal|null
condition|)
block|{
name|NodeProxy
name|parent
decl_stmt|;
switch|switch
condition|(
name|storedSection
condition|)
block|{
case|case
name|ATTRIBUTE_SECTION
case|:
if|if
condition|(
name|contextSet
operator|instanceof
name|VirtualNodeSet
condition|)
block|{
name|parent
operator|=
name|contextSet
operator|.
name|parentWithChild
argument_list|(
name|storedNode
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|,
name|NodeProxy
operator|.
name|UNKNOWN_NODE_LEVEL
argument_list|)
expr_stmt|;
if|if
condition|(
name|parent
operator|!=
literal|null
operator|&&
operator|!
name|parent
operator|.
name|getNodeId
argument_list|()
operator|.
name|equals
argument_list|(
name|storedNode
operator|.
name|getNodeId
argument_list|()
argument_list|)
condition|)
name|parent
operator|=
literal|null
expr_stmt|;
block|}
else|else
name|parent
operator|=
name|contextSet
operator|.
name|get
argument_list|(
name|storedNode
argument_list|)
expr_stmt|;
break|break;
case|case
name|QNAME_SECTION
case|:
case|case
name|TEXT_SECTION
case|:
name|parent
operator|=
name|contextSet
operator|.
name|parentWithChild
argument_list|(
name|storedNode
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|,
name|NodeProxy
operator|.
name|UNKNOWN_NODE_LEVEL
argument_list|)
expr_stmt|;
break|break;
default|default :
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid section type in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|)
throw|;
block|}
if|if
condition|(
name|parent
operator|!=
literal|null
condition|)
block|{
name|Match
name|match
init|=
operator|new
name|FTMatch
argument_list|(
operator|-
literal|1
argument_list|,
name|nodeId
argument_list|,
name|token
argument_list|,
name|freq
argument_list|)
decl_stmt|;
name|readOccurrences
argument_list|(
name|freq
argument_list|,
name|is
argument_list|,
name|match
argument_list|,
name|token
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
if|if
condition|(
name|axis
operator|==
name|NodeSet
operator|.
name|ANCESTOR
condition|)
block|{
name|parent
operator|.
name|addMatch
argument_list|(
name|match
argument_list|)
expr_stmt|;
name|int
name|sizeHint
init|=
name|contextSet
operator|.
name|getSizeHint
argument_list|(
name|storedDocument
argument_list|)
decl_stmt|;
name|result
operator|.
name|add
argument_list|(
name|parent
argument_list|,
name|sizeHint
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|storedNode
operator|.
name|addMatch
argument_list|(
name|match
argument_list|)
expr_stmt|;
name|int
name|sizeHint
init|=
name|contextSet
operator|.
name|getSizeHint
argument_list|(
name|storedDocument
argument_list|)
decl_stmt|;
name|result
operator|.
name|add
argument_list|(
name|storedNode
argument_list|,
name|sizeHint
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|is
operator|.
name|skip
argument_list|(
name|freq
argument_list|)
expr_stmt|;
block|}
comment|// otherwise, we add all text nodes without check
block|}
else|else
block|{
name|Match
name|match
init|=
operator|new
name|FTMatch
argument_list|(
operator|-
literal|1
argument_list|,
name|nodeId
argument_list|,
name|token
argument_list|,
name|freq
argument_list|)
decl_stmt|;
name|readOccurrences
argument_list|(
name|freq
argument_list|,
name|is
argument_list|,
name|match
argument_list|,
name|token
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
name|storedNode
operator|.
name|addMatch
argument_list|(
name|match
argument_list|)
expr_stmt|;
name|result
operator|.
name|add
argument_list|(
name|storedNode
argument_list|,
name|Constants
operator|.
name|NO_SIZE_HINT
argument_list|)
expr_stmt|;
block|}
name|context
operator|.
name|proceed
argument_list|()
expr_stmt|;
block|}
block|}
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
operator|+
literal|" in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|//TODO : return ?
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|(
name|Lock
operator|.
name|READ_LOCK
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|result
return|;
block|}
specifier|private
name|NodeSet
name|getNodesRegexp
parameter_list|(
name|XQueryContext
name|context
parameter_list|,
name|DocumentSet
name|docs
parameter_list|,
name|NodeSet
name|contextSet
parameter_list|,
name|int
name|axis
parameter_list|,
name|QName
name|qname
parameter_list|,
name|String
name|expr
parameter_list|,
name|int
name|type
parameter_list|,
name|boolean
name|matchAll
parameter_list|)
throws|throws
name|TerminatedException
block|{
comment|//Return early
if|if
condition|(
name|expr
operator|==
literal|null
condition|)
return|return
literal|null
return|;
if|if
condition|(
name|stoplist
operator|.
name|contains
argument_list|(
name|expr
argument_list|)
condition|)
return|return
literal|null
return|;
comment|//TODO : case conversion should be handled by the tokenizer -pb
name|expr
operator|=
name|expr
operator|.
name|toLowerCase
argument_list|()
expr_stmt|;
comment|// if the regexp starts with a char sequence, we restrict the index scan to entries starting with
comment|// the same sequence. Otherwise, we have to scan the whole index.
name|CharSequence
name|start
init|=
literal|""
decl_stmt|;
if|if
condition|(
name|matchAll
condition|)
block|{
name|StringBuilder
name|buf
init|=
operator|new
name|StringBuilder
argument_list|()
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|expr
operator|.
name|length
argument_list|()
condition|;
name|i
operator|++
control|)
block|{
if|if
condition|(
name|Character
operator|.
name|isLetterOrDigit
argument_list|(
name|expr
operator|.
name|charAt
argument_list|(
name|i
argument_list|)
argument_list|)
condition|)
name|buf
operator|.
name|append
argument_list|(
name|expr
operator|.
name|charAt
argument_list|(
name|i
argument_list|)
argument_list|)
expr_stmt|;
else|else
break|break;
block|}
name|start
operator|=
name|buf
expr_stmt|;
block|}
try|try
block|{
name|TermMatcher
name|comparator
init|=
operator|new
name|RegexMatcher
argument_list|(
name|expr
argument_list|,
name|type
argument_list|,
name|Pattern
operator|.
name|CASE_INSENSITIVE
operator||
name|Pattern
operator|.
name|UNICODE_CASE
argument_list|,
name|matchAll
argument_list|)
decl_stmt|;
return|return
name|getNodes
argument_list|(
name|context
argument_list|,
name|docs
argument_list|,
name|contextSet
argument_list|,
name|axis
argument_list|,
name|qname
argument_list|,
name|comparator
argument_list|,
name|start
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
name|EXistException
name|e
parameter_list|)
block|{
return|return
literal|null
return|;
block|}
block|}
comment|/* Return all nodes for wich the matcher matches. 	 * @see org.exist.storage.TextSearchEngine#getNodes(org.exist.xquery.XQueryContext, org.exist.dom.DocumentSet, org.exist.dom.NodeSet, org.exist.storage.TermMatcher, java.lang.CharSequence) 	 */
specifier|public
name|NodeSet
name|getNodes
parameter_list|(
name|XQueryContext
name|context
parameter_list|,
name|DocumentSet
name|docs
parameter_list|,
name|NodeSet
name|contextSet
parameter_list|,
name|int
name|axis
parameter_list|,
name|QName
name|qname
parameter_list|,
name|TermMatcher
name|matcher
parameter_list|,
name|CharSequence
name|startTerm
parameter_list|)
throws|throws
name|TerminatedException
block|{
if|if
condition|(
name|LOG
operator|.
name|isTraceEnabled
argument_list|()
operator|&&
name|qname
operator|!=
literal|null
condition|)
name|LOG
operator|.
name|trace
argument_list|(
literal|"Index lookup by QName: "
operator|+
name|qname
argument_list|)
expr_stmt|;
specifier|final
name|NodeSet
name|result
init|=
operator|new
name|NewArrayNodeSet
argument_list|()
decl_stmt|;
specifier|final
name|SearchCallback
name|cb
init|=
operator|new
name|SearchCallback
argument_list|(
name|context
argument_list|,
name|matcher
argument_list|,
name|result
argument_list|,
name|contextSet
argument_list|,
name|axis
argument_list|,
name|docs
argument_list|,
name|qname
argument_list|)
decl_stmt|;
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
for|for
control|(
name|Iterator
argument_list|<
name|Collection
argument_list|>
name|iter
init|=
name|docs
operator|.
name|getCollectionIterator
argument_list|()
init|;
name|iter
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
specifier|final
name|int
name|collectionId
init|=
operator|(
operator|(
name|Collection
operator|)
name|iter
operator|.
name|next
argument_list|()
operator|)
operator|.
name|getId
argument_list|()
decl_stmt|;
comment|//Compute a key for the token
name|Value
name|value
decl_stmt|;
if|if
condition|(
name|startTerm
operator|!=
literal|null
operator|&&
name|startTerm
operator|.
name|length
argument_list|()
operator|>
literal|0
condition|)
block|{
comment|//TODO : case conversion should be handled by the tokenizer -pb
if|if
condition|(
name|qname
operator|==
literal|null
condition|)
block|{
name|value
operator|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|,
name|startTerm
operator|.
name|toString
argument_list|()
operator|.
name|toLowerCase
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|value
operator|=
operator|new
name|QNameWordRef
argument_list|(
name|collectionId
argument_list|,
name|qname
argument_list|,
name|startTerm
operator|.
name|toString
argument_list|()
operator|.
name|toLowerCase
argument_list|()
argument_list|,
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getSymbols
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
name|qname
operator|==
literal|null
condition|)
block|{
name|value
operator|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|value
operator|=
operator|new
name|QNameWordRef
argument_list|(
name|collectionId
argument_list|,
name|qname
argument_list|,
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getSymbols
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
name|IndexQuery
name|query
init|=
operator|new
name|IndexQuery
argument_list|(
name|IndexQuery
operator|.
name|TRUNC_RIGHT
argument_list|,
name|value
argument_list|)
decl_stmt|;
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|(
name|Lock
operator|.
name|READ_LOCK
argument_list|)
expr_stmt|;
name|dbTokens
operator|.
name|query
argument_list|(
name|query
argument_list|,
name|cb
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|BTreeException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|//TODO return null ? rethrow ? -pb
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|//TODO return null ? rethrow ? -pb
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|(
name|Lock
operator|.
name|READ_LOCK
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|result
return|;
block|}
specifier|public
name|String
index|[]
name|getIndexTerms
parameter_list|(
name|DocumentSet
name|docs
parameter_list|,
name|TermMatcher
name|matcher
parameter_list|)
block|{
specifier|final
name|IndexCallback
name|cb
init|=
operator|new
name|IndexCallback
argument_list|(
literal|null
argument_list|,
name|matcher
argument_list|)
decl_stmt|;
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
for|for
control|(
name|Iterator
argument_list|<
name|Collection
argument_list|>
name|iter
init|=
name|docs
operator|.
name|getCollectionIterator
argument_list|()
init|;
name|iter
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
specifier|final
name|int
name|collectionId
init|=
operator|(
operator|(
name|Collection
operator|)
name|iter
operator|.
name|next
argument_list|()
operator|)
operator|.
name|getId
argument_list|()
decl_stmt|;
comment|//Compute a key for the token
name|Value
name|value
init|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|)
decl_stmt|;
name|IndexQuery
name|query
init|=
operator|new
name|IndexQuery
argument_list|(
name|IndexQuery
operator|.
name|TRUNC_RIGHT
argument_list|,
name|value
argument_list|)
decl_stmt|;
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|(
name|Lock
operator|.
name|READ_LOCK
argument_list|)
expr_stmt|;
name|dbTokens
operator|.
name|query
argument_list|(
name|query
argument_list|,
name|cb
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|BTreeException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TerminatedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|(
name|Lock
operator|.
name|READ_LOCK
argument_list|)
expr_stmt|;
block|}
block|}
return|return
name|cb
operator|.
name|getMatches
argument_list|()
return|;
block|}
specifier|public
name|Occurrences
index|[]
name|scanIndexTerms
parameter_list|(
name|DocumentSet
name|docs
parameter_list|,
name|NodeSet
name|contextSet
parameter_list|,
name|String
name|start
parameter_list|,
name|String
name|end
parameter_list|)
throws|throws
name|PermissionDeniedException
block|{
specifier|final
name|IndexScanCallback
name|cb
init|=
operator|new
name|IndexScanCallback
argument_list|(
name|docs
argument_list|,
name|contextSet
argument_list|,
literal|false
argument_list|)
decl_stmt|;
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
for|for
control|(
name|Iterator
argument_list|<
name|Collection
argument_list|>
name|i
init|=
name|docs
operator|.
name|getCollectionIterator
argument_list|()
init|;
name|i
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
specifier|final
name|int
name|collectionId
init|=
operator|(
name|i
operator|.
name|next
argument_list|()
operator|)
operator|.
name|getId
argument_list|()
decl_stmt|;
specifier|final
name|IndexQuery
name|query
decl_stmt|;
if|if
condition|(
name|start
operator|==
literal|null
condition|)
block|{
name|Value
name|startRef
init|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|)
decl_stmt|;
name|query
operator|=
operator|new
name|IndexQuery
argument_list|(
name|IndexQuery
operator|.
name|TRUNC_RIGHT
argument_list|,
name|startRef
argument_list|)
expr_stmt|;
block|}
if|else if
condition|(
name|end
operator|==
literal|null
condition|)
block|{
name|Value
name|startRef
init|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|,
name|start
operator|.
name|toLowerCase
argument_list|()
argument_list|)
decl_stmt|;
name|query
operator|=
operator|new
name|IndexQuery
argument_list|(
name|IndexQuery
operator|.
name|TRUNC_RIGHT
argument_list|,
name|startRef
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Value
name|startRef
init|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|,
name|start
operator|.
name|toLowerCase
argument_list|()
argument_list|)
decl_stmt|;
name|Value
name|endRef
init|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|,
name|end
operator|.
name|toLowerCase
argument_list|()
argument_list|)
decl_stmt|;
name|query
operator|=
operator|new
name|IndexQuery
argument_list|(
name|IndexQuery
operator|.
name|BW
argument_list|,
name|startRef
argument_list|,
name|endRef
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|(
name|Lock
operator|.
name|READ_LOCK
argument_list|)
expr_stmt|;
name|dbTokens
operator|.
name|query
argument_list|(
name|query
argument_list|,
name|cb
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|BTreeException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TerminatedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|(
name|Lock
operator|.
name|READ_LOCK
argument_list|)
expr_stmt|;
block|}
block|}
name|Occurrences
index|[]
name|result
init|=
operator|new
name|Occurrences
index|[
name|cb
operator|.
name|map
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
return|return
operator|(
name|Occurrences
index|[]
operator|)
name|cb
operator|.
name|map
operator|.
name|values
argument_list|()
operator|.
name|toArray
argument_list|(
name|result
argument_list|)
return|;
block|}
specifier|public
name|Occurrences
index|[]
name|scanIndexTerms
parameter_list|(
name|DocumentSet
name|docs
parameter_list|,
name|NodeSet
name|contextSet
parameter_list|,
name|QName
index|[]
name|qnames
parameter_list|,
name|String
name|start
parameter_list|,
name|String
name|end
parameter_list|)
throws|throws
name|PermissionDeniedException
block|{
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
specifier|final
name|IndexScanCallback
name|cb
init|=
operator|new
name|IndexScanCallback
argument_list|(
name|docs
argument_list|,
name|contextSet
argument_list|,
literal|true
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|q
init|=
literal|0
init|;
name|q
operator|<
name|qnames
operator|.
name|length
condition|;
name|q
operator|++
control|)
block|{
for|for
control|(
name|Iterator
argument_list|<
name|Collection
argument_list|>
name|i
init|=
name|docs
operator|.
name|getCollectionIterator
argument_list|()
init|;
name|i
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
specifier|final
name|int
name|collectionId
init|=
operator|(
name|i
operator|.
name|next
argument_list|()
operator|)
operator|.
name|getId
argument_list|()
decl_stmt|;
specifier|final
name|IndexQuery
name|query
decl_stmt|;
if|if
condition|(
name|start
operator|==
literal|null
condition|)
block|{
name|Value
name|startRef
init|=
operator|new
name|QNameWordRef
argument_list|(
name|collectionId
argument_list|,
name|qnames
index|[
name|q
index|]
argument_list|,
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getSymbols
argument_list|()
argument_list|)
decl_stmt|;
name|query
operator|=
operator|new
name|IndexQuery
argument_list|(
name|IndexQuery
operator|.
name|TRUNC_RIGHT
argument_list|,
name|startRef
argument_list|)
expr_stmt|;
block|}
if|else if
condition|(
name|end
operator|==
literal|null
condition|)
block|{
name|Value
name|startRef
init|=
operator|new
name|QNameWordRef
argument_list|(
name|collectionId
argument_list|,
name|qnames
index|[
name|q
index|]
argument_list|,
name|start
operator|.
name|toLowerCase
argument_list|()
argument_list|,
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getSymbols
argument_list|()
argument_list|)
decl_stmt|;
name|query
operator|=
operator|new
name|IndexQuery
argument_list|(
name|IndexQuery
operator|.
name|TRUNC_RIGHT
argument_list|,
name|startRef
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Value
name|startRef
init|=
operator|new
name|QNameWordRef
argument_list|(
name|collectionId
argument_list|,
name|qnames
index|[
name|q
index|]
argument_list|,
name|start
operator|.
name|toLowerCase
argument_list|()
argument_list|,
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getSymbols
argument_list|()
argument_list|)
decl_stmt|;
name|Value
name|endRef
init|=
operator|new
name|QNameWordRef
argument_list|(
name|collectionId
argument_list|,
name|qnames
index|[
name|q
index|]
argument_list|,
name|end
operator|.
name|toLowerCase
argument_list|()
argument_list|,
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getSymbols
argument_list|()
argument_list|)
decl_stmt|;
name|query
operator|=
operator|new
name|IndexQuery
argument_list|(
name|IndexQuery
operator|.
name|BW
argument_list|,
name|startRef
argument_list|,
name|endRef
argument_list|)
expr_stmt|;
block|}
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|(
name|Lock
operator|.
name|READ_LOCK
argument_list|)
expr_stmt|;
name|dbTokens
operator|.
name|query
argument_list|(
name|query
argument_list|,
name|cb
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|BTreeException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|TerminatedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|(
name|Lock
operator|.
name|READ_LOCK
argument_list|)
expr_stmt|;
block|}
block|}
block|}
name|Occurrences
index|[]
name|result
init|=
operator|new
name|Occurrences
index|[
name|cb
operator|.
name|map
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
return|return
operator|(
name|Occurrences
index|[]
operator|)
name|cb
operator|.
name|map
operator|.
name|values
argument_list|()
operator|.
name|toArray
argument_list|(
name|result
argument_list|)
return|;
block|}
comment|/**      * @param freq      * @param is      * @param match      * @throws IOException      */
specifier|private
name|void
name|readOccurrences
parameter_list|(
name|int
name|freq
parameter_list|,
name|VariableByteInput
name|is
parameter_list|,
name|Match
name|match
parameter_list|,
name|int
name|length
parameter_list|)
throws|throws
name|IOException
block|{
for|for
control|(
name|int
name|n
init|=
literal|0
init|;
name|n
operator|<
name|freq
condition|;
name|n
operator|++
control|)
block|{
name|match
operator|.
name|addOffset
argument_list|(
name|is
operator|.
name|readInt
argument_list|()
argument_list|,
name|length
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Collect all words in a document to be removed      *       * @param words      *                Description of the Parameter      * @param domIterator      *                Description of the Parameter      */
comment|//TODO : unify functionalities with storeText -pb
specifier|private
name|void
name|collect
parameter_list|(
name|Set
name|words
parameter_list|,
name|Iterator
name|domIterator
parameter_list|)
block|{
name|byte
index|[]
name|data
init|=
operator|(
operator|(
name|Value
operator|)
name|domIterator
operator|.
name|next
argument_list|()
operator|)
operator|.
name|getData
argument_list|()
decl_stmt|;
name|short
name|type
init|=
name|Signatures
operator|.
name|getType
argument_list|(
name|data
index|[
name|OFFSET_NODE_TYPE
index|]
argument_list|)
decl_stmt|;
switch|switch
condition|(
name|type
condition|)
block|{
case|case
name|Node
operator|.
name|ELEMENT_NODE
case|:
name|int
name|childrenCount
init|=
name|ByteConversion
operator|.
name|byteToInt
argument_list|(
name|data
argument_list|,
name|OFFSET_ELEMENT_CHILDREN_COUNT
argument_list|)
decl_stmt|;
for|for
control|(
name|int
name|i
init|=
literal|0
init|;
name|i
operator|<
name|childrenCount
condition|;
name|i
operator|++
control|)
comment|//recursive call on children
name|collect
argument_list|(
name|words
argument_list|,
name|domIterator
argument_list|)
expr_stmt|;
break|break;
case|case
name|Node
operator|.
name|TEXT_NODE
case|:
name|int
name|dlnLen
init|=
name|ByteConversion
operator|.
name|byteToShort
argument_list|(
name|data
argument_list|,
name|OFFSET_TEXT_DLN_LENGTH
argument_list|)
decl_stmt|;
name|int
name|nodeIdLen
init|=
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getNodeFactory
argument_list|()
operator|.
name|lengthInBytes
argument_list|(
name|dlnLen
argument_list|,
name|data
argument_list|,
name|OFFSET_DLN
argument_list|)
decl_stmt|;
try|try
block|{
name|int
name|readOffset
init|=
name|nodeIdLen
operator|+
name|OFFSET_DLN
decl_stmt|;
name|String
name|s
init|=
operator|new
name|String
argument_list|(
name|data
argument_list|,
name|readOffset
argument_list|,
name|data
operator|.
name|length
operator|-
name|readOffset
argument_list|,
literal|"UTF-8"
argument_list|)
decl_stmt|;
name|tokenizer
operator|.
name|setText
argument_list|(
name|s
argument_list|)
expr_stmt|;
name|TextToken
name|token
decl_stmt|;
while|while
condition|(
literal|null
operator|!=
operator|(
name|token
operator|=
name|tokenizer
operator|.
name|nextToken
argument_list|()
operator|)
condition|)
block|{
name|String
name|word
init|=
name|token
operator|.
name|getText
argument_list|()
decl_stmt|;
if|if
condition|(
name|stoplist
operator|.
name|contains
argument_list|(
name|word
argument_list|)
condition|)
continue|continue;
name|words
operator|.
name|add
argument_list|(
name|word
operator|.
name|toLowerCase
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|UnsupportedEncodingException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
break|break;
case|case
name|Node
operator|.
name|ATTRIBUTE_NODE
case|:
name|byte
name|idSizeType
init|=
operator|(
name|byte
operator|)
operator|(
name|data
index|[
name|OFFSET_NODE_TYPE
index|]
operator|&
literal|0x3
operator|)
decl_stmt|;
name|boolean
name|hasNamespace
init|=
operator|(
name|data
index|[
name|OFFSET_NODE_TYPE
index|]
operator|&
literal|0x10
operator|)
operator|==
literal|0x10
decl_stmt|;
name|dlnLen
operator|=
name|ByteConversion
operator|.
name|byteToShort
argument_list|(
name|data
argument_list|,
name|OFFSET_ATTRIBUTE_DLN_LENGTH
argument_list|)
expr_stmt|;
name|nodeIdLen
operator|=
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getNodeFactory
argument_list|()
operator|.
name|lengthInBytes
argument_list|(
name|dlnLen
argument_list|,
name|data
argument_list|,
name|OFFSET_DLN
argument_list|)
expr_stmt|;
name|int
name|readOffset
init|=
name|Signatures
operator|.
name|getLength
argument_list|(
name|idSizeType
argument_list|)
operator|+
name|nodeIdLen
operator|+
name|OFFSET_DLN
decl_stmt|;
if|if
condition|(
name|hasNamespace
condition|)
block|{
comment|//TODO : check the order in wich both info are read (and discarded)
name|readOffset
operator|+=
name|SymbolTable
operator|.
name|LENGTH_LOCAL_NAME
expr_stmt|;
comment|// skip namespace id
specifier|final
name|short
name|prefixLen
init|=
name|ByteConversion
operator|.
name|byteToShort
argument_list|(
name|data
argument_list|,
name|readOffset
argument_list|)
decl_stmt|;
name|readOffset
operator|+=
name|prefixLen
operator|+
name|SymbolTable
operator|.
name|LENGTH_NS_URI
expr_stmt|;
comment|// skip prefix
block|}
try|try
block|{
name|String
name|val
init|=
operator|new
name|String
argument_list|(
name|data
argument_list|,
name|readOffset
argument_list|,
name|data
operator|.
name|length
operator|-
name|readOffset
argument_list|,
literal|"UTF-8"
argument_list|)
decl_stmt|;
name|tokenizer
operator|.
name|setText
argument_list|(
name|val
argument_list|)
expr_stmt|;
name|TextToken
name|token
decl_stmt|;
while|while
condition|(
literal|null
operator|!=
operator|(
name|token
operator|=
name|tokenizer
operator|.
name|nextToken
argument_list|()
operator|)
condition|)
block|{
name|String
name|word
init|=
name|token
operator|.
name|getText
argument_list|()
decl_stmt|;
if|if
condition|(
name|stoplist
operator|.
name|contains
argument_list|(
name|word
argument_list|)
condition|)
continue|continue;
name|words
operator|.
name|add
argument_list|(
name|word
operator|.
name|toLowerCase
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
name|UnsupportedEncodingException
name|e
parameter_list|)
block|{
comment|//val = new String(data,
comment|//        1 + Signatures.getLength(idSizeType), data.length
comment|//                - 1 - Signatures.getLength(idSizeType));
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
break|break;
default|default :
comment|//Other types are ignored : some may be useful though -pb
comment|//TOUNDERSTAND : it looks like other types (got : Node.PROCESSING_INSTRUCTION_NODE)
comment|//are stored in the index ??? -pb
block|}
block|}
specifier|public
name|void
name|closeAndRemove
parameter_list|()
block|{
name|config
operator|.
name|setProperty
argument_list|(
name|getConfigKeyForFile
argument_list|()
argument_list|,
literal|null
argument_list|)
expr_stmt|;
name|dbTokens
operator|.
name|closeAndRemove
argument_list|()
expr_stmt|;
block|}
specifier|public
name|boolean
name|close
parameter_list|()
throws|throws
name|DBException
block|{
name|config
operator|.
name|setProperty
argument_list|(
name|getConfigKeyForFile
argument_list|()
argument_list|,
literal|null
argument_list|)
expr_stmt|;
return|return
name|dbTokens
operator|.
name|close
argument_list|()
return|;
block|}
specifier|public
name|void
name|printStatistics
parameter_list|()
block|{
name|dbTokens
operator|.
name|printStatistics
argument_list|()
expr_stmt|;
block|}
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
name|this
operator|.
name|getClass
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" at "
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|" owned by "
operator|+
name|broker
operator|.
name|toString
argument_list|()
return|;
block|}
comment|/** 	 * This inner class is responsible for actually storing the list of 	 * occurrences. 	 *  	 * @author Wolfgang Meier<meier@ifs.tu-darmstadt.de> 	 */
specifier|final
class|class
name|InvertedIndex
block|{
specifier|private
class|class
name|QNameTerm
implements|implements
name|Comparable
block|{
name|QName
name|qname
decl_stmt|;
name|String
name|term
decl_stmt|;
specifier|public
name|QNameTerm
parameter_list|(
name|QName
name|qname
parameter_list|,
name|String
name|term
parameter_list|)
block|{
name|this
operator|.
name|qname
operator|=
name|qname
expr_stmt|;
name|this
operator|.
name|term
operator|=
name|term
expr_stmt|;
block|}
specifier|public
name|int
name|compareTo
parameter_list|(
name|Object
name|o
parameter_list|)
block|{
name|QNameTerm
name|other
init|=
operator|(
name|QNameTerm
operator|)
name|o
decl_stmt|;
name|int
name|cmp
init|=
name|qname
operator|.
name|compareTo
argument_list|(
name|other
operator|.
name|qname
argument_list|)
decl_stmt|;
if|if
condition|(
name|cmp
operator|==
literal|0
condition|)
return|return
name|term
operator|.
name|compareTo
argument_list|(
name|other
operator|.
name|term
argument_list|)
return|;
else|else
return|return
name|cmp
return|;
block|}
block|}
specifier|private
name|DocumentImpl
name|doc
init|=
literal|null
decl_stmt|;
comment|// To distinguish between attribute values and text, we use
comment|// two maps: words[0] collects text, words[1] stores attribute
comment|// values.
comment|//TODO : very tricky. Why not 2 inverted indexes ??? -pb
specifier|private
name|Map
name|words
index|[]
init|=
operator|new
name|Map
index|[
literal|3
index|]
decl_stmt|;
specifier|private
name|int
name|TEXT_NODES
init|=
literal|0
decl_stmt|;
specifier|private
name|int
name|ATTRIBUTE_NODES
init|=
literal|1
decl_stmt|;
specifier|private
name|int
name|BY_QNAME
init|=
literal|2
decl_stmt|;
specifier|public
name|InvertedIndex
parameter_list|()
block|{
name|words
index|[
name|TEXT_NODES
index|]
operator|=
operator|new
name|HashMap
argument_list|(
literal|512
argument_list|)
expr_stmt|;
name|words
index|[
name|ATTRIBUTE_NODES
index|]
operator|=
operator|new
name|HashMap
argument_list|(
literal|256
argument_list|)
expr_stmt|;
comment|//seems to be linked with QName indexes
name|words
index|[
name|BY_QNAME
index|]
operator|=
operator|new
name|TreeMap
argument_list|()
expr_stmt|;
block|}
specifier|public
name|void
name|setDocument
parameter_list|(
name|DocumentImpl
name|document
parameter_list|)
block|{
if|if
condition|(
name|this
operator|.
name|doc
operator|!=
literal|null
operator|&&
name|this
operator|.
name|doc
operator|.
name|getDocId
argument_list|()
operator|!=
name|document
operator|.
name|getDocId
argument_list|()
condition|)
name|flush
argument_list|()
expr_stmt|;
name|this
operator|.
name|doc
operator|=
name|document
expr_stmt|;
block|}
specifier|public
name|void
name|addText
parameter_list|(
name|TextToken
name|token
parameter_list|,
name|NodeId
name|nodeId
parameter_list|,
name|boolean
name|remove
parameter_list|)
block|{
if|if
condition|(
operator|!
name|remove
condition|)
block|{
comment|//Is this token already pending ?
name|OccurrenceList
name|list
init|=
operator|(
name|OccurrenceList
operator|)
name|words
index|[
name|TEXT_NODES
index|]
operator|.
name|get
argument_list|(
name|token
argument_list|)
decl_stmt|;
comment|//Create a GIDs list
if|if
condition|(
name|list
operator|==
literal|null
condition|)
block|{
name|list
operator|=
operator|new
name|OccurrenceList
argument_list|()
expr_stmt|;
name|list
operator|.
name|add
argument_list|(
name|nodeId
argument_list|,
name|token
operator|.
name|startOffset
argument_list|()
argument_list|)
expr_stmt|;
name|words
index|[
name|TEXT_NODES
index|]
operator|.
name|put
argument_list|(
name|token
operator|.
name|getText
argument_list|()
argument_list|,
name|list
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|//Add node's GID to the list
name|list
operator|.
name|add
argument_list|(
name|nodeId
argument_list|,
name|token
operator|.
name|startOffset
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
operator|!
name|words
index|[
name|TEXT_NODES
index|]
operator|.
name|containsKey
argument_list|(
name|token
argument_list|)
condition|)
name|words
index|[
name|TEXT_NODES
index|]
operator|.
name|put
argument_list|(
name|token
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|addText
parameter_list|(
name|TextToken
name|token
parameter_list|,
name|ElementImpl
name|ancestor
parameter_list|,
name|boolean
name|remove
parameter_list|)
block|{
name|QNameTerm
name|term
init|=
operator|new
name|QNameTerm
argument_list|(
name|ancestor
operator|.
name|getQName
argument_list|()
argument_list|,
name|token
operator|.
name|getText
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|remove
condition|)
block|{
comment|//Is this token already pending ?
name|OccurrenceList
name|list
init|=
operator|(
name|OccurrenceList
operator|)
name|words
index|[
name|BY_QNAME
index|]
operator|.
name|get
argument_list|(
name|term
argument_list|)
decl_stmt|;
comment|//Create a GIDs list
if|if
condition|(
name|list
operator|==
literal|null
condition|)
block|{
name|list
operator|=
operator|new
name|OccurrenceList
argument_list|()
expr_stmt|;
name|list
operator|.
name|add
argument_list|(
name|ancestor
operator|.
name|getNodeId
argument_list|()
argument_list|,
name|token
operator|.
name|startOffset
argument_list|()
argument_list|)
expr_stmt|;
name|words
index|[
name|BY_QNAME
index|]
operator|.
name|put
argument_list|(
name|term
argument_list|,
name|list
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|//Add node's GID to the list
name|list
operator|.
name|add
argument_list|(
name|ancestor
operator|.
name|getNodeId
argument_list|()
argument_list|,
name|token
operator|.
name|startOffset
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
operator|!
name|words
index|[
name|BY_QNAME
index|]
operator|.
name|containsKey
argument_list|(
name|term
argument_list|)
condition|)
name|words
index|[
name|BY_QNAME
index|]
operator|.
name|put
argument_list|(
name|term
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
comment|//TODO : unify functionalities with addText -pb
specifier|public
name|void
name|addAttribute
parameter_list|(
name|TextToken
name|token
parameter_list|,
name|NodeId
name|nodeId
parameter_list|,
name|boolean
name|remove
parameter_list|)
block|{
comment|//Is this token already pending ?
if|if
condition|(
operator|!
name|remove
condition|)
block|{
name|OccurrenceList
name|list
init|=
operator|(
name|OccurrenceList
operator|)
name|words
index|[
name|ATTRIBUTE_NODES
index|]
operator|.
name|get
argument_list|(
name|token
argument_list|)
decl_stmt|;
comment|//Create a GIDs list
if|if
condition|(
name|list
operator|==
literal|null
condition|)
block|{
name|list
operator|=
operator|new
name|OccurrenceList
argument_list|()
expr_stmt|;
name|list
operator|.
name|add
argument_list|(
name|nodeId
argument_list|,
name|token
operator|.
name|startOffset
argument_list|()
argument_list|)
expr_stmt|;
name|words
index|[
name|ATTRIBUTE_NODES
index|]
operator|.
name|put
argument_list|(
name|token
operator|.
name|getText
argument_list|()
argument_list|,
name|list
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|//Add node's GID to the list
name|list
operator|.
name|add
argument_list|(
name|nodeId
argument_list|,
name|token
operator|.
name|startOffset
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
operator|!
name|words
index|[
name|ATTRIBUTE_NODES
index|]
operator|.
name|containsKey
argument_list|(
name|token
argument_list|)
condition|)
name|words
index|[
name|ATTRIBUTE_NODES
index|]
operator|.
name|put
argument_list|(
name|token
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|addAttribute
parameter_list|(
name|TextToken
name|token
parameter_list|,
name|AttrImpl
name|attr
parameter_list|,
name|boolean
name|remove
parameter_list|)
block|{
name|QNameTerm
name|term
init|=
operator|new
name|QNameTerm
argument_list|(
name|attr
operator|.
name|getQName
argument_list|()
argument_list|,
name|token
operator|.
name|getText
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|remove
condition|)
block|{
comment|//Is this token already pending ?
name|OccurrenceList
name|list
init|=
operator|(
name|OccurrenceList
operator|)
name|words
index|[
name|BY_QNAME
index|]
operator|.
name|get
argument_list|(
name|term
argument_list|)
decl_stmt|;
comment|//Create a GIDs list
if|if
condition|(
name|list
operator|==
literal|null
condition|)
block|{
name|list
operator|=
operator|new
name|OccurrenceList
argument_list|()
expr_stmt|;
name|list
operator|.
name|add
argument_list|(
name|attr
operator|.
name|getNodeId
argument_list|()
argument_list|,
name|token
operator|.
name|startOffset
argument_list|()
argument_list|)
expr_stmt|;
name|words
index|[
name|BY_QNAME
index|]
operator|.
name|put
argument_list|(
name|term
argument_list|,
name|list
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|//Add node's GID to the list
name|list
operator|.
name|add
argument_list|(
name|attr
operator|.
name|getNodeId
argument_list|()
argument_list|,
name|token
operator|.
name|startOffset
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
if|if
condition|(
operator|!
name|words
index|[
name|BY_QNAME
index|]
operator|.
name|containsKey
argument_list|(
name|term
argument_list|)
condition|)
name|words
index|[
name|BY_QNAME
index|]
operator|.
name|put
argument_list|(
name|term
argument_list|,
literal|null
argument_list|)
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|flush
parameter_list|()
block|{
comment|//return early
if|if
condition|(
name|this
operator|.
name|doc
operator|==
literal|null
condition|)
return|return;
specifier|final
name|int
name|wordsCount
init|=
name|words
index|[
name|TEXT_NODES
index|]
operator|.
name|size
argument_list|()
operator|+
name|words
index|[
name|ATTRIBUTE_NODES
index|]
operator|.
name|size
argument_list|()
operator|+
name|words
index|[
name|BY_QNAME
index|]
operator|.
name|size
argument_list|()
decl_stmt|;
if|if
condition|(
name|wordsCount
operator|==
literal|0
condition|)
return|return;
specifier|final
name|ProgressIndicator
name|progress
init|=
operator|new
name|ProgressIndicator
argument_list|(
name|wordsCount
argument_list|,
literal|100
argument_list|)
decl_stmt|;
specifier|final
name|int
name|collectionId
init|=
name|this
operator|.
name|doc
operator|.
name|getCollection
argument_list|()
operator|.
name|getId
argument_list|()
decl_stmt|;
name|int
name|count
init|=
literal|0
decl_stmt|;
for|for
control|(
name|byte
name|currentSection
init|=
literal|0
init|;
name|currentSection
operator|<=
name|QNAME_SECTION
condition|;
name|currentSection
operator|++
control|)
block|{
comment|//Not very necessary, but anyway...
switch|switch
condition|(
name|currentSection
condition|)
block|{
case|case
name|TEXT_SECTION
case|:
case|case
name|ATTRIBUTE_SECTION
case|:
case|case
name|QNAME_SECTION
case|:
break|break;
default|default :
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid section type in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|)
throw|;
block|}
for|for
control|(
name|Iterator
name|i
init|=
name|words
index|[
name|currentSection
index|]
operator|.
name|entrySet
argument_list|()
operator|.
name|iterator
argument_list|()
init|;
name|i
operator|.
name|hasNext
argument_list|()
condition|;
name|count
operator|++
control|)
block|{
name|Map
operator|.
name|Entry
name|entry
init|=
operator|(
name|Map
operator|.
name|Entry
operator|)
name|i
operator|.
name|next
argument_list|()
decl_stmt|;
name|Object
name|token
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|OccurrenceList
name|occurences
init|=
operator|(
name|OccurrenceList
operator|)
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
if|if
condition|(
name|occurences
operator|==
literal|null
condition|)
continue|continue;
comment|// may happen if the index is in an invalid state due to earlier errors
comment|//Don't forget this one
name|occurences
operator|.
name|sort
argument_list|()
expr_stmt|;
name|os
operator|.
name|clear
argument_list|()
expr_stmt|;
name|os
operator|.
name|writeInt
argument_list|(
name|this
operator|.
name|doc
operator|.
name|getDocId
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeByte
argument_list|(
name|currentSection
argument_list|)
expr_stmt|;
comment|//                    os.writeByte(currentSection == QNAME_SECTION ? TEXT_SECTION : currentSection);
name|os
operator|.
name|writeInt
argument_list|(
name|occurences
operator|.
name|getTermCount
argument_list|()
argument_list|)
expr_stmt|;
comment|//Mark position
name|int
name|lenOffset
init|=
name|os
operator|.
name|position
argument_list|()
decl_stmt|;
comment|//Dummy value : actual one will be written below
name|os
operator|.
name|writeFixedInt
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|NodeId
name|previous
init|=
literal|null
decl_stmt|;
for|for
control|(
name|int
name|m
init|=
literal|0
init|;
name|m
operator|<
name|occurences
operator|.
name|getSize
argument_list|()
condition|;
control|)
block|{
try|try
block|{
name|previous
operator|=
name|occurences
operator|.
name|getNode
argument_list|(
name|m
argument_list|)
operator|.
name|write
argument_list|(
name|previous
argument_list|,
name|os
argument_list|)
expr_stmt|;
comment|//                            occurences.nodes[m].write(os);
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"IOException while writing fulltext index: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
name|int
name|freq
init|=
name|occurences
operator|.
name|getOccurrences
argument_list|(
name|m
argument_list|)
decl_stmt|;
name|os
operator|.
name|writeInt
argument_list|(
name|freq
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|n
init|=
literal|0
init|;
name|n
operator|<
name|freq
condition|;
name|n
operator|++
control|)
block|{
name|os
operator|.
name|writeInt
argument_list|(
name|occurences
operator|.
name|getOffset
argument_list|(
name|m
operator|+
name|n
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|m
operator|+=
name|freq
expr_stmt|;
block|}
comment|//Write (variable) length of node IDs + frequency + offsets
name|os
operator|.
name|writeFixedInt
argument_list|(
name|lenOffset
argument_list|,
name|os
operator|.
name|position
argument_list|()
operator|-
name|lenOffset
operator|-
name|LENGTH_NODE_IDS_FREQ_OFFSETS
argument_list|)
expr_stmt|;
name|flushWord
argument_list|(
name|currentSection
argument_list|,
name|collectionId
argument_list|,
name|token
argument_list|,
name|os
operator|.
name|data
argument_list|()
argument_list|)
expr_stmt|;
name|progress
operator|.
name|setValue
argument_list|(
name|count
argument_list|)
expr_stmt|;
if|if
condition|(
name|progress
operator|.
name|changed
argument_list|()
condition|)
block|{
name|setChanged
argument_list|()
expr_stmt|;
name|notifyObservers
argument_list|(
name|progress
argument_list|)
expr_stmt|;
block|}
block|}
comment|//TOUNDERSTAND : is this a flush ?
comment|//If so, the ProgressIndicator should be reinitialized -pb
if|if
condition|(
name|wordsCount
operator|>
literal|100
condition|)
block|{
name|progress
operator|.
name|finish
argument_list|()
expr_stmt|;
name|setChanged
argument_list|()
expr_stmt|;
name|notifyObservers
argument_list|(
name|progress
argument_list|)
expr_stmt|;
block|}
name|words
index|[
name|currentSection
index|]
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
specifier|private
name|void
name|flushWord
parameter_list|(
name|int
name|currentSection
parameter_list|,
name|int
name|collectionId
parameter_list|,
name|Object
name|token
parameter_list|,
name|ByteArray
name|data
parameter_list|)
block|{
comment|//return early
comment|//TODO : is this ever called ? -pb
if|if
condition|(
name|data
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
return|return;
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|(
name|Lock
operator|.
name|WRITE_LOCK
argument_list|)
expr_stmt|;
name|Value
name|key
decl_stmt|;
if|if
condition|(
name|currentSection
operator|==
name|QNAME_SECTION
condition|)
block|{
name|QNameTerm
name|term
init|=
operator|(
name|QNameTerm
operator|)
name|token
decl_stmt|;
name|key
operator|=
operator|new
name|QNameWordRef
argument_list|(
name|collectionId
argument_list|,
name|term
operator|.
name|qname
argument_list|,
name|term
operator|.
name|term
argument_list|,
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getSymbols
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|key
operator|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|,
name|token
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|dbTokens
operator|.
name|append
argument_list|(
name|key
argument_list|,
name|data
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ReadOnlyException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Read-only error on '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
operator|+
literal|"' in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|(
name|Lock
operator|.
name|WRITE_LOCK
argument_list|)
expr_stmt|;
name|os
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
specifier|public
name|void
name|dropIndex
parameter_list|(
name|DocumentImpl
name|document
parameter_list|)
block|{
comment|//Return early
if|if
condition|(
name|document
operator|==
literal|null
condition|)
return|return;
specifier|final
name|int
name|collectionId
init|=
name|document
operator|.
name|getCollection
argument_list|()
operator|.
name|getId
argument_list|()
decl_stmt|;
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
for|for
control|(
name|byte
name|currentSection
init|=
literal|0
init|;
name|currentSection
operator|<=
name|QNAME_SECTION
condition|;
name|currentSection
operator|++
control|)
block|{
comment|//Not very necessary, but anyway...
switch|switch
condition|(
name|currentSection
condition|)
block|{
case|case
name|TEXT_SECTION
case|:
case|case
name|ATTRIBUTE_SECTION
case|:
case|case
name|QNAME_SECTION
case|:
break|break;
default|default :
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid section type in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|)
throw|;
block|}
name|LOG
operator|.
name|debug
argument_list|(
literal|"Removing "
operator|+
name|words
index|[
name|currentSection
index|]
operator|.
name|size
argument_list|()
operator|+
literal|" tokens"
argument_list|)
expr_stmt|;
for|for
control|(
name|Iterator
name|i
init|=
name|words
index|[
name|currentSection
index|]
operator|.
name|entrySet
argument_list|()
operator|.
name|iterator
argument_list|()
init|;
name|i
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
comment|//Compute a key for the token
name|Map
operator|.
name|Entry
name|entry
init|=
operator|(
name|Map
operator|.
name|Entry
operator|)
name|i
operator|.
name|next
argument_list|()
decl_stmt|;
name|Object
name|token
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|Value
name|key
decl_stmt|;
if|if
condition|(
name|currentSection
operator|==
name|QNAME_SECTION
condition|)
block|{
name|QNameTerm
name|term
init|=
operator|(
name|QNameTerm
operator|)
name|token
decl_stmt|;
name|key
operator|=
operator|new
name|QNameWordRef
argument_list|(
name|collectionId
argument_list|,
name|term
operator|.
name|qname
argument_list|,
name|term
operator|.
name|term
argument_list|,
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getSymbols
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|key
operator|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|,
name|token
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|os
operator|.
name|clear
argument_list|()
expr_stmt|;
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|(
name|Lock
operator|.
name|WRITE_LOCK
argument_list|)
expr_stmt|;
name|boolean
name|changed
init|=
literal|false
decl_stmt|;
name|os
operator|.
name|clear
argument_list|()
expr_stmt|;
name|VariableByteInput
name|is
init|=
name|dbTokens
operator|.
name|getAsStream
argument_list|(
name|key
argument_list|)
decl_stmt|;
comment|//Does the token already has data in the index ?
if|if
condition|(
name|is
operator|==
literal|null
condition|)
continue|continue;
comment|//try {
while|while
condition|(
name|is
operator|.
name|available
argument_list|()
operator|>
literal|0
condition|)
block|{
name|int
name|storedDocId
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
name|byte
name|section
init|=
name|is
operator|.
name|readByte
argument_list|()
decl_stmt|;
name|int
name|gidsCount
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
comment|//Read (variable) length of node IDs + frequency + offsets
name|int
name|length
init|=
name|is
operator|.
name|readFixedInt
argument_list|()
decl_stmt|;
if|if
condition|(
name|storedDocId
operator|!=
name|document
operator|.
name|getDocId
argument_list|()
condition|)
block|{
comment|// data are related to another document:
comment|// copy them to any existing data
name|os
operator|.
name|writeInt
argument_list|(
name|storedDocId
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeByte
argument_list|(
name|section
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeInt
argument_list|(
name|gidsCount
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeFixedInt
argument_list|(
name|length
argument_list|)
expr_stmt|;
name|is
operator|.
name|copyRaw
argument_list|(
name|os
argument_list|,
name|length
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// data are related to our document:
comment|// skip them
name|changed
operator|=
literal|true
expr_stmt|;
name|is
operator|.
name|skipBytes
argument_list|(
name|length
argument_list|)
expr_stmt|;
block|}
block|}
comment|//} catch (EOFException e) {
comment|//EOF is expected here
comment|//}
comment|//Store new data, if relevant
if|if
condition|(
name|changed
condition|)
block|{
comment|//Well, nothing to store : remove the existing data
if|if
condition|(
name|os
operator|.
name|data
argument_list|()
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
block|{
name|dbTokens
operator|.
name|remove
argument_list|(
name|key
argument_list|)
expr_stmt|;
block|}
else|else
block|{
if|if
condition|(
name|dbTokens
operator|.
name|put
argument_list|(
name|key
argument_list|,
name|os
operator|.
name|data
argument_list|()
argument_list|)
operator|==
name|BFile
operator|.
name|UNKNOWN_ADDRESS
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Could not put index data for token '"
operator|+
name|token
operator|+
literal|"' in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|)
expr_stmt|;
comment|//TODO : throw an exception ?
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
operator|+
literal|" in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|ReadOnlyException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
operator|+
literal|" in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|(
name|Lock
operator|.
name|WRITE_LOCK
argument_list|)
expr_stmt|;
name|os
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
name|words
index|[
name|currentSection
index|]
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
comment|/** 		 * Remove the entries in the current list from the index. 		 */
comment|//TODO: use VariableInputStream
specifier|public
name|void
name|remove
parameter_list|()
block|{
comment|//Return early
if|if
condition|(
name|doc
operator|==
literal|null
condition|)
return|return;
specifier|final
name|int
name|collectionId
init|=
name|this
operator|.
name|doc
operator|.
name|getCollection
argument_list|()
operator|.
name|getId
argument_list|()
decl_stmt|;
specifier|final
name|Lock
name|lock
init|=
name|dbTokens
operator|.
name|getLock
argument_list|()
decl_stmt|;
for|for
control|(
name|byte
name|currentSection
init|=
literal|0
init|;
name|currentSection
operator|<=
name|QNAME_SECTION
condition|;
name|currentSection
operator|++
control|)
block|{
comment|//Not very necessary, but anyway...
switch|switch
condition|(
name|currentSection
condition|)
block|{
case|case
name|TEXT_SECTION
case|:
case|case
name|ATTRIBUTE_SECTION
case|:
case|case
name|QNAME_SECTION
case|:
break|break;
default|default :
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid section type in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|)
throw|;
block|}
for|for
control|(
name|Iterator
name|i
init|=
name|words
index|[
name|currentSection
index|]
operator|.
name|entrySet
argument_list|()
operator|.
name|iterator
argument_list|()
init|;
name|i
operator|.
name|hasNext
argument_list|()
condition|;
control|)
block|{
comment|//Compute a key for the token
name|Map
operator|.
name|Entry
name|entry
init|=
operator|(
name|Map
operator|.
name|Entry
operator|)
name|i
operator|.
name|next
argument_list|()
decl_stmt|;
name|OccurrenceList
name|storedOccurencesList
init|=
operator|(
name|OccurrenceList
operator|)
name|entry
operator|.
name|getValue
argument_list|()
decl_stmt|;
name|Object
name|token
init|=
name|entry
operator|.
name|getKey
argument_list|()
decl_stmt|;
name|Value
name|key
decl_stmt|;
if|if
condition|(
name|currentSection
operator|==
name|QNAME_SECTION
condition|)
block|{
name|QNameTerm
name|term
init|=
operator|(
name|QNameTerm
operator|)
name|token
decl_stmt|;
name|key
operator|=
operator|new
name|QNameWordRef
argument_list|(
name|collectionId
argument_list|,
name|term
operator|.
name|qname
argument_list|,
name|term
operator|.
name|term
argument_list|,
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getSymbols
argument_list|()
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|key
operator|=
operator|new
name|WordRef
argument_list|(
name|collectionId
argument_list|,
name|token
operator|.
name|toString
argument_list|()
argument_list|)
expr_stmt|;
block|}
name|OccurrenceList
name|newOccurencesList
init|=
operator|new
name|OccurrenceList
argument_list|()
decl_stmt|;
name|os
operator|.
name|clear
argument_list|()
expr_stmt|;
try|try
block|{
name|lock
operator|.
name|acquire
argument_list|(
name|Lock
operator|.
name|WRITE_LOCK
argument_list|)
expr_stmt|;
name|Value
name|value
init|=
name|dbTokens
operator|.
name|get
argument_list|(
name|key
argument_list|)
decl_stmt|;
if|if
condition|(
name|value
operator|==
literal|null
condition|)
continue|continue;
comment|//Add its data to the new list
name|VariableByteArrayInput
name|is
init|=
operator|new
name|VariableByteArrayInput
argument_list|(
name|value
operator|.
name|getData
argument_list|()
argument_list|)
decl_stmt|;
while|while
condition|(
name|is
operator|.
name|available
argument_list|()
operator|>
literal|0
condition|)
block|{
name|int
name|storedDocId
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
name|byte
name|storedSection
init|=
name|is
operator|.
name|readByte
argument_list|()
decl_stmt|;
name|int
name|termCount
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
comment|//Read (variable) length of node IDs + frequency + offsets
name|int
name|length
init|=
name|is
operator|.
name|readFixedInt
argument_list|()
decl_stmt|;
if|if
condition|(
name|storedSection
operator|!=
name|currentSection
operator|||
name|storedDocId
operator|!=
name|this
operator|.
name|doc
operator|.
name|getDocId
argument_list|()
condition|)
block|{
comment|// data are related to another section or document:
comment|// append them to any existing data
name|os
operator|.
name|writeInt
argument_list|(
name|storedDocId
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeByte
argument_list|(
name|storedSection
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeInt
argument_list|(
name|termCount
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeFixedInt
argument_list|(
name|length
argument_list|)
expr_stmt|;
name|is
operator|.
name|copyRaw
argument_list|(
name|os
argument_list|,
name|length
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// data are related to our section and document:
comment|// feed the new list with the GIDs
name|NodeId
name|previous
init|=
literal|null
decl_stmt|;
for|for
control|(
name|int
name|m
init|=
literal|0
init|;
name|m
operator|<
name|termCount
condition|;
name|m
operator|++
control|)
block|{
name|NodeId
name|nodeId
init|=
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getNodeFactory
argument_list|()
operator|.
name|createFromStream
argument_list|(
name|previous
argument_list|,
name|is
argument_list|)
decl_stmt|;
name|previous
operator|=
name|nodeId
expr_stmt|;
name|int
name|freq
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
comment|// add the node to the new list if it is not
comment|// in the list of removed nodes
if|if
condition|(
operator|!
name|storedOccurencesList
operator|.
name|contains
argument_list|(
name|nodeId
argument_list|)
condition|)
block|{
for|for
control|(
name|int
name|n
init|=
literal|0
init|;
name|n
operator|<
name|freq
condition|;
name|n
operator|++
control|)
block|{
name|newOccurencesList
operator|.
name|add
argument_list|(
name|nodeId
argument_list|,
name|is
operator|.
name|readInt
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
name|is
operator|.
name|skip
argument_list|(
name|freq
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|//append the data from the new list
if|if
condition|(
name|newOccurencesList
operator|.
name|getSize
argument_list|()
operator|>
literal|0
condition|)
block|{
comment|//Don't forget this one
name|newOccurencesList
operator|.
name|sort
argument_list|()
expr_stmt|;
name|os
operator|.
name|writeInt
argument_list|(
name|this
operator|.
name|doc
operator|.
name|getDocId
argument_list|()
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeByte
argument_list|(
name|currentSection
argument_list|)
expr_stmt|;
name|os
operator|.
name|writeInt
argument_list|(
name|newOccurencesList
operator|.
name|getTermCount
argument_list|()
argument_list|)
expr_stmt|;
comment|//Mark position
name|int
name|lenOffset
init|=
name|os
operator|.
name|position
argument_list|()
decl_stmt|;
comment|//Dummy value : actual one will be written below
name|os
operator|.
name|writeFixedInt
argument_list|(
literal|0
argument_list|)
expr_stmt|;
name|NodeId
name|previous
init|=
literal|null
decl_stmt|;
for|for
control|(
name|int
name|m
init|=
literal|0
init|;
name|m
operator|<
name|newOccurencesList
operator|.
name|getSize
argument_list|()
condition|;
control|)
block|{
name|previous
operator|=
name|newOccurencesList
operator|.
name|getNode
argument_list|(
name|m
argument_list|)
operator|.
name|write
argument_list|(
name|previous
argument_list|,
name|os
argument_list|)
expr_stmt|;
name|int
name|freq
init|=
name|newOccurencesList
operator|.
name|getOccurrences
argument_list|(
name|m
argument_list|)
decl_stmt|;
name|os
operator|.
name|writeInt
argument_list|(
name|freq
argument_list|)
expr_stmt|;
for|for
control|(
name|int
name|n
init|=
literal|0
init|;
name|n
operator|<
name|freq
condition|;
name|n
operator|++
control|)
block|{
name|os
operator|.
name|writeInt
argument_list|(
name|newOccurencesList
operator|.
name|getOffset
argument_list|(
name|m
operator|+
name|n
argument_list|)
argument_list|)
expr_stmt|;
block|}
name|m
operator|+=
name|freq
expr_stmt|;
block|}
comment|//Write (variable) length of node IDs + frequency + offsets
name|os
operator|.
name|writeFixedInt
argument_list|(
name|lenOffset
argument_list|,
name|os
operator|.
name|position
argument_list|()
operator|-
name|lenOffset
operator|-
name|LENGTH_NODE_IDS_FREQ_OFFSETS
argument_list|)
expr_stmt|;
block|}
comment|//Store the data
if|if
condition|(
name|os
operator|.
name|data
argument_list|()
operator|.
name|size
argument_list|()
operator|==
literal|0
condition|)
name|dbTokens
operator|.
name|remove
argument_list|(
name|key
argument_list|)
expr_stmt|;
if|else if
condition|(
name|dbTokens
operator|.
name|update
argument_list|(
name|value
operator|.
name|getAddress
argument_list|()
argument_list|,
name|key
argument_list|,
name|os
operator|.
name|data
argument_list|()
argument_list|)
operator|==
name|BFile
operator|.
name|UNKNOWN_ADDRESS
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Could not update index data for token '"
operator|+
name|token
operator|+
literal|"' in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|)
expr_stmt|;
comment|//TODO : throw an exception ?
block|}
block|}
catch|catch
parameter_list|(
name|LockException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|warn
argument_list|(
literal|"Failed to acquire lock for '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|//} catch (ReadOnlyException e) {
comment|//LOG.warn("Read-only error on '" + dbTokens.getFile().getName() + "' (inverted index)", e);
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
operator|+
literal|"' in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"' (inverted index)"
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|lock
operator|.
name|release
argument_list|(
name|Lock
operator|.
name|WRITE_LOCK
argument_list|)
expr_stmt|;
name|os
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
name|words
index|[
name|currentSection
index|]
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
block|}
specifier|private
class|class
name|IndexCallback
implements|implements
name|BTreeCallback
block|{
name|List
name|matches
init|=
operator|new
name|ArrayList
argument_list|()
decl_stmt|;
name|TermMatcher
name|matcher
decl_stmt|;
name|XQueryContext
name|context
decl_stmt|;
specifier|public
name|IndexCallback
parameter_list|(
name|XQueryContext
name|context
parameter_list|,
name|TermMatcher
name|matcher
parameter_list|)
block|{
name|this
operator|.
name|matcher
operator|=
name|matcher
expr_stmt|;
name|this
operator|.
name|context
operator|=
name|context
expr_stmt|;
block|}
specifier|public
name|String
index|[]
name|getMatches
parameter_list|()
block|{
name|String
index|[]
name|a
init|=
operator|new
name|String
index|[
name|matches
operator|.
name|size
argument_list|()
index|]
decl_stmt|;
return|return
operator|(
name|String
index|[]
operator|)
name|matches
operator|.
name|toArray
argument_list|(
name|a
argument_list|)
return|;
block|}
comment|/* (non-Javadoc) 		 * @see org.dbxml.core.filer.BTreeCallback#indexInfo(org.dbxml.core.data.Value, long) 		 */
specifier|public
name|boolean
name|indexInfo
parameter_list|(
name|Value
name|key
parameter_list|,
name|long
name|pointer
parameter_list|)
throws|throws
name|TerminatedException
block|{
if|if
condition|(
name|context
operator|!=
literal|null
condition|)
name|context
operator|.
name|proceed
argument_list|()
expr_stmt|;
try|try
block|{
specifier|final
name|String
name|word
init|=
operator|new
name|String
argument_list|(
name|key
operator|.
name|getData
argument_list|()
argument_list|,
name|Collection
operator|.
name|LENGTH_COLLECTION_ID
argument_list|,
name|key
operator|.
name|getLength
argument_list|()
operator|-
name|Collection
operator|.
name|LENGTH_COLLECTION_ID
argument_list|,
literal|"UTF-8"
argument_list|)
decl_stmt|;
if|if
condition|(
name|matcher
operator|.
name|matches
argument_list|(
name|word
argument_list|)
condition|)
name|matches
operator|.
name|add
argument_list|(
name|word
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
catch|catch
parameter_list|(
name|UnsupportedEncodingException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
block|}
specifier|private
specifier|final
class|class
name|SearchCallback
implements|implements
name|BTreeCallback
block|{
name|DocumentSet
name|docs
decl_stmt|;
name|TermMatcher
name|matcher
decl_stmt|;
name|NodeSet
name|result
decl_stmt|;
name|NodeSet
name|contextSet
decl_stmt|;
name|int
name|axis
decl_stmt|;
name|XQueryContext
name|context
decl_stmt|;
name|XMLString
name|word
init|=
operator|new
name|XMLString
argument_list|(
literal|64
argument_list|)
decl_stmt|;
name|QName
name|qname
decl_stmt|;
specifier|public
name|SearchCallback
parameter_list|(
name|XQueryContext
name|context
parameter_list|,
name|TermMatcher
name|comparator
parameter_list|,
name|NodeSet
name|result
parameter_list|,
name|NodeSet
name|contextSet
parameter_list|,
name|int
name|axis
parameter_list|,
name|DocumentSet
name|docs
parameter_list|,
name|QName
name|qname
parameter_list|)
block|{
name|this
operator|.
name|matcher
operator|=
name|comparator
expr_stmt|;
name|this
operator|.
name|result
operator|=
name|result
expr_stmt|;
name|this
operator|.
name|docs
operator|=
name|docs
expr_stmt|;
name|this
operator|.
name|contextSet
operator|=
name|contextSet
expr_stmt|;
name|this
operator|.
name|context
operator|=
name|context
expr_stmt|;
name|this
operator|.
name|qname
operator|=
name|qname
expr_stmt|;
name|this
operator|.
name|axis
operator|=
name|axis
expr_stmt|;
block|}
specifier|public
name|boolean
name|indexInfo
parameter_list|(
name|Value
name|key
parameter_list|,
name|long
name|pointer
parameter_list|)
throws|throws
name|TerminatedException
block|{
name|VariableByteInput
name|is
decl_stmt|;
try|try
block|{
name|is
operator|=
name|dbTokens
operator|.
name|getAsStream
argument_list|(
name|pointer
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
name|word
operator|.
name|reuse
argument_list|()
expr_stmt|;
if|if
condition|(
name|qname
operator|==
literal|null
condition|)
name|WordRef
operator|.
name|decode
argument_list|(
name|key
argument_list|,
name|word
argument_list|)
expr_stmt|;
else|else
name|QNameWordRef
operator|.
name|decode
argument_list|(
name|key
argument_list|,
name|word
argument_list|)
expr_stmt|;
if|if
condition|(
name|matcher
operator|.
name|matches
argument_list|(
name|word
argument_list|)
condition|)
block|{
try|try
block|{
while|while
condition|(
name|is
operator|.
name|available
argument_list|()
operator|>
literal|0
condition|)
block|{
if|if
condition|(
name|context
operator|!=
literal|null
condition|)
name|context
operator|.
name|proceed
argument_list|()
expr_stmt|;
name|int
name|storedDocId
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
name|byte
name|storedSection
init|=
name|is
operator|.
name|readByte
argument_list|()
decl_stmt|;
name|int
name|termCount
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
comment|//Read (variable) length of node IDs + frequency + offsets
name|int
name|length
init|=
name|is
operator|.
name|readFixedInt
argument_list|()
decl_stmt|;
name|DocumentImpl
name|storedDocument
init|=
name|docs
operator|.
name|getDoc
argument_list|(
name|storedDocId
argument_list|)
decl_stmt|;
comment|//Exit if the document is not concerned
if|if
condition|(
name|storedDocument
operator|==
literal|null
condition|)
block|{
name|is
operator|.
name|skipBytes
argument_list|(
name|length
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|NodeId
name|previous
init|=
literal|null
decl_stmt|;
for|for
control|(
name|int
name|m
init|=
literal|0
init|;
name|m
operator|<
name|termCount
condition|;
name|m
operator|++
control|)
block|{
name|NodeId
name|nodeId
init|=
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getNodeFactory
argument_list|()
operator|.
name|createFromStream
argument_list|(
name|previous
argument_list|,
name|is
argument_list|)
decl_stmt|;
name|previous
operator|=
name|nodeId
expr_stmt|;
name|int
name|freq
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
name|NodeProxy
name|storedNode
decl_stmt|;
switch|switch
condition|(
name|storedSection
condition|)
block|{
case|case
name|TEXT_SECTION
case|:
name|storedNode
operator|=
operator|new
name|NodeProxy
argument_list|(
name|storedDocument
argument_list|,
name|nodeId
argument_list|,
name|Node
operator|.
name|TEXT_NODE
argument_list|)
expr_stmt|;
break|break;
case|case
name|ATTRIBUTE_SECTION
case|:
name|storedNode
operator|=
operator|new
name|NodeProxy
argument_list|(
name|storedDocument
argument_list|,
name|nodeId
argument_list|,
name|Node
operator|.
name|ATTRIBUTE_NODE
argument_list|)
expr_stmt|;
break|break;
case|case
name|QNAME_SECTION
case|:
name|storedNode
operator|=
operator|new
name|NodeProxy
argument_list|(
name|storedDocument
argument_list|,
name|nodeId
argument_list|,
name|qname
operator|.
name|getNameType
argument_list|()
operator|==
name|ElementValue
operator|.
name|ATTRIBUTE
condition|?
name|Node
operator|.
name|ATTRIBUTE_NODE
else|:
name|Node
operator|.
name|ELEMENT_NODE
argument_list|)
expr_stmt|;
break|break;
default|default :
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid section type in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|)
throw|;
block|}
if|if
condition|(
name|contextSet
operator|!=
literal|null
condition|)
block|{
name|NodeProxy
name|parentNode
decl_stmt|;
switch|switch
condition|(
name|storedSection
condition|)
block|{
case|case
name|TEXT_SECTION
case|:
case|case
name|QNAME_SECTION
case|:
name|parentNode
operator|=
name|contextSet
operator|.
name|parentWithChild
argument_list|(
name|storedNode
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|,
name|NodeProxy
operator|.
name|UNKNOWN_NODE_LEVEL
argument_list|)
expr_stmt|;
break|break;
case|case
name|ATTRIBUTE_SECTION
case|:
if|if
condition|(
name|contextSet
operator|instanceof
name|VirtualNodeSet
condition|)
block|{
name|parentNode
operator|=
name|contextSet
operator|.
name|parentWithChild
argument_list|(
name|storedNode
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|,
name|NodeProxy
operator|.
name|UNKNOWN_NODE_LEVEL
argument_list|)
expr_stmt|;
if|if
condition|(
name|parentNode
operator|!=
literal|null
operator|&&
name|parentNode
operator|.
name|getNodeId
argument_list|()
operator|.
name|equals
argument_list|(
name|nodeId
argument_list|)
condition|)
name|parentNode
operator|=
literal|null
expr_stmt|;
block|}
else|else
block|{
name|parentNode
operator|=
name|contextSet
operator|.
name|get
argument_list|(
name|storedNode
argument_list|)
expr_stmt|;
block|}
break|break;
default|default :
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid section type in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|)
throw|;
block|}
if|if
condition|(
name|parentNode
operator|!=
literal|null
condition|)
block|{
name|Match
name|match
init|=
operator|new
name|FTMatch
argument_list|(
operator|-
literal|1
argument_list|,
name|nodeId
argument_list|,
name|word
operator|.
name|toString
argument_list|()
argument_list|,
name|freq
argument_list|)
decl_stmt|;
name|readOccurrences
argument_list|(
name|freq
argument_list|,
name|is
argument_list|,
name|match
argument_list|,
name|word
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
name|int
name|sizeHint
init|=
name|contextSet
operator|.
name|getSizeHint
argument_list|(
name|storedDocument
argument_list|)
decl_stmt|;
if|if
condition|(
name|axis
operator|==
name|NodeSet
operator|.
name|ANCESTOR
condition|)
block|{
name|parentNode
operator|.
name|addMatch
argument_list|(
name|match
argument_list|)
expr_stmt|;
name|result
operator|.
name|add
argument_list|(
name|parentNode
argument_list|,
name|sizeHint
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|storedNode
operator|.
name|addMatch
argument_list|(
name|match
argument_list|)
expr_stmt|;
name|result
operator|.
name|add
argument_list|(
name|storedNode
argument_list|,
name|sizeHint
argument_list|)
expr_stmt|;
block|}
block|}
else|else
name|is
operator|.
name|skip
argument_list|(
name|freq
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Match
name|match
init|=
operator|new
name|FTMatch
argument_list|(
operator|-
literal|1
argument_list|,
name|nodeId
argument_list|,
name|word
operator|.
name|toString
argument_list|()
argument_list|,
name|freq
argument_list|)
decl_stmt|;
name|readOccurrences
argument_list|(
name|freq
argument_list|,
name|is
argument_list|,
name|match
argument_list|,
name|word
operator|.
name|length
argument_list|()
argument_list|)
expr_stmt|;
name|storedNode
operator|.
name|addMatch
argument_list|(
name|match
argument_list|)
expr_stmt|;
name|result
operator|.
name|add
argument_list|(
name|storedNode
argument_list|,
name|Constants
operator|.
name|NO_SIZE_HINT
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|//} catch (EOFException e) {
comment|// EOFExceptions are normal
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
operator|+
literal|" in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|//TODO : return early -pb
block|}
block|}
comment|//TOUNDERSTAND : why sort here ? -pb
if|if
condition|(
name|contextSet
operator|!=
literal|null
condition|)
operator|(
operator|(
name|NewArrayNodeSet
operator|)
name|result
operator|)
operator|.
name|sort
argument_list|()
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
specifier|private
specifier|final
class|class
name|IndexScanCallback
implements|implements
name|BTreeCallback
block|{
specifier|private
name|DocumentSet
name|docs
decl_stmt|;
specifier|private
name|NodeSet
name|contextSet
decl_stmt|;
specifier|private
name|Map
name|map
init|=
operator|new
name|TreeMap
argument_list|()
decl_stmt|;
specifier|private
name|XMLString
name|word
init|=
operator|new
name|XMLString
argument_list|(
literal|64
argument_list|)
decl_stmt|;
specifier|private
name|boolean
name|byQName
decl_stmt|;
name|IndexScanCallback
parameter_list|(
name|DocumentSet
name|docs
parameter_list|,
name|NodeSet
name|contextSet
parameter_list|,
name|boolean
name|byQName
parameter_list|)
block|{
name|this
operator|.
name|docs
operator|=
name|docs
expr_stmt|;
name|this
operator|.
name|contextSet
operator|=
name|contextSet
expr_stmt|;
name|this
operator|.
name|byQName
operator|=
name|byQName
expr_stmt|;
block|}
comment|/* (non-Javadoc) 		 * @see org.dbxml.core.filer.BTreeCallback#indexInfo(org.dbxml.core.data.Value, long) 		 */
specifier|public
name|boolean
name|indexInfo
parameter_list|(
name|Value
name|key
parameter_list|,
name|long
name|pointer
parameter_list|)
throws|throws
name|TerminatedException
block|{
name|word
operator|.
name|reuse
argument_list|()
expr_stmt|;
if|if
condition|(
name|byQName
condition|)
name|QNameWordRef
operator|.
name|decode
argument_list|(
name|key
argument_list|,
name|word
argument_list|)
expr_stmt|;
else|else
name|WordRef
operator|.
name|decode
argument_list|(
name|key
argument_list|,
name|word
argument_list|)
expr_stmt|;
specifier|final
name|String
name|term
init|=
name|word
operator|.
name|toString
argument_list|()
decl_stmt|;
name|VariableByteInput
name|is
decl_stmt|;
try|try
block|{
name|is
operator|=
name|dbTokens
operator|.
name|getAsStream
argument_list|(
name|pointer
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
try|try
block|{
while|while
condition|(
name|is
operator|.
name|available
argument_list|()
operator|>
literal|0
condition|)
block|{
name|boolean
name|docAdded
init|=
literal|false
decl_stmt|;
name|int
name|storedDocId
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
name|byte
name|storedSection
init|=
name|is
operator|.
name|readByte
argument_list|()
decl_stmt|;
name|int
name|termCount
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
comment|//Read (variable) length of node IDs + frequency + offsets
name|int
name|length
init|=
name|is
operator|.
name|readFixedInt
argument_list|()
decl_stmt|;
name|DocumentImpl
name|storedDocument
init|=
name|docs
operator|.
name|getDoc
argument_list|(
name|storedDocId
argument_list|)
decl_stmt|;
comment|//Exit if the document is not concerned
if|if
condition|(
name|storedDocument
operator|==
literal|null
condition|)
block|{
name|is
operator|.
name|skipBytes
argument_list|(
name|length
argument_list|)
expr_stmt|;
continue|continue;
block|}
name|NodeId
name|previous
init|=
literal|null
decl_stmt|;
for|for
control|(
name|int
name|m
init|=
literal|0
init|;
name|m
operator|<
name|termCount
condition|;
name|m
operator|++
control|)
block|{
name|NodeId
name|nodeId
init|=
name|broker
operator|.
name|getBrokerPool
argument_list|()
operator|.
name|getNodeFactory
argument_list|()
operator|.
name|createFromStream
argument_list|(
name|previous
argument_list|,
name|is
argument_list|)
decl_stmt|;
name|previous
operator|=
name|nodeId
expr_stmt|;
name|int
name|freq
init|=
name|is
operator|.
name|readInt
argument_list|()
decl_stmt|;
name|is
operator|.
name|skip
argument_list|(
name|freq
argument_list|)
expr_stmt|;
if|if
condition|(
name|contextSet
operator|!=
literal|null
condition|)
block|{
name|boolean
name|include
init|=
literal|false
decl_stmt|;
name|NodeProxy
name|parentNode
init|=
name|contextSet
operator|.
name|parentWithChild
argument_list|(
name|storedDocument
argument_list|,
name|nodeId
argument_list|,
literal|false
argument_list|,
literal|true
argument_list|)
decl_stmt|;
switch|switch
condition|(
name|storedSection
condition|)
block|{
case|case
name|TEXT_SECTION
case|:
case|case
name|QNAME_SECTION
case|:
comment|//TODO : also test on Node.TEXT_NODE like below ? -pb
name|include
operator|=
operator|(
name|parentNode
operator|!=
literal|null
operator|)
expr_stmt|;
break|break;
case|case
name|ATTRIBUTE_SECTION
case|:
name|include
operator|=
operator|(
name|parentNode
operator|!=
literal|null
operator|&&
name|parentNode
operator|.
name|getNodeType
argument_list|()
operator|==
name|Node
operator|.
name|ATTRIBUTE_NODE
operator|)
expr_stmt|;
break|break;
default|default :
throw|throw
operator|new
name|IllegalArgumentException
argument_list|(
literal|"Invalid section type  in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|)
throw|;
block|}
if|if
condition|(
name|include
condition|)
block|{
name|Occurrences
name|oc
init|=
operator|(
name|Occurrences
operator|)
name|map
operator|.
name|get
argument_list|(
name|term
argument_list|)
decl_stmt|;
if|if
condition|(
name|oc
operator|==
literal|null
condition|)
block|{
name|oc
operator|=
operator|new
name|Occurrences
argument_list|(
name|term
argument_list|)
expr_stmt|;
name|map
operator|.
name|put
argument_list|(
name|term
argument_list|,
name|oc
argument_list|)
expr_stmt|;
block|}
if|if
condition|(
operator|!
name|docAdded
condition|)
block|{
name|oc
operator|.
name|addDocument
argument_list|(
name|storedDocument
argument_list|)
expr_stmt|;
name|docAdded
operator|=
literal|true
expr_stmt|;
block|}
name|oc
operator|.
name|addOccurrences
argument_list|(
name|freq
argument_list|)
expr_stmt|;
block|}
block|}
block|}
block|}
comment|//} catch(EOFException e) {
comment|//EOFExceptions are expected
block|}
catch|catch
parameter_list|(
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
operator|+
literal|" in '"
operator|+
name|dbTokens
operator|.
name|getFile
argument_list|()
operator|.
name|getName
argument_list|()
operator|+
literal|"'"
argument_list|,
name|e
argument_list|)
expr_stmt|;
comment|//TODO : return early -pb
block|}
return|return
literal|true
return|;
block|}
block|}
specifier|private
specifier|static
class|class
name|TermFrequencyList
block|{
specifier|protected
specifier|static
class|class
name|TermFreq
implements|implements
name|Comparable
block|{
name|long
name|l
decl_stmt|;
name|int
name|count
init|=
literal|1
decl_stmt|;
name|TermFreq
name|next
init|=
literal|null
decl_stmt|;
specifier|public
name|TermFreq
parameter_list|(
name|long
name|l
parameter_list|)
block|{
name|this
operator|.
name|l
operator|=
name|l
expr_stmt|;
block|}
specifier|public
name|void
name|increment
parameter_list|()
block|{
operator|++
name|count
expr_stmt|;
block|}
specifier|public
name|int
name|compareTo
parameter_list|(
name|Object
name|o
parameter_list|)
block|{
specifier|final
name|TermFreq
name|other
init|=
operator|(
name|TermFreq
operator|)
name|o
decl_stmt|;
if|if
condition|(
name|l
operator|==
name|other
operator|.
name|l
condition|)
return|return
name|Constants
operator|.
name|EQUAL
return|;
else|else
return|return
name|l
operator|<
name|other
operator|.
name|l
condition|?
name|Constants
operator|.
name|INFERIOR
else|:
name|Constants
operator|.
name|SUPERIOR
return|;
block|}
block|}
specifier|private
name|TermFreq
name|first
init|=
literal|null
decl_stmt|;
specifier|private
name|TermFreq
name|last
init|=
literal|null
decl_stmt|;
specifier|private
name|int
name|count
init|=
literal|0
decl_stmt|;
specifier|public
name|void
name|add
parameter_list|(
name|long
name|l
parameter_list|)
block|{
if|if
condition|(
name|first
operator|==
literal|null
condition|)
block|{
name|first
operator|=
operator|new
name|TermFreq
argument_list|(
name|l
argument_list|)
expr_stmt|;
name|last
operator|=
name|first
expr_stmt|;
block|}
else|else
block|{
name|TermFreq
name|next
init|=
operator|new
name|TermFreq
argument_list|(
name|l
argument_list|)
decl_stmt|;
name|last
operator|.
name|next
operator|=
name|next
expr_stmt|;
name|last
operator|=
name|next
expr_stmt|;
block|}
operator|++
name|count
expr_stmt|;
block|}
specifier|public
name|void
name|incLastTerm
parameter_list|()
block|{
if|if
condition|(
name|last
operator|!=
literal|null
condition|)
name|last
operator|.
name|increment
argument_list|()
expr_stmt|;
block|}
specifier|public
name|void
name|setLastTermFreq
parameter_list|(
name|int
name|freq
parameter_list|)
block|{
if|if
condition|(
name|last
operator|!=
literal|null
condition|)
name|last
operator|.
name|count
operator|=
name|freq
expr_stmt|;
block|}
specifier|public
name|long
name|getLast
parameter_list|()
block|{
if|if
condition|(
name|last
operator|!=
literal|null
condition|)
return|return
name|last
operator|.
name|l
return|;
else|else
return|return
operator|-
literal|1
return|;
block|}
specifier|public
name|boolean
name|contains
parameter_list|(
name|long
name|l
parameter_list|)
block|{
name|TermFreq
name|next
init|=
name|first
decl_stmt|;
while|while
condition|(
name|next
operator|!=
literal|null
condition|)
block|{
if|if
condition|(
name|next
operator|.
name|l
operator|==
name|l
condition|)
return|return
literal|true
return|;
name|next
operator|=
name|next
operator|.
name|next
expr_stmt|;
block|}
return|return
literal|false
return|;
block|}
specifier|public
name|int
name|getSize
parameter_list|()
block|{
return|return
name|count
return|;
block|}
specifier|public
name|TermFreq
index|[]
name|toArray
parameter_list|()
block|{
name|TermFreq
index|[]
name|data
init|=
operator|new
name|TermFreq
index|[
name|count
index|]
decl_stmt|;
name|TermFreq
name|next
init|=
name|first
decl_stmt|;
name|int
name|i
init|=
literal|0
decl_stmt|;
while|while
condition|(
name|next
operator|!=
literal|null
condition|)
block|{
name|data
index|[
name|i
operator|++
index|]
operator|=
name|next
expr_stmt|;
name|next
operator|=
name|next
operator|.
name|next
expr_stmt|;
block|}
return|return
name|data
return|;
block|}
block|}
specifier|private
specifier|final
specifier|static
class|class
name|WordRef
extends|extends
name|Value
block|{
specifier|public
specifier|static
name|int
name|LENGTH_IDX_TYPE
init|=
literal|1
decl_stmt|;
comment|//sizeof byte
specifier|public
specifier|static
name|int
name|OFFSET_IDX_TYPE
init|=
literal|0
decl_stmt|;
specifier|public
specifier|static
name|int
name|OFFSET_COLLECTION_ID
init|=
name|OFFSET_IDX_TYPE
operator|+
name|WordRef
operator|.
name|LENGTH_IDX_TYPE
decl_stmt|;
comment|//1
specifier|public
specifier|static
name|int
name|OFFSET_WORD
init|=
name|OFFSET_COLLECTION_ID
operator|+
name|Collection
operator|.
name|LENGTH_COLLECTION_ID
decl_stmt|;
comment|//3
specifier|public
name|WordRef
parameter_list|(
name|int
name|collectionId
parameter_list|)
block|{
name|len
operator|=
name|WordRef
operator|.
name|LENGTH_IDX_TYPE
operator|+
name|Collection
operator|.
name|LENGTH_COLLECTION_ID
expr_stmt|;
name|data
operator|=
operator|new
name|byte
index|[
name|len
index|]
expr_stmt|;
name|data
index|[
name|OFFSET_IDX_TYPE
index|]
operator|=
name|IDX_GENERIC
expr_stmt|;
name|ByteConversion
operator|.
name|intToByte
argument_list|(
name|collectionId
argument_list|,
name|data
argument_list|,
name|OFFSET_COLLECTION_ID
argument_list|)
expr_stmt|;
block|}
specifier|public
name|WordRef
parameter_list|(
name|int
name|collectionId
parameter_list|,
name|String
name|word
parameter_list|)
block|{
name|len
operator|=
name|WordRef
operator|.
name|LENGTH_IDX_TYPE
operator|+
name|Collection
operator|.
name|LENGTH_COLLECTION_ID
operator|+
name|UTF8
operator|.
name|encoded
argument_list|(
name|word
argument_list|)
expr_stmt|;
name|data
operator|=
operator|new
name|byte
index|[
name|len
index|]
expr_stmt|;
name|data
index|[
name|OFFSET_IDX_TYPE
index|]
operator|=
name|IDX_GENERIC
expr_stmt|;
name|ByteConversion
operator|.
name|intToByte
argument_list|(
name|collectionId
argument_list|,
name|data
argument_list|,
name|OFFSET_COLLECTION_ID
argument_list|)
expr_stmt|;
name|UTF8
operator|.
name|encode
argument_list|(
name|word
argument_list|,
name|data
argument_list|,
name|OFFSET_WORD
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|XMLString
name|decode
parameter_list|(
name|Value
name|key
parameter_list|,
name|XMLString
name|word
parameter_list|)
block|{
name|int
name|prefixLength
init|=
name|WordRef
operator|.
name|LENGTH_IDX_TYPE
operator|+
name|Collection
operator|.
name|LENGTH_COLLECTION_ID
decl_stmt|;
return|return
name|UTF8
operator|.
name|decode
argument_list|(
name|key
operator|.
name|getData
argument_list|()
argument_list|,
name|prefixLength
argument_list|,
name|key
operator|.
name|getLength
argument_list|()
operator|-
name|prefixLength
argument_list|,
name|word
argument_list|)
return|;
block|}
specifier|public
name|String
name|toString
parameter_list|()
block|{
if|if
condition|(
name|len
operator|>
name|OFFSET_WORD
condition|)
return|return
operator|new
name|String
argument_list|(
name|data
argument_list|,
name|OFFSET_WORD
argument_list|,
name|len
operator|-
name|OFFSET_WORD
argument_list|)
return|;
else|else
return|return
literal|"no word"
return|;
block|}
block|}
comment|//TODO : extend WordRef ?
specifier|private
specifier|final
specifier|static
class|class
name|QNameWordRef
extends|extends
name|Value
block|{
specifier|public
specifier|static
name|int
name|LENGTH_IDX_TYPE
init|=
literal|1
decl_stmt|;
comment|//sizeof byte
specifier|public
specifier|static
name|int
name|LENGTH_QNAME_TYPE
init|=
literal|1
decl_stmt|;
comment|//sizeof byte
specifier|public
specifier|static
name|int
name|OFFSET_IDX_TYPE
init|=
literal|0
decl_stmt|;
specifier|public
specifier|static
name|int
name|OFFSET_COLLECTION_ID
init|=
name|OFFSET_IDX_TYPE
operator|+
name|QNameWordRef
operator|.
name|LENGTH_IDX_TYPE
decl_stmt|;
comment|//1
specifier|public
specifier|static
name|int
name|OFFSET_QNAME_TYPE
init|=
name|OFFSET_COLLECTION_ID
operator|+
name|Collection
operator|.
name|LENGTH_COLLECTION_ID
decl_stmt|;
comment|//4
specifier|public
specifier|static
name|int
name|OFFSET_NS_URI
init|=
name|OFFSET_QNAME_TYPE
operator|+
name|LENGTH_QNAME_TYPE
decl_stmt|;
comment|//4
specifier|public
specifier|static
name|int
name|OFFSET_LOCAL_NAME
init|=
name|OFFSET_NS_URI
operator|+
name|SymbolTable
operator|.
name|LENGTH_NS_URI
decl_stmt|;
comment|//6
specifier|public
specifier|static
name|int
name|OFFSET_WORD
init|=
name|OFFSET_LOCAL_NAME
operator|+
name|SymbolTable
operator|.
name|LENGTH_LOCAL_NAME
decl_stmt|;
comment|//8
specifier|public
name|QNameWordRef
parameter_list|(
name|int
name|collectionId
parameter_list|)
block|{
name|len
operator|=
name|QNameWordRef
operator|.
name|LENGTH_IDX_TYPE
operator|+
name|Collection
operator|.
name|LENGTH_COLLECTION_ID
expr_stmt|;
name|data
operator|=
operator|new
name|byte
index|[
name|len
index|]
expr_stmt|;
name|data
index|[
name|OFFSET_IDX_TYPE
index|]
operator|=
name|IDX_QNAME
expr_stmt|;
name|ByteConversion
operator|.
name|intToByte
argument_list|(
name|collectionId
argument_list|,
name|data
argument_list|,
name|OFFSET_COLLECTION_ID
argument_list|)
expr_stmt|;
name|pos
operator|=
name|OFFSET_IDX_TYPE
expr_stmt|;
block|}
specifier|public
name|QNameWordRef
parameter_list|(
name|int
name|collectionId
parameter_list|,
name|QName
name|qname
parameter_list|,
name|SymbolTable
name|symbols
parameter_list|)
block|{
name|len
operator|=
name|QNameWordRef
operator|.
name|LENGTH_IDX_TYPE
operator|+
name|Collection
operator|.
name|LENGTH_COLLECTION_ID
operator|+
name|QNameWordRef
operator|.
name|LENGTH_QNAME_TYPE
operator|+
name|SymbolTable
operator|.
name|LENGTH_NS_URI
operator|+
name|SymbolTable
operator|.
name|LENGTH_LOCAL_NAME
expr_stmt|;
name|data
operator|=
operator|new
name|byte
index|[
name|len
index|]
expr_stmt|;
specifier|final
name|short
name|namespaceId
init|=
name|symbols
operator|.
name|getNSSymbol
argument_list|(
name|qname
operator|.
name|getNamespaceURI
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|short
name|localNameId
init|=
name|symbols
operator|.
name|getSymbol
argument_list|(
name|qname
operator|.
name|getLocalName
argument_list|()
argument_list|)
decl_stmt|;
name|data
index|[
name|OFFSET_IDX_TYPE
index|]
operator|=
name|IDX_QNAME
expr_stmt|;
name|ByteConversion
operator|.
name|intToByte
argument_list|(
name|collectionId
argument_list|,
name|data
argument_list|,
name|OFFSET_COLLECTION_ID
argument_list|)
expr_stmt|;
name|data
index|[
name|OFFSET_QNAME_TYPE
index|]
operator|=
name|qname
operator|.
name|getNameType
argument_list|()
expr_stmt|;
name|ByteConversion
operator|.
name|shortToByte
argument_list|(
name|namespaceId
argument_list|,
name|data
argument_list|,
name|OFFSET_NS_URI
argument_list|)
expr_stmt|;
name|ByteConversion
operator|.
name|shortToByte
argument_list|(
name|localNameId
argument_list|,
name|data
argument_list|,
name|OFFSET_LOCAL_NAME
argument_list|)
expr_stmt|;
block|}
specifier|public
name|QNameWordRef
parameter_list|(
name|int
name|collectionId
parameter_list|,
name|QName
name|qname
parameter_list|,
name|String
name|word
parameter_list|,
name|SymbolTable
name|symbols
parameter_list|)
block|{
name|len
operator|=
name|UTF8
operator|.
name|encoded
argument_list|(
name|word
argument_list|)
operator|+
name|QNameWordRef
operator|.
name|LENGTH_IDX_TYPE
operator|+
name|Collection
operator|.
name|LENGTH_COLLECTION_ID
operator|+
name|LENGTH_QNAME_TYPE
operator|+
name|SymbolTable
operator|.
name|LENGTH_NS_URI
operator|+
name|SymbolTable
operator|.
name|LENGTH_LOCAL_NAME
expr_stmt|;
name|data
operator|=
operator|new
name|byte
index|[
name|len
index|]
expr_stmt|;
specifier|final
name|short
name|namespaceId
init|=
name|symbols
operator|.
name|getNSSymbol
argument_list|(
name|qname
operator|.
name|getNamespaceURI
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|short
name|localNameId
init|=
name|symbols
operator|.
name|getSymbol
argument_list|(
name|qname
operator|.
name|getLocalName
argument_list|()
argument_list|)
decl_stmt|;
name|data
index|[
name|OFFSET_IDX_TYPE
index|]
operator|=
name|IDX_QNAME
expr_stmt|;
name|ByteConversion
operator|.
name|intToByte
argument_list|(
name|collectionId
argument_list|,
name|data
argument_list|,
name|OFFSET_COLLECTION_ID
argument_list|)
expr_stmt|;
name|data
index|[
name|OFFSET_QNAME_TYPE
index|]
operator|=
name|qname
operator|.
name|getNameType
argument_list|()
expr_stmt|;
name|ByteConversion
operator|.
name|shortToByte
argument_list|(
name|namespaceId
argument_list|,
name|data
argument_list|,
name|OFFSET_NS_URI
argument_list|)
expr_stmt|;
name|ByteConversion
operator|.
name|shortToByte
argument_list|(
name|localNameId
argument_list|,
name|data
argument_list|,
name|OFFSET_LOCAL_NAME
argument_list|)
expr_stmt|;
name|UTF8
operator|.
name|encode
argument_list|(
name|word
argument_list|,
name|data
argument_list|,
name|OFFSET_WORD
argument_list|)
expr_stmt|;
block|}
specifier|public
specifier|static
name|XMLString
name|decode
parameter_list|(
name|Value
name|key
parameter_list|,
name|XMLString
name|word
parameter_list|)
block|{
name|int
name|prefixLength
init|=
name|QNameWordRef
operator|.
name|LENGTH_IDX_TYPE
operator|+
name|Collection
operator|.
name|LENGTH_COLLECTION_ID
operator|+
name|QNameWordRef
operator|.
name|LENGTH_QNAME_TYPE
operator|+
name|SymbolTable
operator|.
name|LENGTH_NS_URI
operator|+
name|SymbolTable
operator|.
name|LENGTH_LOCAL_NAME
decl_stmt|;
return|return
name|UTF8
operator|.
name|decode
argument_list|(
name|key
operator|.
name|getData
argument_list|()
argument_list|,
name|prefixLength
argument_list|,
name|key
operator|.
name|getLength
argument_list|()
operator|-
name|prefixLength
argument_list|,
name|word
argument_list|)
return|;
block|}
specifier|public
name|String
name|toString
parameter_list|()
block|{
if|if
condition|(
name|len
operator|>
name|OFFSET_WORD
condition|)
return|return
operator|new
name|String
argument_list|(
name|data
argument_list|,
name|OFFSET_WORD
argument_list|,
name|len
operator|-
name|OFFSET_WORD
argument_list|)
return|;
else|else
return|return
literal|"no word"
return|;
block|}
block|}
block|}
end_class

end_unit

