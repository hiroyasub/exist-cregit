begin_unit|revision:1.0.0;language:Java;cregit-version:0.0.1
begin_comment
comment|/*  * Copyright (C) 2018 Adam Retter  *  * This program is free software; you can redistribute it and/or  * modify it under the terms of the GNU Lesser General Public License  * as published by the Free Software Foundation; either version 2  * of the License, or (at your option) any later version.  *  * This program is distributed in the hope that it will be useful,  * but WITHOUT ANY WARRANTY; without even the implied warranty of  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the  * GNU Lesser General Public License for more details.  *  * You should have received a copy of the GNU Lesser General Public  * License along with this library; if not, write to the Free Software  * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA  */
end_comment

begin_package
package|package
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|blob
package|;
end_package

begin_import
import|import
name|com
operator|.
name|evolvedbinary
operator|.
name|j8fu
operator|.
name|Try
import|;
end_import

begin_import
import|import
name|com
operator|.
name|evolvedbinary
operator|.
name|j8fu
operator|.
name|tuple
operator|.
name|Tuple2
import|;
end_import

begin_import
import|import
name|com
operator|.
name|evolvedbinary
operator|.
name|j8fu
operator|.
name|tuple
operator|.
name|Tuple3
import|;
end_import

begin_import
import|import
name|net
operator|.
name|jcip
operator|.
name|annotations
operator|.
name|ThreadSafe
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|commons
operator|.
name|io
operator|.
name|input
operator|.
name|CountingInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|logging
operator|.
name|log4j
operator|.
name|LogManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|apache
operator|.
name|logging
operator|.
name|log4j
operator|.
name|Logger
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|Database
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|backup
operator|.
name|RawDataBackup
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|journal
operator|.
name|JournalException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|journal
operator|.
name|JournalManager
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|journal
operator|.
name|LogEntryTypes
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|journal
operator|.
name|LogException
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|txn
operator|.
name|Txn
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|txn
operator|.
name|TxnListener
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|FileUtils
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|UUIDGenerator
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|crypto
operator|.
name|digest
operator|.
name|DigestInputStream
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|crypto
operator|.
name|digest
operator|.
name|DigestType
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|crypto
operator|.
name|digest
operator|.
name|MessageDigest
import|;
end_import

begin_import
import|import
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|crypto
operator|.
name|digest
operator|.
name|StreamableDigest
import|;
end_import

begin_import
import|import
name|javax
operator|.
name|annotation
operator|.
name|Nullable
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FileNotFoundException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|FilterInputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|IOException
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|InputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|io
operator|.
name|OutputStream
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|ByteBuffer
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|channels
operator|.
name|SeekableByteChannel
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|Files
import|;
end_import

begin_import
import|import
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|Path
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|*
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|*
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicBoolean
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicInteger
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|concurrent
operator|.
name|atomic
operator|.
name|AtomicReference
import|;
end_import

begin_import
import|import
name|java
operator|.
name|util
operator|.
name|function
operator|.
name|Function
import|;
end_import

begin_import
import|import static
name|com
operator|.
name|evolvedbinary
operator|.
name|j8fu
operator|.
name|Try
operator|.
name|TaggedTryUnchecked
import|;
end_import

begin_import
import|import static
name|com
operator|.
name|evolvedbinary
operator|.
name|j8fu
operator|.
name|tuple
operator|.
name|Tuple
operator|.
name|Tuple
import|;
end_import

begin_import
import|import static
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|StandardCopyOption
operator|.
name|ATOMIC_MOVE
import|;
end_import

begin_import
import|import static
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|StandardCopyOption
operator|.
name|REPLACE_EXISTING
import|;
end_import

begin_import
import|import static
name|java
operator|.
name|nio
operator|.
name|file
operator|.
name|StandardOpenOption
operator|.
name|*
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|blob
operator|.
name|BlobLoggable
operator|.
name|LOG_STORE_BLOB_FILE
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|blob
operator|.
name|BlobLoggable
operator|.
name|LOG_UPDATE_BLOB_REF_COUNT
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|exist
operator|.
name|storage
operator|.
name|blob
operator|.
name|BlobStoreImpl
operator|.
name|BlobReference
operator|.
name|*
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|FileUtils
operator|.
name|fileName
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|HexEncoder
operator|.
name|bytesToHex
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|ThreadUtils
operator|.
name|nameInstanceThread
import|;
end_import

begin_import
import|import static
name|org
operator|.
name|exist
operator|.
name|util
operator|.
name|ThreadUtils
operator|.
name|newInstanceSubThreadGroup
import|;
end_import

begin_comment
comment|/**  * De-duplicating store for BLOBs (Binary Large Objects).  *  * Each unique BLOB is stored by checksum into a blob file on disk.  *  * For each BLOB a reference count and the number of active readers is maintained.  * Adding a BLOB which is already present increments the reference count only,  * it does not require any additional storage.  *  * Removing a BLOB decrements its reference count, BLOBs are only removed when  * their reference count reaches zero, the blob file itself is scheduled for deletion  * and will only be removed when there are no active readers and its reference is zero.  * When the scheduled action for deleting a blob file is realised, if another thread  * has meanwhile added a BLOB to the BLOB store where its blob file has the same  * checksum, then the BLOB's reference count will have increased from zero,  * therefore the schedule will not delete this now again active blob file, we call  * this feature "recycling".  *  * The Blob Store is backed to disk by a persistent store file which  * reflects the in-memory state of BlobStore.  *  * The persistent store file will grow for each unique blob added to  * the system, space is not reclaimed in the persistent file until  * {@link #compactPersistentReferences(ByteBuffer, Path)} is called,  * which typically only happens the next time the blob store is re-opened.  *  * Each unique blob typically takes up only 36 bytes in the  * persistent store file, but this can vary if a smaller or larger  * digestType is specified.  *  * On-line compaction of the persistent file could be added in  * future with relative ease if deemed necessary.  *  * The persistent file for the blob store has the format:  *  * [fileHeader entry+]  *  * fileHeader:          [magicNumber blobStoreVersion].  * magicNumber:         4 bytes. See {@link #BLOB_STORE_MAGIC_NUMBER}.  * blobStoreVersion:    2 bytes. java.lang.short, see {@link #BLOB_STORE_VERSION}.  *  * entry:               [blobChecksum blobReferenceCount]  * blobChecksum:        n-bytes determined by the constructed {@link MessageDigest}.  * blobReferenceCount:  4 bytes. java.lang.int.  *  * Note the persistent file may contain more than one entry  * for the same blobChecksum, however all entries previous to  * the last entry will have a blobReferenceCount of zero. The last  * entry will have the current blobReferenceCount which may be  * zero or more.  *     The use of {@code orphanedBlobFileIds} in the  * {@link #compactPersistentReferences(ByteBuffer, Path)} method  * makes sure to only delete blob files which have a final  * blobReferenceCount of zero.  *  * For performance, writing to the persistent store file,  * removing staged blob files, and deleting blob files are all  * asynchronous actions. To ensure the ability to achieve a consistent  * state after a system crash, the BLOB Store writes entries to a  * Journal WAL (Write-Ahead-Log) which is flushed to disk before each state  * changing operation. If the system restarts after a crash, then a recovery  * process will be performed from the entries in the WAL.  *  * Journal and Recovery of the BLOB Store works as follows:  *  *  Add Blob:  *    Writes two journal entries:  *      * StoreBlobFile(blobId, stagedUuid)  *      * UpdateBlobReferenceCount(blobId, currentCount, newCount + 1)  *  *      On crash recovery, firstly:  *          the StoreBlobFile will either be:  *              1. undone, which copies the blob file from the blob store to to the staging area,  *              2. redone, which copies the blob file from the staging area to the blob store,  *              3. or both undone and redone.  *          This is possible because the blob file in the staging area is ONLY deleted after  *          a COMMIT and CHECKPOINT have been written to the Journal, which means  *          that the staged file is always available for recovery, and that no  *          crash recovery of the staged file itself is needed  *  *          Deletion of the staged  *          file happens on a best effort basis, any files which were not deleted due  *          to a system crash, will be deleted upon restart (after recovery) when  *          the Blob Store is next opened.  *  *      Secondly:  *          the BlobReferenceCount will either be undone, redone, or both.  *  *  *  Remove Blob:  *      Writes a single journal entry:  *        *  UpdateBlobReferenceCount(blobId, currentCount, currentCount - 1)  *  *      On crash recovery the BlobReferenceCount will either be undone, redone,  *      or both.  *  *      It is worth noting that the actual blob file on disk is only ever deleted  *      after a COMMIT and CHECKPOINT have been written to the Journal, and then  *      only when it has zero references and zero readers. As it is only  *      deleted after a CHECKPOINT, there is no need for any crash recovery of the  *      disk file itself.  *  *      Deletion of the blob file happens on a best effort basis, any files which  *      were not deleted due to a system crash, will be deleted upon restart  *      (after recovery) by the {@link #compactPersistentReferences(ByteBuffer, Path)}  *      process when the Blob Store is next opened.  *  *  * @author<a href="mailto:adam@evolvedbinary.com">Adam Retter</a>  */
end_comment

begin_class
annotation|@
name|ThreadSafe
specifier|public
class|class
name|BlobStoreImpl
implements|implements
name|BlobStore
block|{
specifier|private
specifier|static
specifier|final
name|Logger
name|LOG
init|=
name|LogManager
operator|.
name|getLogger
argument_list|(
name|BlobStoreImpl
operator|.
name|class
argument_list|)
decl_stmt|;
comment|/**      * Maximum time to wait whilst trying add an      * item to the vacuum queue {@link #vacuumQueue}.      */
specifier|private
specifier|static
specifier|final
name|long
name|VACUUM_ENQUEUE_TIMEOUT
init|=
literal|5000
decl_stmt|;
comment|// 5 seconds
comment|/*      * Journal entry types      */
static|static
block|{
name|LogEntryTypes
operator|.
name|addEntryType
argument_list|(
name|LOG_STORE_BLOB_FILE
argument_list|,
name|StoreBlobFileLoggable
operator|::
operator|new
argument_list|)
expr_stmt|;
name|LogEntryTypes
operator|.
name|addEntryType
argument_list|(
name|LOG_UPDATE_BLOB_REF_COUNT
argument_list|,
name|UpdateBlobRefCountLoggable
operator|::
operator|new
argument_list|)
expr_stmt|;
block|}
comment|/**      * Length in bytes of the reference count.      */
specifier|static
specifier|final
name|int
name|REFERENCE_COUNT_LEN
init|=
literal|4
decl_stmt|;
comment|/**      * File header length      */
specifier|static
specifier|final
name|int
name|BLOB_STORE_HEADER_LEN
init|=
literal|6
decl_stmt|;
comment|/**      * File header - magic number      */
specifier|static
specifier|final
name|byte
index|[]
name|BLOB_STORE_MAGIC_NUMBER
init|=
block|{
literal|0x0E
block|,
literal|0x0D
block|,
literal|0x0B
block|,
literal|0x02
block|}
decl_stmt|;
comment|/**      * File header - blob store version      */
specifier|public
specifier|static
specifier|final
name|short
name|BLOB_STORE_VERSION
init|=
literal|1
decl_stmt|;
specifier|private
name|ByteBuffer
name|buffer
decl_stmt|;
specifier|private
name|SeekableByteChannel
name|channel
decl_stmt|;
comment|/**      * In-memory representation of the Blob Store.      */
specifier|private
name|ConcurrentMap
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|>
name|references
decl_stmt|;
comment|/**      * Queue for communicating between the thread calling      * the BlobStore and the {@link #persistentWriter} thread.      *      * Holds blob references which need to be updated in the      * blob stores persistent dbx file ({@link #persistentFile})      * on disk.      */
specifier|private
specifier|final
name|BlockingQueue
argument_list|<
name|Tuple3
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|,
name|Integer
argument_list|>
argument_list|>
name|persistQueue
init|=
operator|new
name|LinkedBlockingQueue
argument_list|<>
argument_list|()
decl_stmt|;
comment|/**      * Queue for communicating between the thread calling      * the BlobStore and the {@link #blobVacuum} thread.      *      * Head of the queue is the blob with the least active readers.      *      * Holds blob references which are scheduled to have their blob file      * removed from the blob file store.      */
specifier|private
specifier|final
name|BlockingQueue
argument_list|<
name|BlobVacuum
operator|.
name|Request
argument_list|>
name|vacuumQueue
init|=
operator|new
name|PriorityBlockingQueue
argument_list|<>
argument_list|()
decl_stmt|;
specifier|private
specifier|final
name|Database
name|database
decl_stmt|;
specifier|private
specifier|final
name|Path
name|persistentFile
decl_stmt|;
specifier|private
specifier|final
name|Path
name|blobDir
decl_stmt|;
specifier|private
specifier|final
name|Path
name|stagingDir
decl_stmt|;
specifier|private
specifier|final
name|DigestType
name|digestType
decl_stmt|;
comment|/**      * Enumeration of possible      * Blob Store states.      */
specifier|private
enum|enum
name|State
block|{
name|OPENING
block|,
name|OPEN
block|,
name|RECOVERY
block|,
name|CLOSING
block|,
name|CLOSED
block|}
comment|/**      * State of the Blob Store      */
specifier|private
specifier|final
name|AtomicReference
argument_list|<
name|State
argument_list|>
name|state
init|=
operator|new
name|AtomicReference
argument_list|<>
argument_list|(
name|State
operator|.
name|CLOSED
argument_list|)
decl_stmt|;
comment|/**      * Thread which updates the persistent blob      * store file on disk.      */
specifier|private
name|PersistentWriter
name|persistentWriter
decl_stmt|;
specifier|private
name|Thread
name|persistentWriterThread
decl_stmt|;
comment|/**      * Thread which deletes de-referenced      * blob files when there are no      * more readers.      */
specifier|private
name|BlobVacuum
name|blobVacuum
decl_stmt|;
specifier|private
name|Thread
name|blobVacuumThread
decl_stmt|;
comment|/**      * @param database the database that this BlobStore is operating within      * @param persistentFile the file path for the persistent blob store metadata.      * @param blobDir the directory to store BLOBs in.      * @param digestType the message digest type to use for creating checksums of the BLOBs.      */
specifier|public
name|BlobStoreImpl
parameter_list|(
specifier|final
name|Database
name|database
parameter_list|,
specifier|final
name|Path
name|persistentFile
parameter_list|,
specifier|final
name|Path
name|blobDir
parameter_list|,
specifier|final
name|DigestType
name|digestType
parameter_list|)
block|{
name|this
operator|.
name|database
operator|=
name|database
expr_stmt|;
name|this
operator|.
name|persistentFile
operator|=
name|persistentFile
expr_stmt|;
name|this
operator|.
name|blobDir
operator|=
name|blobDir
expr_stmt|;
name|this
operator|.
name|stagingDir
operator|=
name|blobDir
operator|.
name|resolve
argument_list|(
literal|"staging"
argument_list|)
expr_stmt|;
name|this
operator|.
name|digestType
operator|=
name|digestType
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|open
parameter_list|()
throws|throws
name|IOException
block|{
name|openBlobStore
argument_list|(
literal|false
argument_list|)
expr_stmt|;
comment|// thread group for the blob store
specifier|final
name|ThreadGroup
name|blobStoreThreadGroup
init|=
name|newInstanceSubThreadGroup
argument_list|(
name|database
argument_list|,
literal|"blob-store"
argument_list|)
decl_stmt|;
comment|// startup the persistent writer thread
name|this
operator|.
name|persistentWriter
operator|=
operator|new
name|PersistentWriter
argument_list|(
name|persistQueue
argument_list|,
name|buffer
argument_list|,
name|channel
argument_list|,
name|this
operator|::
name|abnormalPersistentWriterShutdown
argument_list|)
expr_stmt|;
name|this
operator|.
name|persistentWriterThread
operator|=
operator|new
name|Thread
argument_list|(
name|blobStoreThreadGroup
argument_list|,
name|persistentWriter
argument_list|,
name|nameInstanceThread
argument_list|(
name|database
argument_list|,
literal|"blob-store.persistent-writer"
argument_list|)
argument_list|)
expr_stmt|;
name|persistentWriterThread
operator|.
name|start
argument_list|()
expr_stmt|;
comment|// startup the blob vacuum thread
name|this
operator|.
name|blobVacuum
operator|=
operator|new
name|BlobVacuum
argument_list|(
name|vacuumQueue
argument_list|)
expr_stmt|;
name|this
operator|.
name|blobVacuumThread
operator|=
operator|new
name|Thread
argument_list|(
name|blobStoreThreadGroup
argument_list|,
name|blobVacuum
argument_list|,
name|nameInstanceThread
argument_list|(
name|database
argument_list|,
literal|"blob-store.vacuum"
argument_list|)
argument_list|)
expr_stmt|;
name|blobVacuumThread
operator|.
name|start
argument_list|()
expr_stmt|;
comment|// we are now open!
name|state
operator|.
name|set
argument_list|(
name|State
operator|.
name|OPEN
argument_list|)
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|openForRecovery
parameter_list|()
throws|throws
name|IOException
block|{
name|openBlobStore
argument_list|(
literal|true
argument_list|)
expr_stmt|;
name|state
operator|.
name|set
argument_list|(
name|State
operator|.
name|RECOVERY
argument_list|)
expr_stmt|;
block|}
comment|/**      * Opens the BLOB Store's persistent store file,      * and prepares the staging area.      *      * @param forRecovery true if the Blob Store is being opened for crash recovery, false otherwise      *      * @throws IOException if an error occurs whilst opening the BLOB Store      */
specifier|private
name|void
name|openBlobStore
parameter_list|(
specifier|final
name|boolean
name|forRecovery
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|state
operator|.
name|get
argument_list|()
operator|==
name|State
operator|.
name|OPEN
condition|)
block|{
if|if
condition|(
name|forRecovery
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"BlobStore is already open!"
argument_list|)
throw|;
block|}
else|else
block|{
return|return;
block|}
block|}
if|if
condition|(
operator|!
name|state
operator|.
name|compareAndSet
argument_list|(
name|State
operator|.
name|CLOSED
argument_list|,
name|State
operator|.
name|OPENING
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"BlobStore is not closed"
argument_list|)
throw|;
block|}
comment|// size the buffer to hold a complete entry
name|buffer
operator|=
name|ByteBuffer
operator|.
name|allocate
argument_list|(
name|digestType
operator|.
name|getDigestLengthBytes
argument_list|()
operator|+
name|REFERENCE_COUNT_LEN
argument_list|)
expr_stmt|;
try|try
block|{
comment|// open the dbx file
if|if
condition|(
name|Files
operator|.
name|exists
argument_list|(
name|persistentFile
argument_list|)
condition|)
block|{
if|if
condition|(
operator|!
name|forRecovery
condition|)
block|{
comment|// compact existing blob store file and then open
name|this
operator|.
name|references
operator|=
name|compactPersistentReferences
argument_list|(
name|buffer
argument_list|,
name|persistentFile
argument_list|)
expr_stmt|;
name|channel
operator|=
name|Files
operator|.
name|newByteChannel
argument_list|(
name|persistentFile
argument_list|,
name|WRITE
argument_list|)
expr_stmt|;
comment|/*                      * We are not recovering, so we can delete any staging area left over                      * from a previous running database instance                      */
name|FileUtils
operator|.
name|deleteQuietly
argument_list|(
name|stagingDir
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// recovery... so open the existing blob store file and just validate its header
name|channel
operator|=
name|Files
operator|.
name|newByteChannel
argument_list|(
name|persistentFile
argument_list|,
name|WRITE
argument_list|,
name|READ
argument_list|)
expr_stmt|;
name|validateFileHeader
argument_list|(
name|buffer
argument_list|,
name|persistentFile
argument_list|,
name|channel
argument_list|)
expr_stmt|;
block|}
block|}
else|else
block|{
comment|// open new blob store file
if|if
condition|(
name|forRecovery
condition|)
block|{
comment|// we are trying to recover, but there is no existing Blob Store!
throw|throw
operator|new
name|FileNotFoundException
argument_list|(
literal|"No Blob Store found at '"
operator|+
name|persistentFile
operator|.
name|toAbsolutePath
argument_list|()
operator|.
name|toString
argument_list|()
operator|+
literal|"' to recover!"
argument_list|)
throw|;
block|}
name|references
operator|=
operator|new
name|ConcurrentHashMap
argument_list|<>
argument_list|()
expr_stmt|;
name|channel
operator|=
name|Files
operator|.
name|newByteChannel
argument_list|(
name|persistentFile
argument_list|,
name|CREATE_NEW
argument_list|,
name|WRITE
argument_list|)
expr_stmt|;
name|writeFileHeader
argument_list|(
name|buffer
argument_list|,
name|channel
argument_list|)
expr_stmt|;
block|}
comment|// create the staging directory if it does not exist
name|Files
operator|.
name|createDirectories
argument_list|(
name|stagingDir
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
specifier|final
name|IOException
name|e
parameter_list|)
block|{
if|if
condition|(
name|channel
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|channel
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
specifier|final
name|IOException
name|ce
parameter_list|)
block|{
comment|// ignore
block|}
block|}
name|state
operator|.
name|set
argument_list|(
name|State
operator|.
name|CLOSED
argument_list|)
expr_stmt|;
throw|throw
name|e
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
comment|// check the blob store is open
if|if
condition|(
name|state
operator|.
name|get
argument_list|()
operator|==
name|State
operator|.
name|CLOSED
condition|)
block|{
return|return;
block|}
if|if
condition|(
name|state
operator|.
name|compareAndSet
argument_list|(
name|State
operator|.
name|OPEN
argument_list|,
name|State
operator|.
name|CLOSING
argument_list|)
condition|)
block|{
comment|// close up normally
name|normalClose
argument_list|()
expr_stmt|;
block|}
if|else if
condition|(
name|state
operator|.
name|compareAndSet
argument_list|(
name|State
operator|.
name|RECOVERY
argument_list|,
name|State
operator|.
name|CLOSING
argument_list|)
condition|)
block|{
comment|// close up after recovery was attempted
name|closeAfterRecoveryAttempt
argument_list|()
expr_stmt|;
block|}
else|else
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"BlobStore is not open"
argument_list|)
throw|;
block|}
block|}
comment|/**      * Closes the Blob Store.      *      * @throws IOException if an error occurs whilst closing the Blob Store      */
specifier|private
name|void
name|normalClose
parameter_list|()
throws|throws
name|IOException
block|{
try|try
block|{
comment|// shutdown the persistent writer
if|if
condition|(
name|persistentWriter
operator|!=
literal|null
condition|)
block|{
name|persistQueue
operator|.
name|put
argument_list|(
name|PersistentWriter
operator|.
name|POISON_PILL
argument_list|)
expr_stmt|;
block|}
name|persistentWriterThread
operator|.
name|join
argument_list|()
expr_stmt|;
comment|// shutdown the vacuum
if|if
condition|(
name|blobVacuum
operator|!=
literal|null
condition|)
block|{
name|blobVacuumThread
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
name|blobVacuumThread
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
specifier|final
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// Restore the interrupted status
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
finally|finally
block|{
name|closeBlobStore
argument_list|()
expr_stmt|;
comment|// we are now closed!
name|state
operator|.
name|set
argument_list|(
name|State
operator|.
name|CLOSED
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Closes the Blob Store after it was opened for Recovery.      */
specifier|private
name|void
name|closeAfterRecoveryAttempt
parameter_list|()
block|{
name|closeBlobStore
argument_list|()
expr_stmt|;
comment|// we are now closed!
name|state
operator|.
name|set
argument_list|(
name|State
operator|.
name|CLOSED
argument_list|)
expr_stmt|;
block|}
comment|/**      * Closes the resources associated      * with the Blob Store persistent file.      *      * Clears the {@link #buffer} and closes the {@link #channel}.      */
specifier|private
name|void
name|closeBlobStore
parameter_list|()
block|{
if|if
condition|(
name|buffer
operator|!=
literal|null
condition|)
block|{
name|buffer
operator|.
name|clear
argument_list|()
expr_stmt|;
name|buffer
operator|=
literal|null
expr_stmt|;
block|}
comment|// close the file channel
if|if
condition|(
name|channel
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|channel
operator|.
name|close
argument_list|()
expr_stmt|;
name|channel
operator|=
literal|null
expr_stmt|;
block|}
catch|catch
parameter_list|(
specifier|final
name|IOException
name|e
parameter_list|)
block|{
comment|// non-critical error
name|LOG
operator|.
name|error
argument_list|(
literal|"Error whilst closing blob.dbx: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
block|}
block|}
comment|/**      * Closes the BlobStore if the {@link #persistentWriter} has      * to shutdown due to abnormal circumstances.      *      * Only called when the Blob Store is in the {@link State#OPEN} state!      */
specifier|private
name|void
name|abnormalPersistentWriterShutdown
parameter_list|()
block|{
comment|// check the blob store is open
if|if
condition|(
name|state
operator|.
name|get
argument_list|()
operator|==
name|State
operator|.
name|CLOSED
condition|)
block|{
return|return;
block|}
if|if
condition|(
operator|!
name|state
operator|.
name|compareAndSet
argument_list|(
name|State
operator|.
name|OPEN
argument_list|,
name|State
operator|.
name|CLOSING
argument_list|)
condition|)
block|{
return|return;
block|}
try|try
block|{
comment|// NOTE: persistent writer thread will join when this method finishes!
comment|// shutdown the vacuum
if|if
condition|(
name|blobVacuum
operator|!=
literal|null
condition|)
block|{
name|blobVacuumThread
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
name|blobVacuumThread
operator|.
name|join
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
specifier|final
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// Restore the interrupted status
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
name|LOG
operator|.
name|error
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|closeBlobStore
argument_list|()
expr_stmt|;
comment|// we are now closed!
name|state
operator|.
name|set
argument_list|(
name|State
operator|.
name|CLOSED
argument_list|)
expr_stmt|;
block|}
block|}
comment|/**      * Compacts an existing Blob Store file.      *      * Reads the existing Blob Store file and copies non zero reference      * entries to a new Blob Store file. We call this compaction.      * Once complete, the existing file is replaced with the new file.      *      * @param persistentFile an existing persistentFile to compact.      *      * @return An in-memory representation of the compacted Blob Store      *      * @throws IOException if an error occurs during compaction.      */
specifier|private
name|ConcurrentMap
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|>
name|compactPersistentReferences
parameter_list|(
specifier|final
name|ByteBuffer
name|buffer
parameter_list|,
specifier|final
name|Path
name|persistentFile
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|ConcurrentMap
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|>
name|compactReferences
init|=
operator|new
name|ConcurrentHashMap
argument_list|<>
argument_list|()
decl_stmt|;
specifier|final
name|Path
name|compactPersistentFile
init|=
name|persistentFile
operator|.
name|getParent
argument_list|()
operator|.
name|resolve
argument_list|(
name|persistentFile
operator|.
name|getFileName
argument_list|()
operator|+
literal|".new."
operator|+
name|System
operator|.
name|currentTimeMillis
argument_list|()
argument_list|)
decl_stmt|;
comment|// tracks the BlobIds of Blob Files which have been orphaned
specifier|final
name|Set
argument_list|<
name|BlobId
argument_list|>
name|orphanedBlobFileIds
init|=
operator|new
name|HashSet
argument_list|<>
argument_list|()
decl_stmt|;
try|try
init|(
specifier|final
name|SeekableByteChannel
name|channel
init|=
name|Files
operator|.
name|newByteChannel
argument_list|(
name|persistentFile
argument_list|,
name|READ
argument_list|)
init|)
block|{
name|validateFileHeader
argument_list|(
name|buffer
argument_list|,
name|persistentFile
argument_list|,
name|channel
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|clear
argument_list|()
expr_stmt|;
try|try
init|(
specifier|final
name|SeekableByteChannel
name|compactChannel
init|=
name|Files
operator|.
name|newByteChannel
argument_list|(
name|compactPersistentFile
argument_list|,
name|CREATE_NEW
argument_list|,
name|APPEND
argument_list|)
init|)
block|{
name|writeFileHeader
argument_list|(
name|buffer
argument_list|,
name|compactChannel
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|clear
argument_list|()
expr_stmt|;
while|while
condition|(
name|channel
operator|.
name|read
argument_list|(
name|buffer
argument_list|)
operator|>
operator|-
literal|1
condition|)
block|{
specifier|final
name|byte
index|[]
name|id
init|=
operator|new
name|byte
index|[
name|digestType
operator|.
name|getDigestLengthBytes
argument_list|()
index|]
decl_stmt|;
name|buffer
operator|.
name|flip
argument_list|()
expr_stmt|;
name|buffer
operator|.
name|get
argument_list|(
name|id
argument_list|)
expr_stmt|;
specifier|final
name|BlobId
name|blobId
init|=
operator|new
name|BlobId
argument_list|(
name|id
argument_list|)
decl_stmt|;
specifier|final
name|int
name|count
init|=
name|buffer
operator|.
name|getInt
argument_list|()
decl_stmt|;
if|if
condition|(
name|count
operator|==
literal|0
condition|)
block|{
name|orphanedBlobFileIds
operator|.
name|add
argument_list|(
name|blobId
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|orphanedBlobFileIds
operator|.
name|remove
argument_list|(
name|blobId
argument_list|)
expr_stmt|;
name|compactReferences
operator|.
name|put
argument_list|(
name|blobId
argument_list|,
operator|new
name|BlobReference
argument_list|(
name|count
argument_list|,
name|compactChannel
operator|.
name|position
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|flip
argument_list|()
expr_stmt|;
name|compactChannel
operator|.
name|write
argument_list|(
name|buffer
argument_list|)
expr_stmt|;
block|}
name|buffer
operator|.
name|clear
argument_list|()
expr_stmt|;
block|}
block|}
block|}
comment|// cleanup any orphaned Blob files
for|for
control|(
specifier|final
name|BlobId
name|orphanedBlobFileId
range|:
name|orphanedBlobFileIds
control|)
block|{
name|deleteBlob
argument_list|(
name|blobDir
argument_list|,
name|orphanedBlobFileId
argument_list|,
literal|false
argument_list|)
expr_stmt|;
block|}
comment|// replace the persistent file with the new compact persistent file
name|Files
operator|.
name|move
argument_list|(
name|compactPersistentFile
argument_list|,
name|persistentFile
argument_list|,
name|ATOMIC_MOVE
argument_list|,
name|REPLACE_EXISTING
argument_list|)
expr_stmt|;
return|return
name|compactReferences
return|;
block|}
comment|/**      * Writes the persistent file header      *      * @param buffer a byte buffer to use      * @param channel the channel to write to      * @return the number of bytes written.      * @throws IOException if an error occurs whilst writing the header.      */
specifier|private
name|long
name|writeFileHeader
parameter_list|(
specifier|final
name|ByteBuffer
name|buffer
parameter_list|,
specifier|final
name|SeekableByteChannel
name|channel
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|long
name|start
init|=
name|channel
operator|.
name|position
argument_list|()
decl_stmt|;
name|buffer
operator|.
name|clear
argument_list|()
expr_stmt|;
name|writeFileHeader
argument_list|(
name|buffer
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|flip
argument_list|()
expr_stmt|;
name|buffer
operator|.
name|limit
argument_list|(
name|BLOB_STORE_HEADER_LEN
argument_list|)
expr_stmt|;
name|channel
operator|.
name|write
argument_list|(
name|buffer
argument_list|)
expr_stmt|;
return|return
name|channel
operator|.
name|position
argument_list|()
operator|-
name|start
return|;
block|}
comment|/**      * Writes the persistent file header      *      * @param buffer the buffer to write to      */
specifier|private
specifier|static
name|void
name|writeFileHeader
parameter_list|(
specifier|final
name|ByteBuffer
name|buffer
parameter_list|)
block|{
name|buffer
operator|.
name|put
argument_list|(
name|BLOB_STORE_MAGIC_NUMBER
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|putShort
argument_list|(
name|BLOB_STORE_VERSION
argument_list|)
expr_stmt|;
block|}
comment|/**      * Validates the persistent file header.      *      * @param buffer a byte buffer to use      * @param file the file containing the header.      * @param channel the channel of the file to read from.      *      * @throws IOException if the header is invalid.      */
specifier|private
name|void
name|validateFileHeader
parameter_list|(
specifier|final
name|ByteBuffer
name|buffer
parameter_list|,
specifier|final
name|Path
name|file
parameter_list|,
specifier|final
name|SeekableByteChannel
name|channel
parameter_list|)
throws|throws
name|IOException
block|{
name|buffer
operator|.
name|clear
argument_list|()
expr_stmt|;
name|buffer
operator|.
name|limit
argument_list|(
name|BLOB_STORE_HEADER_LEN
argument_list|)
expr_stmt|;
name|channel
operator|.
name|read
argument_list|(
name|buffer
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|flip
argument_list|()
expr_stmt|;
specifier|final
name|boolean
name|validMagic
init|=
name|buffer
operator|.
name|get
argument_list|()
operator|==
name|BLOB_STORE_MAGIC_NUMBER
index|[
literal|0
index|]
operator|&&
name|buffer
operator|.
name|get
argument_list|()
operator|==
name|BLOB_STORE_MAGIC_NUMBER
index|[
literal|1
index|]
operator|&&
name|buffer
operator|.
name|get
argument_list|()
operator|==
name|BLOB_STORE_MAGIC_NUMBER
index|[
literal|2
index|]
operator|&&
name|buffer
operator|.
name|get
argument_list|()
operator|==
name|BLOB_STORE_MAGIC_NUMBER
index|[
literal|3
index|]
decl_stmt|;
if|if
condition|(
operator|!
name|validMagic
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"File was not recognised as a valid eXist-db Blob Store: "
operator|+
name|file
operator|.
name|toAbsolutePath
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
comment|// check the version of the blob store format
specifier|final
name|short
name|storedVersion
init|=
name|buffer
operator|.
name|getShort
argument_list|()
decl_stmt|;
specifier|final
name|boolean
name|validVersion
init|=
name|storedVersion
operator|==
name|BLOB_STORE_VERSION
decl_stmt|;
if|if
condition|(
operator|!
name|validVersion
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Blob Store file was version "
operator|+
name|storedVersion
operator|+
literal|", but required version "
operator|+
name|BLOB_STORE_VERSION
operator|+
literal|": "
operator|+
name|file
operator|.
name|toAbsolutePath
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|Tuple2
argument_list|<
name|BlobId
argument_list|,
name|Long
argument_list|>
name|add
parameter_list|(
specifier|final
name|Txn
name|transaction
parameter_list|,
specifier|final
name|InputStream
name|is
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|state
operator|.
name|get
argument_list|()
operator|!=
name|State
operator|.
name|OPEN
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Blob Store is not open!"
argument_list|)
throw|;
block|}
comment|// stage the BLOB file
specifier|final
name|Tuple3
argument_list|<
name|Path
argument_list|,
name|Long
argument_list|,
name|MessageDigest
argument_list|>
name|staged
init|=
name|stage
argument_list|(
name|is
argument_list|)
decl_stmt|;
specifier|final
name|BlobVacuum
operator|.
name|RequestDeleteStagedBlobFile
name|requestDeleteStagedBlobFile
init|=
operator|new
name|BlobVacuum
operator|.
name|RequestDeleteStagedBlobFile
argument_list|(
name|stagingDir
argument_list|,
name|staged
operator|.
name|_1
operator|.
name|getFileName
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
decl_stmt|;
comment|// register a callback to cleanup the staged BLOB file ONLY after commit+checkpoint
specifier|final
name|JournalManager
name|journalManager
init|=
name|database
operator|.
name|getJournalManager
argument_list|()
operator|.
name|orElse
argument_list|(
literal|null
argument_list|)
decl_stmt|;
if|if
condition|(
name|journalManager
operator|!=
literal|null
condition|)
block|{
specifier|final
name|DeleteStagedBlobFile
name|cleanupStagedBlob
init|=
operator|new
name|DeleteStagedBlobFile
argument_list|(
name|vacuumQueue
argument_list|,
name|requestDeleteStagedBlobFile
argument_list|)
decl_stmt|;
name|journalManager
operator|.
name|listen
argument_list|(
name|cleanupStagedBlob
argument_list|)
expr_stmt|;
name|transaction
operator|.
name|registerListener
argument_list|(
name|cleanupStagedBlob
argument_list|)
expr_stmt|;
block|}
specifier|final
name|BlobId
name|blobId
init|=
operator|new
name|BlobId
argument_list|(
name|staged
operator|.
name|_3
operator|.
name|getValue
argument_list|()
argument_list|)
decl_stmt|;
comment|// if the blob entry does not exist, we exclusively compute it as STAGED.
name|BlobReference
name|blobReference
init|=
name|references
operator|.
name|computeIfAbsent
argument_list|(
name|blobId
argument_list|,
name|k
lambda|->
operator|new
name|BlobReference
argument_list|(
name|STAGED
argument_list|)
argument_list|)
decl_stmt|;
try|try
block|{
while|while
condition|(
literal|true
condition|)
block|{
if|if
condition|(
name|blobReference
operator|.
name|count
operator|.
name|compareAndSet
argument_list|(
name|STAGED
argument_list|,
name|PROMOTING
argument_list|)
condition|)
block|{
comment|// NOTE: we are the only thread that can be in this branch for the blobId
comment|// write journal entries to the WAL
if|if
condition|(
name|journalManager
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|journalManager
operator|.
name|journal
argument_list|(
operator|new
name|StoreBlobFileLoggable
argument_list|(
name|transaction
operator|.
name|getId
argument_list|()
argument_list|,
name|blobId
argument_list|,
name|staged
operator|.
name|_1
operator|.
name|getFileName
argument_list|()
operator|.
name|toString
argument_list|()
argument_list|)
argument_list|)
expr_stmt|;
name|journalManager
operator|.
name|journal
argument_list|(
operator|new
name|UpdateBlobRefCountLoggable
argument_list|(
name|transaction
operator|.
name|getId
argument_list|()
argument_list|,
name|blobId
argument_list|,
literal|0
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
name|journalManager
operator|.
name|flush
argument_list|(
literal|true
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// force WAL entries to disk!
block|}
catch|catch
parameter_list|(
specifier|final
name|JournalException
name|e
parameter_list|)
block|{
name|references
operator|.
name|remove
argument_list|(
name|blobId
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|// promote the staged blob
name|promote
argument_list|(
name|staged
argument_list|)
expr_stmt|;
if|if
condition|(
name|journalManager
operator|==
literal|null
condition|)
block|{
comment|// no journal (or recovery)... so go ahead and schedule cleanup of the staged blob file
name|enqueueVacuum
argument_list|(
name|vacuumQueue
argument_list|,
name|requestDeleteStagedBlobFile
argument_list|)
expr_stmt|;
block|}
comment|// schedule disk persist of the new value
name|persistQueue
operator|.
name|put
argument_list|(
name|Tuple
argument_list|(
name|blobId
argument_list|,
name|blobReference
argument_list|,
literal|1
argument_list|)
argument_list|)
expr_stmt|;
comment|// update memory with the new value
name|blobReference
operator|.
name|count
operator|.
name|set
argument_list|(
literal|1
argument_list|)
expr_stmt|;
comment|// done!
return|return
name|Tuple
argument_list|(
name|blobId
argument_list|,
name|staged
operator|.
name|_2
argument_list|)
return|;
block|}
specifier|final
name|int
name|count
init|=
name|blobReference
operator|.
name|count
operator|.
name|get
argument_list|()
decl_stmt|;
comment|// guard against a concurrent #add or #remove
if|if
condition|(
name|count
operator|==
name|PROMOTING
operator|||
name|count
operator|==
name|UPDATING_COUNT
condition|)
block|{
comment|// spin whilst another thread promotes the blob, or updates the reference count
comment|// sleep a small time to save CPU
name|Thread
operator|.
name|sleep
argument_list|(
literal|10
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|// guard against a concurrent vacuum operation
comment|// ...retry the blob reference until the vacuum has completed!
comment|// i.e. wait for the deletion of the blob to complete, and then we can add the blob again
if|if
condition|(
name|count
operator|==
name|DELETING
condition|)
block|{
name|blobReference
operator|=
name|references
operator|.
name|computeIfAbsent
argument_list|(
name|blobId
argument_list|,
name|k
lambda|->
operator|new
name|BlobReference
argument_list|(
name|STAGED
argument_list|)
argument_list|)
expr_stmt|;
continue|continue;
comment|// loop again
block|}
comment|// only increment the blob reference if the blob is active!
if|if
condition|(
name|count
operator|>=
literal|0
operator|&&
name|blobReference
operator|.
name|count
operator|.
name|compareAndSet
argument_list|(
name|count
argument_list|,
name|UPDATING_COUNT
argument_list|)
condition|)
block|{
comment|// NOTE: we are the only thread that can be in this branch for the blobId
specifier|final
name|int
name|newCount
init|=
name|count
operator|+
literal|1
decl_stmt|;
comment|// write journal entries to the WAL
if|if
condition|(
name|journalManager
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|journalManager
operator|.
name|journal
argument_list|(
operator|new
name|UpdateBlobRefCountLoggable
argument_list|(
name|transaction
operator|.
name|getId
argument_list|()
argument_list|,
name|blobId
argument_list|,
name|count
argument_list|,
name|newCount
argument_list|)
argument_list|)
expr_stmt|;
name|journalManager
operator|.
name|flush
argument_list|(
literal|true
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// force WAL entries to disk!
block|}
catch|catch
parameter_list|(
specifier|final
name|JournalException
name|e
parameter_list|)
block|{
comment|// restore the state of the blobReference first!
name|blobReference
operator|.
name|count
operator|.
name|set
argument_list|(
name|count
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|// persist the new value
name|persistQueue
operator|.
name|put
argument_list|(
name|Tuple
argument_list|(
name|blobId
argument_list|,
name|blobReference
argument_list|,
name|newCount
argument_list|)
argument_list|)
expr_stmt|;
comment|// update memory with the new value, and release other spinning threads
name|blobReference
operator|.
name|count
operator|.
name|set
argument_list|(
name|newCount
argument_list|)
expr_stmt|;
comment|// done!
return|return
name|Tuple
argument_list|(
name|blobId
argument_list|,
name|staged
operator|.
name|_2
argument_list|)
return|;
block|}
block|}
block|}
catch|catch
parameter_list|(
specifier|final
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// thrown by persistQueue.put or Thread.sleep
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|BlobId
name|copy
parameter_list|(
specifier|final
name|Txn
name|transaction
parameter_list|,
specifier|final
name|BlobId
name|blobId
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|state
operator|.
name|get
argument_list|()
operator|!=
name|State
operator|.
name|OPEN
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Blob Store is not open!"
argument_list|)
throw|;
block|}
specifier|final
name|BlobReference
name|blobReference
init|=
name|references
operator|.
name|get
argument_list|(
name|blobId
argument_list|)
decl_stmt|;
if|if
condition|(
name|blobReference
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// NOTE: that copy is simply an increment of the reference count!
try|try
block|{
while|while
condition|(
literal|true
condition|)
block|{
specifier|final
name|int
name|count
init|=
name|blobReference
operator|.
name|count
operator|.
name|get
argument_list|()
decl_stmt|;
comment|// guard against a concurrent #add or #remove
if|if
condition|(
name|count
operator|==
name|STAGED
operator|||
name|count
operator|==
name|PROMOTING
operator|||
name|count
operator|==
name|UPDATING_COUNT
condition|)
block|{
comment|// spin whilst another thread promotes the blob, or updates the reference count
comment|// sleep a small time to save CPU
name|Thread
operator|.
name|sleep
argument_list|(
literal|10
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|// guard against a concurrent vacuum operation
if|if
condition|(
name|count
operator|==
name|DELETING
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// only increment the blob reference if the blob is active!
if|if
condition|(
name|count
operator|>=
literal|0
operator|&&
name|blobReference
operator|.
name|count
operator|.
name|compareAndSet
argument_list|(
name|count
argument_list|,
name|UPDATING_COUNT
argument_list|)
condition|)
block|{
comment|// NOTE: we are the only thread that can be in this branch for the blobId
specifier|final
name|int
name|newCount
init|=
name|count
operator|+
literal|1
decl_stmt|;
comment|// write journal entries to the WAL
specifier|final
name|JournalManager
name|journalManager
init|=
name|database
operator|.
name|getJournalManager
argument_list|()
operator|.
name|orElse
argument_list|(
literal|null
argument_list|)
decl_stmt|;
if|if
condition|(
name|journalManager
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|journalManager
operator|.
name|journal
argument_list|(
operator|new
name|UpdateBlobRefCountLoggable
argument_list|(
name|transaction
operator|.
name|getId
argument_list|()
argument_list|,
name|blobId
argument_list|,
name|count
argument_list|,
name|newCount
argument_list|)
argument_list|)
expr_stmt|;
name|journalManager
operator|.
name|flush
argument_list|(
literal|true
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// force WAL entries to disk!
block|}
catch|catch
parameter_list|(
specifier|final
name|JournalException
name|e
parameter_list|)
block|{
comment|// restore the state of the blobReference first!
name|blobReference
operator|.
name|count
operator|.
name|set
argument_list|(
name|count
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|// persist the new value
name|persistQueue
operator|.
name|put
argument_list|(
name|Tuple
argument_list|(
name|blobId
argument_list|,
name|blobReference
argument_list|,
name|newCount
argument_list|)
argument_list|)
expr_stmt|;
comment|// update memory with the new value, and release other spinning threads
name|blobReference
operator|.
name|count
operator|.
name|set
argument_list|(
name|newCount
argument_list|)
expr_stmt|;
comment|// done!
return|return
name|blobId
return|;
block|}
block|}
block|}
catch|catch
parameter_list|(
specifier|final
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// thrown by persistQueue.put or Thread.sleep
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
annotation|@
name|Override
annotation|@
name|Nullable
specifier|public
name|InputStream
name|get
parameter_list|(
specifier|final
name|Txn
name|transaction
parameter_list|,
specifier|final
name|BlobId
name|blobId
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|BlobFileLease
name|blobFileLease
init|=
name|readLeaseBlobFile
argument_list|(
name|transaction
argument_list|,
name|blobId
argument_list|)
decl_stmt|;
if|if
condition|(
name|blobFileLease
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
comment|// blob file lease is released either when the input stream is closed, or if an error occurs opening the stream
try|try
block|{
return|return
operator|new
name|OnCloseInputStream
argument_list|(
name|Files
operator|.
name|newInputStream
argument_list|(
name|blobFileLease
operator|.
name|path
argument_list|)
argument_list|,
name|blobFileLease
operator|.
name|release
argument_list|)
return|;
block|}
catch|catch
parameter_list|(
specifier|final
name|IOException
name|e
parameter_list|)
block|{
name|blobFileLease
operator|.
name|release
operator|.
name|run
argument_list|()
expr_stmt|;
comment|// MUST release the read lease!
throw|throw
name|e
throw|;
block|}
block|}
annotation|@
name|Override
annotation|@
name|Nullable
specifier|public
name|MessageDigest
name|getDigest
parameter_list|(
specifier|final
name|Txn
name|transaction
parameter_list|,
specifier|final
name|BlobId
name|blobId
parameter_list|,
specifier|final
name|DigestType
name|digestType
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|this
operator|.
name|digestType
operator|.
name|equals
argument_list|(
name|digestType
argument_list|)
condition|)
block|{
comment|// optimisation, we can just return the BlobId as that is the digest for this digest type!
return|return
operator|new
name|MessageDigest
argument_list|(
name|digestType
argument_list|,
name|blobId
operator|.
name|getId
argument_list|()
argument_list|)
return|;
block|}
else|else
block|{
comment|// calculate the digest
specifier|final
name|StreamableDigest
name|streamableDigest
init|=
name|digestType
operator|.
name|newStreamableDigest
argument_list|()
decl_stmt|;
specifier|final
name|Try
argument_list|<
name|MessageDigest
argument_list|,
name|IOException
argument_list|>
name|result
init|=
name|with
argument_list|(
name|transaction
argument_list|,
name|blobId
argument_list|,
name|maybeBlobFile
lambda|->
name|maybeBlobFile
operator|==
literal|null
condition|?
literal|null
else|:
name|TaggedTryUnchecked
argument_list|(
name|IOException
operator|.
name|class
argument_list|,
parameter_list|()
lambda|->
block|{
name|FileUtils
operator|.
name|digest
argument_list|(
name|maybeBlobFile
argument_list|,
name|streamableDigest
argument_list|)
argument_list|;
return|return
operator|new
name|MessageDigest
argument_list|(
name|streamableDigest
operator|.
name|getDigestType
argument_list|()
argument_list|,
name|streamableDigest
operator|.
name|getMessageDigest
argument_list|()
argument_list|)
return|;
block|}
block_content|)
block|)
class|;
end_class

begin_return
return|return
name|result
operator|.
name|get
argument_list|()
return|;
end_return

begin_function
unit|}     }
annotation|@
name|Override
specifier|public
parameter_list|<
name|T
parameter_list|>
name|T
name|with
parameter_list|(
specifier|final
name|Txn
name|transaction
parameter_list|,
specifier|final
name|BlobId
name|blobId
parameter_list|,
specifier|final
name|Function
argument_list|<
name|Path
argument_list|,
name|T
argument_list|>
name|fnFile
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|BlobFileLease
name|blobFileLease
init|=
name|readLeaseBlobFile
argument_list|(
name|transaction
argument_list|,
name|blobId
argument_list|)
decl_stmt|;
try|try
block|{
return|return
name|fnFile
operator|.
name|apply
argument_list|(
name|blobFileLease
operator|==
literal|null
condition|?
literal|null
else|:
name|blobFileLease
operator|.
name|path
argument_list|)
return|;
block|}
finally|finally
block|{
if|if
condition|(
name|blobFileLease
operator|!=
literal|null
condition|)
block|{
name|blobFileLease
operator|.
name|release
operator|.
name|run
argument_list|()
expr_stmt|;
comment|// MUST release the read lease!
block|}
block|}
block|}
end_function

begin_comment
comment|/**      * Lease a Blob file for reading from the Blob Store.      *      * @param transaction the current database transaction.      * @param blobId the identifier of the blob to lease the blob file from.      *      * @return the blob file lease, or null if the blob does not exist in the Blob Store      *      * @throws IOException if an error occurs whilst retrieving the BLOB file.      */
end_comment

begin_function
specifier|private
name|BlobFileLease
name|readLeaseBlobFile
parameter_list|(
specifier|final
name|Txn
name|transaction
parameter_list|,
specifier|final
name|BlobId
name|blobId
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|state
operator|.
name|get
argument_list|()
operator|!=
name|State
operator|.
name|OPEN
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Blob Store is not open!"
argument_list|)
throw|;
block|}
specifier|final
name|BlobReference
name|blobReference
init|=
name|references
operator|.
name|get
argument_list|(
name|blobId
argument_list|)
decl_stmt|;
if|if
condition|(
name|blobReference
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
try|try
block|{
while|while
condition|(
literal|true
condition|)
block|{
specifier|final
name|int
name|count
init|=
name|blobReference
operator|.
name|count
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|count
operator|==
literal|0
condition|)
block|{
comment|// can't return something with has zero references
return|return
literal|null
return|;
block|}
comment|// guard against a concurrent vacuum operation
if|if
condition|(
name|count
operator|==
name|DELETING
condition|)
block|{
comment|// can't return something with has zero references (because it is being deleted)
return|return
literal|null
return|;
block|}
comment|// guard against a concurrent #add doing staging
if|if
condition|(
name|count
operator|==
name|STAGED
operator|||
name|count
operator|==
name|PROMOTING
condition|)
block|{
comment|// spin whilst another thread promotes the blob
comment|// sleep a small time to save CPU
name|Thread
operator|.
name|sleep
argument_list|(
literal|10
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|// read a blob which has references
if|if
condition|(
name|count
operator|>
literal|0
condition|)
block|{
comment|// we are reading
name|blobReference
operator|.
name|readers
operator|.
name|incrementAndGet
argument_list|()
expr_stmt|;
comment|// get the blob
specifier|final
name|Path
name|blobFile
init|=
name|blobDir
operator|.
name|resolve
argument_list|(
name|bytesToHex
argument_list|(
name|blobId
operator|.
name|getId
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
return|return
operator|new
name|BlobFileLease
argument_list|(
name|blobFile
argument_list|,
name|blobReference
operator|.
name|readers
operator|::
name|decrementAndGet
argument_list|)
return|;
block|}
block|}
block|}
catch|catch
parameter_list|(
specifier|final
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// only thrown by Thread.sleep above
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
end_function

begin_comment
comment|/**      * Gets the reference count for the Blob      *      * NOTE: this method is not thread-safe and should ONLY      * be used for testing, which is why this method is      * marked package-private!      *      * @param blobId The id of the blob      *      * @return the reference count, or null if the blob id is not in the references table.      *      * @throws IOException if the BlobStore is not open.      */
end_comment

begin_function
annotation|@
name|Nullable
name|Integer
name|getReferenceCount
parameter_list|(
specifier|final
name|BlobId
name|blobId
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|state
operator|.
name|get
argument_list|()
operator|!=
name|State
operator|.
name|OPEN
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Blob Store is not open!"
argument_list|)
throw|;
block|}
specifier|final
name|BlobReference
name|blobReference
init|=
name|references
operator|.
name|get
argument_list|(
name|blobId
argument_list|)
decl_stmt|;
if|if
condition|(
name|blobReference
operator|==
literal|null
condition|)
block|{
return|return
literal|null
return|;
block|}
return|return
name|blobReference
operator|.
name|count
operator|.
name|get
argument_list|()
return|;
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|remove
parameter_list|(
specifier|final
name|Txn
name|transaction
parameter_list|,
specifier|final
name|BlobId
name|blobId
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|state
operator|.
name|get
argument_list|()
operator|!=
name|State
operator|.
name|OPEN
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Blob Store is not open!"
argument_list|)
throw|;
block|}
specifier|final
name|BlobReference
name|blobReference
init|=
name|references
operator|.
name|get
argument_list|(
name|blobId
argument_list|)
decl_stmt|;
if|if
condition|(
name|blobReference
operator|==
literal|null
condition|)
block|{
return|return;
block|}
try|try
block|{
while|while
condition|(
literal|true
condition|)
block|{
specifier|final
name|int
name|count
init|=
name|blobReference
operator|.
name|count
operator|.
name|get
argument_list|()
decl_stmt|;
if|if
condition|(
name|count
operator|==
literal|0
condition|)
block|{
comment|// can't remove something which has zero references
return|return;
block|}
comment|// guard against a concurrent vacuum operation
if|if
condition|(
name|count
operator|==
name|DELETING
condition|)
block|{
comment|// can't remove something which has zero references (because it is being deleted)
return|return;
block|}
comment|// guard against a concurrent #add or #remove
if|if
condition|(
name|count
operator|==
name|STAGED
operator|||
name|count
operator|==
name|PROMOTING
operator|||
name|count
operator|==
name|UPDATING_COUNT
condition|)
block|{
comment|// spin whilst another thread promotes the blob or updates the reference count
comment|// sleep a small time to save CPU
name|Thread
operator|.
name|sleep
argument_list|(
literal|10
argument_list|)
expr_stmt|;
continue|continue;
block|}
comment|// only decrement the blob reference if the blob has more than zero references
if|if
condition|(
name|count
operator|>
literal|0
operator|&&
name|blobReference
operator|.
name|count
operator|.
name|compareAndSet
argument_list|(
name|count
argument_list|,
name|UPDATING_COUNT
argument_list|)
condition|)
block|{
comment|// NOTE: we are the only thread that can be in this branch for the blobId
specifier|final
name|int
name|newCount
init|=
name|count
operator|-
literal|1
decl_stmt|;
comment|// write journal entries to the WAL
specifier|final
name|JournalManager
name|journalManager
init|=
name|database
operator|.
name|getJournalManager
argument_list|()
operator|.
name|orElse
argument_list|(
literal|null
argument_list|)
decl_stmt|;
if|if
condition|(
name|journalManager
operator|!=
literal|null
condition|)
block|{
try|try
block|{
name|journalManager
operator|.
name|journal
argument_list|(
operator|new
name|UpdateBlobRefCountLoggable
argument_list|(
name|transaction
operator|.
name|getId
argument_list|()
argument_list|,
name|blobId
argument_list|,
name|count
argument_list|,
name|newCount
argument_list|)
argument_list|)
expr_stmt|;
name|journalManager
operator|.
name|flush
argument_list|(
literal|true
argument_list|,
literal|true
argument_list|)
expr_stmt|;
comment|// force WAL entries to disk!
block|}
catch|catch
parameter_list|(
specifier|final
name|JournalException
name|e
parameter_list|)
block|{
comment|// restore the state of the blobReference first!
name|blobReference
operator|.
name|count
operator|.
name|set
argument_list|(
name|count
argument_list|)
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
comment|// schedule disk persist of the new value
name|persistQueue
operator|.
name|put
argument_list|(
name|Tuple
argument_list|(
name|blobId
argument_list|,
name|blobReference
argument_list|,
name|newCount
argument_list|)
argument_list|)
expr_stmt|;
if|if
condition|(
name|newCount
operator|==
literal|0
condition|)
block|{
comment|// schedule blob file for vacuum.
specifier|final
name|BlobVacuum
operator|.
name|RequestDeleteBlobFile
name|requestDeleteBlobFile
init|=
operator|new
name|BlobVacuum
operator|.
name|RequestDeleteBlobFile
argument_list|(
name|references
argument_list|,
name|blobDir
argument_list|,
name|blobId
argument_list|,
name|blobReference
argument_list|)
decl_stmt|;
if|if
condition|(
name|journalManager
operator|!=
literal|null
condition|)
block|{
comment|// register a callback to schedule the BLOB file for vacuum ONLY after commit+checkpoint
specifier|final
name|ScheduleDeleteBlobFile
name|scheduleDeleteBlobFile
init|=
operator|new
name|ScheduleDeleteBlobFile
argument_list|(
name|vacuumQueue
argument_list|,
name|requestDeleteBlobFile
argument_list|)
decl_stmt|;
name|journalManager
operator|.
name|listen
argument_list|(
name|scheduleDeleteBlobFile
argument_list|)
expr_stmt|;
name|transaction
operator|.
name|registerListener
argument_list|(
name|scheduleDeleteBlobFile
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// no journal (or recovery)... so go ahead and schedule
name|enqueueVacuum
argument_list|(
name|vacuumQueue
argument_list|,
name|requestDeleteBlobFile
argument_list|)
expr_stmt|;
block|}
block|}
comment|// update memory with the new value, and release other spinning threads
name|blobReference
operator|.
name|count
operator|.
name|set
argument_list|(
name|newCount
argument_list|)
expr_stmt|;
comment|// done!
return|return;
block|}
block|}
block|}
catch|catch
parameter_list|(
specifier|final
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// thrown by persistQueue.put or Thread.sleep
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
throw|throw
operator|new
name|IOException
argument_list|(
name|e
argument_list|)
throw|;
block|}
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|backupToArchive
parameter_list|(
specifier|final
name|RawDataBackup
name|backup
parameter_list|)
throws|throws
name|IOException
block|{
if|if
condition|(
name|state
operator|.
name|get
argument_list|()
operator|!=
name|State
operator|.
name|OPEN
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Blob Store is not open!"
argument_list|)
throw|;
block|}
comment|// TODO(AR) should we enter an exclusive backup state?
comment|// NOTE: do not use try-with-resources here, closing the OutputStream will close the entire backup
comment|// backup the blob.dbx
try|try
block|{
specifier|final
name|OutputStream
name|os
init|=
name|backup
operator|.
name|newEntry
argument_list|(
name|fileName
argument_list|(
name|persistentFile
argument_list|)
argument_list|)
decl_stmt|;
name|Files
operator|.
name|copy
argument_list|(
name|persistentFile
argument_list|,
name|os
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|backup
operator|.
name|closeEntry
argument_list|()
expr_stmt|;
block|}
comment|// backup the blob files
for|for
control|(
specifier|final
name|Path
name|blobFile
range|:
name|FileUtils
operator|.
name|list
argument_list|(
name|blobDir
argument_list|,
name|Files
operator|::
name|isRegularFile
argument_list|)
control|)
block|{
try|try
block|{
specifier|final
name|OutputStream
name|os
init|=
name|backup
operator|.
name|newEntry
argument_list|(
name|fileName
argument_list|(
name|blobDir
argument_list|)
operator|+
literal|'/'
operator|+
name|fileName
argument_list|(
name|blobFile
argument_list|)
argument_list|)
decl_stmt|;
name|Files
operator|.
name|copy
argument_list|(
name|persistentFile
argument_list|,
name|os
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|backup
operator|.
name|closeEntry
argument_list|()
expr_stmt|;
block|}
block|}
comment|// backup the staging area
for|for
control|(
specifier|final
name|Path
name|blobFile
range|:
name|FileUtils
operator|.
name|list
argument_list|(
name|stagingDir
argument_list|,
name|Files
operator|::
name|isRegularFile
argument_list|)
control|)
block|{
try|try
block|{
specifier|final
name|OutputStream
name|os
init|=
name|backup
operator|.
name|newEntry
argument_list|(
name|fileName
argument_list|(
name|blobDir
argument_list|)
operator|+
literal|'/'
operator|+
name|fileName
argument_list|(
name|stagingDir
argument_list|)
operator|+
literal|'/'
operator|+
name|fileName
argument_list|(
name|blobFile
argument_list|)
argument_list|)
decl_stmt|;
name|Files
operator|.
name|copy
argument_list|(
name|persistentFile
argument_list|,
name|os
argument_list|)
expr_stmt|;
block|}
finally|finally
block|{
name|backup
operator|.
name|closeEntry
argument_list|()
expr_stmt|;
block|}
block|}
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|redo
parameter_list|(
specifier|final
name|BlobLoggable
name|blobLoggable
parameter_list|)
throws|throws
name|LogException
block|{
try|try
block|{
if|if
condition|(
name|blobLoggable
operator|instanceof
name|StoreBlobFileLoggable
condition|)
block|{
specifier|final
name|StoreBlobFileLoggable
name|storeBlobFileLoggable
init|=
operator|(
name|StoreBlobFileLoggable
operator|)
name|blobLoggable
decl_stmt|;
name|redoStoreBlobFile
argument_list|(
name|storeBlobFileLoggable
operator|.
name|getBlobId
argument_list|()
argument_list|,
name|storeBlobFileLoggable
operator|.
name|getStagedUuid
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|else if
condition|(
name|blobLoggable
operator|instanceof
name|UpdateBlobRefCountLoggable
condition|)
block|{
specifier|final
name|UpdateBlobRefCountLoggable
name|updateBlobRefCountLoggable
init|=
operator|(
name|UpdateBlobRefCountLoggable
operator|)
name|blobLoggable
decl_stmt|;
name|updateBlogRefCount
argument_list|(
name|updateBlobRefCountLoggable
operator|.
name|getBlobId
argument_list|()
argument_list|,
name|updateBlobRefCountLoggable
operator|.
name|getNewCount
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
specifier|final
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|LogException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
end_function

begin_function
annotation|@
name|Override
specifier|public
name|void
name|undo
parameter_list|(
specifier|final
name|BlobLoggable
name|blobLoggable
parameter_list|)
throws|throws
name|LogException
block|{
try|try
block|{
if|if
condition|(
name|blobLoggable
operator|instanceof
name|StoreBlobFileLoggable
condition|)
block|{
specifier|final
name|StoreBlobFileLoggable
name|storeBlobFileLoggable
init|=
operator|(
name|StoreBlobFileLoggable
operator|)
name|blobLoggable
decl_stmt|;
name|undoStoreBlobFile
argument_list|(
name|storeBlobFileLoggable
operator|.
name|getBlobId
argument_list|()
argument_list|,
name|storeBlobFileLoggable
operator|.
name|getStagedUuid
argument_list|()
argument_list|)
expr_stmt|;
block|}
if|else if
condition|(
name|blobLoggable
operator|instanceof
name|UpdateBlobRefCountLoggable
condition|)
block|{
specifier|final
name|UpdateBlobRefCountLoggable
name|updateBlobRefCountLoggable
init|=
operator|(
name|UpdateBlobRefCountLoggable
operator|)
name|blobLoggable
decl_stmt|;
name|updateBlogRefCount
argument_list|(
name|updateBlobRefCountLoggable
operator|.
name|getBlobId
argument_list|()
argument_list|,
name|updateBlobRefCountLoggable
operator|.
name|getCurrentCount
argument_list|()
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
specifier|final
name|IOException
name|e
parameter_list|)
block|{
throw|throw
operator|new
name|LogException
argument_list|(
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
throw|;
block|}
block|}
end_function

begin_comment
comment|/**      * Recovery - redo: Promotes the Staged Blob File after performing some checks.      *      * This is possible because the Staged Blob file is not      * removed until a checkpoint is written AFTER the transaction      * was committed.      *      * @param blobId the blobId      * @param stagedUuid The uuid of the staged blob file.      *      * @throws IOException if the staged blob file cannot be promoted      */
end_comment

begin_function
specifier|private
name|void
name|redoStoreBlobFile
parameter_list|(
specifier|final
name|BlobId
name|blobId
parameter_list|,
specifier|final
name|String
name|stagedUuid
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|Path
name|stagedBlobFile
init|=
name|stagingDir
operator|.
name|resolve
argument_list|(
name|stagedUuid
argument_list|)
decl_stmt|;
comment|// check the staged file exists
if|if
condition|(
operator|!
name|Files
operator|.
name|exists
argument_list|(
name|stagedBlobFile
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Staged Blob File does not exist: "
operator|+
name|stagedBlobFile
operator|.
name|toAbsolutePath
argument_list|()
argument_list|)
throw|;
block|}
comment|// check the staged file has the correct checksum
specifier|final
name|StreamableDigest
name|streamableDigest
init|=
name|digestType
operator|.
name|newStreamableDigest
argument_list|()
decl_stmt|;
name|FileUtils
operator|.
name|digest
argument_list|(
name|stagedBlobFile
argument_list|,
name|streamableDigest
argument_list|)
expr_stmt|;
specifier|final
name|String
name|blobFilename
init|=
name|bytesToHex
argument_list|(
name|blobId
operator|.
name|getId
argument_list|()
argument_list|)
decl_stmt|;
if|if
condition|(
operator|!
name|Arrays
operator|.
name|equals
argument_list|(
name|blobId
operator|.
name|getId
argument_list|()
argument_list|,
name|streamableDigest
operator|.
name|getMessageDigest
argument_list|()
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Staged Blob File checksum '"
operator|+
name|bytesToHex
argument_list|(
name|streamableDigest
operator|.
name|getMessageDigest
argument_list|()
argument_list|)
operator|+
literal|"', does not match checksum of blobId ''"
operator|+
name|blobFilename
operator|+
literal|"'"
argument_list|)
throw|;
block|}
specifier|final
name|Path
name|blobFile
init|=
name|blobDir
operator|.
name|resolve
argument_list|(
name|blobFilename
argument_list|)
decl_stmt|;
name|Files
operator|.
name|copy
argument_list|(
name|stagedBlobFile
argument_list|,
name|blobFile
argument_list|,
name|REPLACE_EXISTING
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**      * Recovery - undo: Demotes the Blob File back to the staging area after performing some checks.      *      * @param blobId the blobId      * @param stagedUuid The uuid of the staged blob file.      *      * @throws IOException if the blob file cannot be demoted to the staging area      */
end_comment

begin_function
specifier|private
name|void
name|undoStoreBlobFile
parameter_list|(
specifier|final
name|BlobId
name|blobId
parameter_list|,
specifier|final
name|String
name|stagedUuid
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|String
name|blobFilename
init|=
name|bytesToHex
argument_list|(
name|blobId
operator|.
name|getId
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|Path
name|blobFile
init|=
name|blobDir
operator|.
name|resolve
argument_list|(
name|blobFilename
argument_list|)
decl_stmt|;
comment|// check the blob file exists
if|if
condition|(
operator|!
name|Files
operator|.
name|exists
argument_list|(
name|blobFile
argument_list|)
condition|)
block|{
throw|throw
operator|new
name|IOException
argument_list|(
literal|"Blob File does not exist: "
operator|+
name|blobFile
operator|.
name|toAbsolutePath
argument_list|()
argument_list|)
throw|;
block|}
specifier|final
name|Path
name|stagedBlobFile
init|=
name|stagingDir
operator|.
name|resolve
argument_list|(
name|stagedUuid
argument_list|)
decl_stmt|;
name|Files
operator|.
name|copy
argument_list|(
name|blobFile
argument_list|,
name|stagedBlobFile
argument_list|,
name|REPLACE_EXISTING
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**      * Recovery - redo/undo: sets the reference count of a blob.      *      * @param blobId the blobId      * @param count The reference count to set.      *      * @throws IOException if the blob's reference count cannot be set      */
end_comment

begin_function
specifier|private
name|void
name|updateBlogRefCount
parameter_list|(
specifier|final
name|BlobId
name|blobId
parameter_list|,
specifier|final
name|int
name|count
parameter_list|)
throws|throws
name|IOException
block|{
name|buffer
operator|.
name|clear
argument_list|()
expr_stmt|;
name|buffer
operator|.
name|limit
argument_list|(
name|digestType
operator|.
name|getDigestLengthBytes
argument_list|()
argument_list|)
expr_stmt|;
comment|// we are only going to read the BlobIds
comment|// start immediately after the file header
name|channel
operator|.
name|position
argument_list|(
name|BLOB_STORE_HEADER_LEN
argument_list|)
expr_stmt|;
name|boolean
name|updatedCount
init|=
literal|false
decl_stmt|;
while|while
condition|(
name|channel
operator|.
name|read
argument_list|(
name|buffer
argument_list|)
operator|>
literal|0
condition|)
block|{
name|buffer
operator|.
name|flip
argument_list|()
expr_stmt|;
specifier|final
name|byte
index|[]
name|id
init|=
operator|new
name|byte
index|[
name|digestType
operator|.
name|getDigestLengthBytes
argument_list|()
index|]
decl_stmt|;
name|buffer
operator|.
name|get
argument_list|(
name|id
argument_list|)
expr_stmt|;
specifier|final
name|BlobId
name|readBlobId
init|=
operator|new
name|BlobId
argument_list|(
name|id
argument_list|)
decl_stmt|;
if|if
condition|(
name|blobId
operator|.
name|equals
argument_list|(
name|readBlobId
argument_list|)
condition|)
block|{
name|buffer
operator|.
name|clear
argument_list|()
expr_stmt|;
name|buffer
operator|.
name|limit
argument_list|(
name|REFERENCE_COUNT_LEN
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|putInt
argument_list|(
name|count
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|flip
argument_list|()
expr_stmt|;
name|channel
operator|.
name|write
argument_list|(
name|buffer
argument_list|)
expr_stmt|;
name|updatedCount
operator|=
literal|true
expr_stmt|;
break|break;
block|}
comment|// skip over the reference count
name|channel
operator|.
name|position
argument_list|(
name|channel
operator|.
name|position
argument_list|()
operator|+
name|REFERENCE_COUNT_LEN
argument_list|)
expr_stmt|;
block|}
comment|/*          * If we could not update the count of an existing entry, append a new entry to the end of the file.          * We even include those entries with count = 0, so that their blob files will be cleared up by          * the next call to compactPersistentReferences          */
if|if
condition|(
operator|!
name|updatedCount
condition|)
block|{
name|buffer
operator|.
name|clear
argument_list|()
expr_stmt|;
name|buffer
operator|.
name|put
argument_list|(
name|blobId
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|putInt
argument_list|(
name|count
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|flip
argument_list|()
expr_stmt|;
name|channel
operator|.
name|write
argument_list|(
name|buffer
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/**      * Stages a BLOB file.      *      * Writes a BLOB to a file in the Blob Store staging area.      *      * @param is data stream for the BLOB.      * @return The file path, length and checksum of the staged BLOB      * @throws IOException if an error occurs whilst staging the BLOB.      */
end_comment

begin_function
specifier|private
name|Tuple3
argument_list|<
name|Path
argument_list|,
name|Long
argument_list|,
name|MessageDigest
argument_list|>
name|stage
parameter_list|(
specifier|final
name|InputStream
name|is
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|Path
name|stageFile
init|=
name|stagingDir
operator|.
name|resolve
argument_list|(
name|UUIDGenerator
operator|.
name|getUUIDversion4
argument_list|()
argument_list|)
decl_stmt|;
specifier|final
name|CountingInputStream
name|cis
init|=
operator|new
name|CountingInputStream
argument_list|(
name|is
argument_list|)
decl_stmt|;
specifier|final
name|StreamableDigest
name|streamableDigest
init|=
name|digestType
operator|.
name|newStreamableDigest
argument_list|()
decl_stmt|;
specifier|final
name|DigestInputStream
name|dis
init|=
operator|new
name|DigestInputStream
argument_list|(
name|cis
argument_list|,
name|streamableDigest
argument_list|)
decl_stmt|;
name|Files
operator|.
name|copy
argument_list|(
name|dis
argument_list|,
name|stageFile
argument_list|)
expr_stmt|;
return|return
name|Tuple
argument_list|(
name|stageFile
argument_list|,
name|cis
operator|.
name|getByteCount
argument_list|()
argument_list|,
name|streamableDigest
operator|.
name|copyMessageDigest
argument_list|()
argument_list|)
return|;
block|}
end_function

begin_comment
comment|/**      * Promotes a staged BLOB file to the BLOB store.      *      * Copies a staged BLOB file in the Blob Store staging area to      * the live Blob Store.      *      * The staged BLOB will be removed as part of the Journalling      * and Recovery.      *      * @param staged the staged BLOB.      * @throws IOException if an error occurs whilst promoting the BLOB.      */
end_comment

begin_function
specifier|private
name|void
name|promote
parameter_list|(
specifier|final
name|Tuple3
argument_list|<
name|Path
argument_list|,
name|Long
argument_list|,
name|MessageDigest
argument_list|>
name|staged
parameter_list|)
throws|throws
name|IOException
block|{
name|Files
operator|.
name|copy
argument_list|(
name|staged
operator|.
name|_1
argument_list|,
name|blobDir
operator|.
name|resolve
argument_list|(
name|staged
operator|.
name|_3
operator|.
name|toHexString
argument_list|()
argument_list|)
argument_list|,
name|REPLACE_EXISTING
argument_list|)
expr_stmt|;
block|}
end_function

begin_comment
comment|/**      * Deletes a BLOB file from the Blob Store.      *      * @param blobDir the blob directory.      * @param blobId the identifier of the BLOB file to delete.      * @param always true if we should always be able to delete the file,      *     false if the file may not exist.      *      * @throws IOException if the file cannot be deleted, for example if {@code always}      *                     is set to true and the BLOB does not exist.      */
end_comment

begin_function
specifier|private
specifier|static
name|void
name|deleteBlob
parameter_list|(
specifier|final
name|Path
name|blobDir
parameter_list|,
specifier|final
name|BlobId
name|blobId
parameter_list|,
specifier|final
name|boolean
name|always
parameter_list|)
throws|throws
name|IOException
block|{
specifier|final
name|Path
name|blobFile
init|=
name|blobDir
operator|.
name|resolve
argument_list|(
name|bytesToHex
argument_list|(
name|blobId
operator|.
name|getId
argument_list|()
argument_list|)
argument_list|)
decl_stmt|;
if|if
condition|(
name|always
condition|)
block|{
name|Files
operator|.
name|delete
argument_list|(
name|blobFile
argument_list|)
expr_stmt|;
block|}
else|else
block|{
name|Files
operator|.
name|deleteIfExists
argument_list|(
name|blobFile
argument_list|)
expr_stmt|;
block|}
block|}
end_function

begin_comment
comment|/**      * Value class which represents the reference      * count for a blob, the number of active readers,      * and the offset of its entry in the persistent file.      */
end_comment

begin_class
specifier|static
class|class
name|BlobReference
block|{
specifier|static
specifier|final
name|int
name|DELETING
init|=
operator|-
literal|4
decl_stmt|;
specifier|static
specifier|final
name|int
name|STAGED
init|=
operator|-
literal|3
decl_stmt|;
specifier|static
specifier|final
name|int
name|PROMOTING
init|=
operator|-
literal|2
decl_stmt|;
specifier|static
specifier|final
name|int
name|UPDATING_COUNT
init|=
operator|-
literal|1
decl_stmt|;
specifier|final
name|AtomicInteger
name|count
decl_stmt|;
specifier|final
name|AtomicInteger
name|readers
init|=
operator|new
name|AtomicInteger
argument_list|()
decl_stmt|;
specifier|static
specifier|final
name|long
name|NOT_PERSISTED
init|=
operator|-
literal|1
decl_stmt|;
comment|/**          * Is only read and written from a single          * thread in {@link PersistentWriter}          * so no synchronization needed.          */
name|long
name|persistentOffset
init|=
name|NOT_PERSISTED
decl_stmt|;
comment|/**          * Construct a new Blob Reference which has not yet          * been persisted.          *          * @param count the reference count          *          * The persistentOffset will be set to {@link #NOT_PERSISTED}          */
specifier|public
name|BlobReference
parameter_list|(
specifier|final
name|int
name|count
parameter_list|)
block|{
name|this
operator|.
name|count
operator|=
operator|new
name|AtomicInteger
argument_list|(
name|count
argument_list|)
expr_stmt|;
block|}
comment|/**          * Construct a new Blob Reference to a persistent          * blob.          *          * @param count the reference count          * @param persistentOffset the offset of the blob reference in the persistent file          */
specifier|public
name|BlobReference
parameter_list|(
specifier|final
name|int
name|count
parameter_list|,
specifier|final
name|long
name|persistentOffset
parameter_list|)
block|{
name|this
operator|.
name|count
operator|=
operator|new
name|AtomicInteger
argument_list|(
name|count
argument_list|)
expr_stmt|;
name|this
operator|.
name|persistentOffset
operator|=
name|persistentOffset
expr_stmt|;
block|}
block|}
end_class

begin_comment
comment|/**      * Value class which represents a lease      * of a Blob's file.      */
end_comment

begin_class
specifier|private
specifier|static
class|class
name|BlobFileLease
block|{
specifier|final
name|Path
name|path
decl_stmt|;
specifier|final
name|Runnable
name|release
decl_stmt|;
comment|/**          * @param path the blob file          * @param release the action to run to release the lease          */
specifier|public
name|BlobFileLease
parameter_list|(
specifier|final
name|Path
name|path
parameter_list|,
specifier|final
name|Runnable
name|release
parameter_list|)
block|{
name|this
operator|.
name|path
operator|=
name|path
expr_stmt|;
name|this
operator|.
name|release
operator|=
name|release
expr_stmt|;
block|}
block|}
end_class

begin_comment
comment|/**      * A FilterInputStream which executes an action when      * the underlying stream is closed.      */
end_comment

begin_class
specifier|public
specifier|static
class|class
name|OnCloseInputStream
extends|extends
name|FilterInputStream
block|{
specifier|private
specifier|final
name|Runnable
name|closeAction
decl_stmt|;
comment|/**          * Ensures that the close action is only executed once.          */
specifier|private
specifier|final
name|AtomicBoolean
name|closed
init|=
operator|new
name|AtomicBoolean
argument_list|(
literal|false
argument_list|)
decl_stmt|;
comment|/**          * @param in  An input stream.          * @param closeAction an action to run after the stream is closed.          */
specifier|public
name|OnCloseInputStream
parameter_list|(
specifier|final
name|InputStream
name|in
parameter_list|,
specifier|final
name|Runnable
name|closeAction
parameter_list|)
block|{
name|super
argument_list|(
name|in
argument_list|)
expr_stmt|;
name|this
operator|.
name|closeAction
operator|=
name|closeAction
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|read
parameter_list|(
specifier|final
name|byte
index|[]
name|b
parameter_list|)
throws|throws
name|IOException
block|{
return|return
name|in
operator|.
name|read
argument_list|(
name|b
argument_list|)
return|;
block|}
comment|/**          * First, closes the underlying Input Stream          * by calling {@code super#close()} and then          * always executes the {@link #closeAction}.          *          * This method is idempotent, which is to say that          * the operation will only be          * applied once.          *          * @exception IOException if an I/O error occurs.          */
annotation|@
name|Override
specifier|public
name|void
name|close
parameter_list|()
throws|throws
name|IOException
block|{
if|if
condition|(
name|closed
operator|.
name|compareAndSet
argument_list|(
literal|false
argument_list|,
literal|true
argument_list|)
condition|)
block|{
try|try
block|{
name|super
operator|.
name|close
argument_list|()
expr_stmt|;
block|}
finally|finally
block|{
name|closeAction
operator|.
name|run
argument_list|()
expr_stmt|;
block|}
block|}
block|}
block|}
end_class

begin_comment
comment|/**      * A Journal and Transaction listener which will execute an action only      * after the transaction has been completed (aborted or committed) and      * a checkpoint has been written.      */
end_comment

begin_class
specifier|private
specifier|static
specifier|abstract
class|class
name|CommitThenCheckpointListener
implements|implements
name|TxnListener
implements|,
name|JournalManager
operator|.
name|JournalListener
block|{
comment|// written from single-thread, read from multiple threads
specifier|private
specifier|volatile
name|boolean
name|committedOrAborted
init|=
literal|false
decl_stmt|;
annotation|@
name|Override
specifier|public
name|void
name|commit
parameter_list|()
block|{
name|committedOrAborted
operator|=
literal|true
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|abort
parameter_list|()
block|{
name|committedOrAborted
operator|=
literal|true
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|afterCheckpoint
parameter_list|(
specifier|final
name|long
name|txnId
parameter_list|)
block|{
if|if
condition|(
operator|!
name|committedOrAborted
condition|)
block|{
comment|/*                  * we have not yet/committed or aborted                  * so keep receiving checkpoint events!                  */
return|return
literal|true
return|;
block|}
name|execute
argument_list|()
expr_stmt|;
return|return
literal|false
return|;
block|}
comment|/**          * Called after the transaction has completed          * and a checkpoint has been written.          */
specifier|public
specifier|abstract
name|void
name|execute
parameter_list|()
function_decl|;
block|}
end_class

begin_comment
comment|/**      * Deletes a staged Blob file once the transaction that promoted it has      * completed and a checkpoint has been written.      */
end_comment

begin_class
specifier|private
specifier|static
class|class
name|DeleteStagedBlobFile
extends|extends
name|CommitThenCheckpointListener
block|{
specifier|private
specifier|final
name|BlockingQueue
argument_list|<
name|BlobVacuum
operator|.
name|Request
argument_list|>
name|vacuumQueue
decl_stmt|;
specifier|private
specifier|final
name|BlobVacuum
operator|.
name|RequestDeleteStagedBlobFile
name|requestDeleteStagedBlobFile
decl_stmt|;
comment|/**          * @param vacuumQueue the vacuum queue.          * @param requestDeleteStagedBlobFile the request to delete the staged blob file.          */
specifier|public
name|DeleteStagedBlobFile
parameter_list|(
specifier|final
name|BlockingQueue
argument_list|<
name|BlobVacuum
operator|.
name|Request
argument_list|>
name|vacuumQueue
parameter_list|,
specifier|final
name|BlobVacuum
operator|.
name|RequestDeleteStagedBlobFile
name|requestDeleteStagedBlobFile
parameter_list|)
block|{
name|this
operator|.
name|vacuumQueue
operator|=
name|vacuumQueue
expr_stmt|;
name|this
operator|.
name|requestDeleteStagedBlobFile
operator|=
name|requestDeleteStagedBlobFile
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|execute
parameter_list|()
block|{
name|enqueueVacuum
argument_list|(
name|vacuumQueue
argument_list|,
name|requestDeleteStagedBlobFile
argument_list|)
expr_stmt|;
block|}
block|}
end_class

begin_comment
comment|/**      * Schedules a Blob File for deletion once the transaction that removed it      * has completed and a checkpoint has been written.      */
end_comment

begin_class
specifier|private
specifier|static
class|class
name|ScheduleDeleteBlobFile
extends|extends
name|CommitThenCheckpointListener
block|{
specifier|private
specifier|final
name|BlockingQueue
argument_list|<
name|BlobVacuum
operator|.
name|Request
argument_list|>
name|vacuumQueue
decl_stmt|;
specifier|private
specifier|final
name|BlobVacuum
operator|.
name|RequestDeleteBlobFile
name|requestDeleteBlobFile
decl_stmt|;
comment|/**          * @param vacuumQueue the vacuum queue.          * @param requestDeleteBlobFile the request to delete the blob file.          */
specifier|public
name|ScheduleDeleteBlobFile
parameter_list|(
specifier|final
name|BlockingQueue
argument_list|<
name|BlobVacuum
operator|.
name|Request
argument_list|>
name|vacuumQueue
parameter_list|,
specifier|final
name|BlobVacuum
operator|.
name|RequestDeleteBlobFile
name|requestDeleteBlobFile
parameter_list|)
block|{
name|this
operator|.
name|vacuumQueue
operator|=
name|vacuumQueue
expr_stmt|;
name|this
operator|.
name|requestDeleteBlobFile
operator|=
name|requestDeleteBlobFile
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|execute
parameter_list|()
block|{
name|enqueueVacuum
argument_list|(
name|vacuumQueue
argument_list|,
name|requestDeleteBlobFile
argument_list|)
expr_stmt|;
block|}
block|}
end_class

begin_function
specifier|private
specifier|static
name|void
name|enqueueVacuum
parameter_list|(
specifier|final
name|BlockingQueue
argument_list|<
name|BlobVacuum
operator|.
name|Request
argument_list|>
name|vacuumQueue
parameter_list|,
specifier|final
name|BlobVacuum
operator|.
name|Request
name|request
parameter_list|)
block|{
try|try
block|{
comment|/*              * We offer with timeout because vacuum              * is best effort rather than essential, anything              * we cannot vacuum will be cleaned up at next startup              * either as a part of crash recovery or compaction              */
if|if
condition|(
operator|!
name|vacuumQueue
operator|.
name|offer
argument_list|(
name|request
argument_list|,
name|VACUUM_ENQUEUE_TIMEOUT
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Timeout, could not not enqueue for vacuum: "
operator|+
name|request
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
specifier|final
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Interrupted, could not not enqueue for vacuum: "
operator|+
name|request
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
comment|// restore interrupted status!
return|return;
block|}
block|}
end_function

begin_comment
comment|/**      * The PersistentWriter is designed to be run      * exclusively on its own single thread for a BlobStore      * and is solely responsible for writing updates to the      * persistent blob store file.      */
end_comment

begin_class
specifier|private
specifier|static
class|class
name|PersistentWriter
implements|implements
name|Runnable
block|{
comment|/**          * The Poison Pill can be placed on the {@link #persistQueue},          * when encountered the {@link PersistentWriter} will          * shutdown.          */
specifier|public
specifier|static
specifier|final
name|Tuple3
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|,
name|Integer
argument_list|>
name|POISON_PILL
init|=
name|Tuple
argument_list|(
literal|null
argument_list|,
literal|null
argument_list|,
literal|null
argument_list|)
decl_stmt|;
specifier|private
specifier|final
name|BlockingQueue
argument_list|<
name|Tuple3
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|,
name|Integer
argument_list|>
argument_list|>
name|persistQueue
decl_stmt|;
specifier|private
specifier|final
name|ByteBuffer
name|buffer
decl_stmt|;
specifier|private
specifier|final
name|SeekableByteChannel
name|channel
decl_stmt|;
specifier|private
specifier|final
name|Runnable
name|abnormalShutdownCallback
decl_stmt|;
name|PersistentWriter
parameter_list|(
specifier|final
name|BlockingQueue
argument_list|<
name|Tuple3
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|,
name|Integer
argument_list|>
argument_list|>
name|persistQueue
parameter_list|,
specifier|final
name|ByteBuffer
name|buffer
parameter_list|,
specifier|final
name|SeekableByteChannel
name|channel
parameter_list|,
specifier|final
name|Runnable
name|abnormalShutdownCallback
parameter_list|)
block|{
name|this
operator|.
name|persistQueue
operator|=
name|persistQueue
expr_stmt|;
name|this
operator|.
name|buffer
operator|=
name|buffer
expr_stmt|;
name|this
operator|.
name|channel
operator|=
name|channel
expr_stmt|;
name|this
operator|.
name|abnormalShutdownCallback
operator|=
name|abnormalShutdownCallback
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
while|while
condition|(
literal|true
condition|)
block|{
specifier|final
name|Tuple3
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|,
name|Integer
argument_list|>
name|blobData
init|=
name|persistQueue
operator|.
name|take
argument_list|()
decl_stmt|;
if|if
condition|(
name|blobData
operator|==
name|POISON_PILL
condition|)
block|{
comment|// if we received the Poison Pill, we should shutdown!
break|break;
comment|// exit
block|}
comment|// write an entry
name|writeEntry
argument_list|(
name|blobData
operator|.
name|_1
argument_list|,
name|blobData
operator|.
name|_2
argument_list|,
name|blobData
operator|.
name|_3
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
specifier|final
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// Restore the interrupted status
name|LOG
operator|.
name|error
argument_list|(
literal|"PersistentWriter Shutting down due to interrupt: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
name|abnormalShutdownCallback
operator|.
name|run
argument_list|()
expr_stmt|;
block|}
catch|catch
parameter_list|(
specifier|final
name|IOException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"PersistentWriter Shutting down, received: "
operator|+
name|e
operator|.
name|getMessage
argument_list|()
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|abnormalShutdownCallback
operator|.
name|run
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**          * Stores the reference count for a blob to the persistent blob store file.          *          * When a new reference count is written for the first time it updates          * the {@link BlobStoreImpl.BlobReference#persistentOffset} with the          * location of the reference in the persistent file.          *          * @param blobId the identifier of the blob.          * @param blobReference the reference details for the blob          * @param newCount the new reference count to store.          *          * @throws IOException if an error occurs whilst writing the persistent file.          */
specifier|private
name|void
name|writeEntry
parameter_list|(
specifier|final
name|BlobId
name|blobId
parameter_list|,
specifier|final
name|BlobReference
name|blobReference
parameter_list|,
specifier|final
name|int
name|newCount
parameter_list|)
throws|throws
name|IOException
block|{
comment|// if new record (i.e. not yet persisted), append to the end of the file
if|if
condition|(
name|blobReference
operator|.
name|persistentOffset
operator|==
name|NOT_PERSISTED
condition|)
block|{
name|blobReference
operator|.
name|persistentOffset
operator|=
name|channel
operator|.
name|size
argument_list|()
expr_stmt|;
block|}
name|channel
operator|.
name|position
argument_list|(
name|blobReference
operator|.
name|persistentOffset
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|clear
argument_list|()
expr_stmt|;
name|buffer
operator|.
name|put
argument_list|(
name|blobId
operator|.
name|getId
argument_list|()
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|putInt
argument_list|(
name|newCount
argument_list|)
expr_stmt|;
name|buffer
operator|.
name|flip
argument_list|()
expr_stmt|;
name|channel
operator|.
name|write
argument_list|(
name|buffer
argument_list|)
expr_stmt|;
block|}
block|}
end_class

begin_comment
comment|/**      * The BlobVacuum is designed to be run      * exclusively on its own single thread for a BlobStore      * and is solely responsible for deleting blob files from      * the blob file store.      */
end_comment

begin_class
specifier|private
specifier|static
class|class
name|BlobVacuum
implements|implements
name|Runnable
block|{
specifier|private
specifier|final
name|BlockingQueue
argument_list|<
name|Request
argument_list|>
name|vacuumQueue
decl_stmt|;
specifier|public
name|BlobVacuum
parameter_list|(
specifier|final
name|BlockingQueue
argument_list|<
name|Request
argument_list|>
name|vacuumQueue
parameter_list|)
block|{
name|this
operator|.
name|vacuumQueue
operator|=
name|vacuumQueue
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|void
name|run
parameter_list|()
block|{
try|try
block|{
while|while
condition|(
literal|true
condition|)
block|{
specifier|final
name|Request
name|request
init|=
name|vacuumQueue
operator|.
name|take
argument_list|()
decl_stmt|;
if|if
condition|(
operator|!
name|request
operator|.
name|service
argument_list|()
condition|)
block|{
comment|// if the request could not be serviced then enque it so we can try again in future
try|try
block|{
if|if
condition|(
operator|!
name|vacuumQueue
operator|.
name|offer
argument_list|(
name|request
argument_list|,
name|VACUUM_ENQUEUE_TIMEOUT
argument_list|,
name|TimeUnit
operator|.
name|MILLISECONDS
argument_list|)
condition|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Timeout, could not not enqueue for vacuum: "
operator|+
name|request
argument_list|)
expr_stmt|;
block|}
block|}
catch|catch
parameter_list|(
specifier|final
name|InterruptedException
name|e
parameter_list|)
block|{
name|LOG
operator|.
name|error
argument_list|(
literal|"Interrupted, could not not enqueue for vacuum: "
operator|+
name|request
argument_list|,
name|e
argument_list|)
expr_stmt|;
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
comment|// restore interrupted status!
throw|throw
name|e
throw|;
block|}
block|}
block|}
block|}
catch|catch
parameter_list|(
specifier|final
name|InterruptedException
name|e
parameter_list|)
block|{
comment|// expected when we are shutting down, only thrown by vacuumQueue.take/offer.
comment|// Any remaining objects in the queue which we have not yet vacuumed will
comment|// be taken care of by {@link #compactPersistentReferences(ByteBuffer, Path)
comment|// when the persistent blob store file is next opened
comment|// Restore the interrupted status
name|Thread
operator|.
name|currentThread
argument_list|()
operator|.
name|interrupt
argument_list|()
expr_stmt|;
block|}
block|}
comment|/**          * The type of Vacuum Request          */
interface|interface
name|Request
extends|extends
name|Comparable
argument_list|<
name|Request
argument_list|>
block|{
comment|/**              * @return true if the request was serviced,              *     false if the request should be re-scheduled.              */
name|boolean
name|service
parameter_list|()
function_decl|;
block|}
comment|/**          * Vacuum request for deleting a Blob File for a Blob that has been removed.          *          * The Blob File will only be deleted if it has no references and no active readers.          *          * As vacuuming happens asynchronously, a new Blob may have been added which          * has the same de-duplicated Blob File, causing an increase in references,          * in which case the Blob File will be recycled instead          * and will not be deleted here.          */
specifier|public
specifier|static
specifier|final
class|class
name|RequestDeleteBlobFile
implements|implements
name|Request
block|{
specifier|private
specifier|final
name|ConcurrentMap
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|>
name|references
decl_stmt|;
specifier|private
specifier|final
name|Path
name|blobDir
decl_stmt|;
specifier|private
specifier|final
name|BlobId
name|blobId
decl_stmt|;
specifier|private
specifier|final
name|BlobReference
name|blobReference
decl_stmt|;
specifier|public
name|RequestDeleteBlobFile
parameter_list|(
specifier|final
name|ConcurrentMap
argument_list|<
name|BlobId
argument_list|,
name|BlobReference
argument_list|>
name|references
parameter_list|,
specifier|final
name|Path
name|blobDir
parameter_list|,
specifier|final
name|BlobId
name|blobId
parameter_list|,
specifier|final
name|BlobReference
name|blobReference
parameter_list|)
block|{
name|this
operator|.
name|references
operator|=
name|references
expr_stmt|;
name|this
operator|.
name|blobDir
operator|=
name|blobDir
expr_stmt|;
name|this
operator|.
name|blobId
operator|=
name|blobId
expr_stmt|;
name|this
operator|.
name|blobReference
operator|=
name|blobReference
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"RequestDeleteBlobFile("
operator|+
name|blobId
operator|+
literal|")"
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|compareTo
parameter_list|(
specifier|final
name|Request
name|other
parameter_list|)
block|{
if|if
condition|(
name|other
operator|instanceof
name|RequestDeleteBlobFile
condition|)
block|{
return|return
operator|(
operator|(
name|RequestDeleteBlobFile
operator|)
name|other
operator|)
operator|.
name|blobReference
operator|.
name|readers
operator|.
name|get
argument_list|()
operator|-
name|blobReference
operator|.
name|readers
operator|.
name|get
argument_list|()
return|;
block|}
else|else
block|{
comment|// This class has higher priority than other classes
return|return
literal|1
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|service
parameter_list|()
block|{
comment|// we can only delete the blob file itelf if there are no references
if|if
condition|(
name|blobReference
operator|.
name|count
operator|.
name|compareAndSet
argument_list|(
literal|0
argument_list|,
name|DELETING
argument_list|)
condition|)
block|{
comment|// make sure there are no readers still actively reading the blob file
if|if
condition|(
name|blobReference
operator|.
name|readers
operator|.
name|get
argument_list|()
operator|==
literal|0
condition|)
block|{
comment|// no more readers can be taken whilst count == DELETING, so we can delete
try|try
block|{
name|deleteBlob
argument_list|(
name|blobDir
argument_list|,
name|blobId
argument_list|,
literal|true
argument_list|)
expr_stmt|;
block|}
catch|catch
parameter_list|(
specifier|final
name|IOException
name|ioe
parameter_list|)
block|{
comment|// non-critical error
name|LOG
operator|.
name|error
argument_list|(
literal|"Unable to delete blob file: "
operator|+
name|bytesToHex
argument_list|(
name|blobId
operator|.
name|getId
argument_list|()
argument_list|)
argument_list|,
name|ioe
argument_list|)
expr_stmt|;
block|}
comment|// remove from shared map
name|references
operator|.
name|remove
argument_list|(
name|blobId
argument_list|)
expr_stmt|;
block|}
else|else
block|{
comment|// reschedule the blob vacuum for later (when hopefully there are no active readers)
return|return
literal|false
return|;
block|}
comment|// NOTE: DELETING is the last state of a BlobReference#count -- there is no coming back from this!
block|}
else|else
block|{
comment|/*                      * no-op: ignore this blob as it now again has active references,                      * so we don't need to delete it, instead it has been recycled :-)                      * Therefore we can just continue...                      */
block|}
comment|// we serviced this request!
return|return
literal|true
return|;
block|}
block|}
specifier|public
specifier|static
specifier|final
class|class
name|RequestDeleteStagedBlobFile
implements|implements
name|Request
block|{
specifier|private
specifier|final
name|Path
name|stagingDir
decl_stmt|;
specifier|private
specifier|final
name|String
name|stagedBlobUuid
decl_stmt|;
specifier|public
name|RequestDeleteStagedBlobFile
parameter_list|(
specifier|final
name|Path
name|stagingDir
parameter_list|,
specifier|final
name|String
name|stagedBlobUuid
parameter_list|)
block|{
name|this
operator|.
name|stagingDir
operator|=
name|stagingDir
expr_stmt|;
name|this
operator|.
name|stagedBlobUuid
operator|=
name|stagedBlobUuid
expr_stmt|;
block|}
annotation|@
name|Override
specifier|public
name|String
name|toString
parameter_list|()
block|{
return|return
literal|"RequestDeleteStagedBlobFile("
operator|+
name|stagedBlobUuid
operator|+
literal|")"
return|;
block|}
annotation|@
name|Override
specifier|public
name|int
name|compareTo
parameter_list|(
specifier|final
name|Request
name|other
parameter_list|)
block|{
if|if
condition|(
name|other
operator|instanceof
name|RequestDeleteStagedBlobFile
condition|)
block|{
return|return
name|stagedBlobUuid
operator|.
name|compareTo
argument_list|(
operator|(
operator|(
name|RequestDeleteStagedBlobFile
operator|)
name|other
operator|)
operator|.
name|stagedBlobUuid
argument_list|)
return|;
block|}
else|else
block|{
comment|// This class has lower priority than other classes
return|return
operator|-
literal|1
return|;
block|}
block|}
annotation|@
name|Override
specifier|public
name|boolean
name|service
parameter_list|()
block|{
specifier|final
name|Path
name|stagedBlobFile
init|=
name|stagingDir
operator|.
name|resolve
argument_list|(
name|stagedBlobUuid
argument_list|)
decl_stmt|;
name|FileUtils
operator|.
name|deleteQuietly
argument_list|(
name|stagedBlobFile
argument_list|)
expr_stmt|;
return|return
literal|true
return|;
block|}
block|}
block|}
end_class

unit|}
end_unit

