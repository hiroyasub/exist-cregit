<?xml version="1.0" encoding="UTF-8"?>
<!--<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.1.2//EN" "docbookx.dtd">-->
<book xmlns:ci="http://apache.org/cocoon/include/1.0">
    <bookinfo>
        <graphic fileref="logo.jpg"/>
		<title>Open Source XML Database</title>
        <author>
            <firstname>Wolfgang M.</firstname>
            <surname>Meier</surname>
            <affiliation>
                <address format="linespecific">
					<email>wolfgang@exist-db.org</email>
                </address>
            </affiliation>
        </author>
    </bookinfo>
    <ci:include src="sidebar.xml"/>
    <chapter>
        <title>Performance HowTo</title>
        <section>
            <title>Indexing</title>
            <section>
                <title>Use a Local Connection to the Database for Large Files</title>
                <para>The XML:DB driver uses XMLRPC calls to communicate with a
                    remote database server. When storing files, the file content
                    has first to be send over the network. To avoid memory problems, the XMLRPC interface supports
                    file uploads in chunks. This way, not the whole file has to fit into
                    main memory. Instead, the file is first uploaded chunk by chunk and stored
                    into a temporary file on the server, which is then stored into the database. 
                    However, sending the content of larger files over XMLRPC can cost a lot 
                    of time.</para>
                    
                <para>It is thus usually better to use a client with direct connection to
                    the database to load a large amount of data. The client will open 
                    the database in embedded mode, so no network connection is established. 
                    To launch the client in local mode, enter:</para>
                    
                <synopsis>bin/client.sh -l</synopsis>
                
                <para>Please note that you should stop any running server before starting
                    the client in local mode.</para>
                    
                <para>The embedded XML:DB driver uses SAX to parse the XML files. Since the
                    file content is not loaded into memory, there should be no limit to the 
                    size of a file.</para>
                    
                <para>Developers using the XML:DB API should prefer the setContent()
                    method of class XMLResource and pass a Java File object. The file object
                    is directly forwarded to the indexer.</para>
            </section>
            <section>
                <title>Collection Size</title>
                
                <para>For previous versions of eXist, we recommended to split
                large collections into several sub-collections. This does no
                longer apply to recent releases. eXist can now well handle
                collections with a few thousand files in it.</para>
                
                <para>You should still think about splitting a collection if it
                contains more than, let's say, 10,000 files. However, too many
                collections make the database slow. So please don't create
                thousands of sub-collections. Reading collection metadata is 
                expensive and has a bad impact on query performance.</para>
            </section>
            
            <section>
                <title>Restrict Fulltext-Indexing</title>
                <para>Another alternative is to exclude some parts of your
                    documents from fulltext-indexing. By default, eXist tries to
                    index every character sequence it finds. But usually, fulltext-queries
                    make more sense for some parts of a document than for
                    others. For example, URLs, serial numbers and the like
                    consume a lot of space in the index, but will rarely be
                    searched this way. </para>
                <para>The <ulink href="configuration.xml">configuration
                    document</ulink> contains some information about how to
                    exclude or include document parts into the fulltext index.
                    Please note that, even if you exclude some elements from
                    fulltext-indexing, you will still be able to apply all
                    standard XPath operators and functions to them. They will
                    just perform slower.</para>
            </section>
            <section>
                <title>Page Buffer Sizes and Memory Usage</title>
                <para> Native backend page buffer sizes may sometimes get too
                    small, which may cause a lot of page-in/page-out operations.</para>
                
                <para>The database writes some information about page buffer usage
                    to the log files whenever it is stopped or flushes pages to disk. 
                    There should be several lines in the log looking like this:</para>
                
                <synopsis>2003-01-13 21:22:38,096 [Thread-1] INFO  (BTree.java [printStatistics]:1188) - elements.dbx INDEX 1024 / 1 / 3/ 1</synopsis>
                <synopsis>2003-01-13 21:22:38,097 [Thread-1] INFO  (BFile.java [printStatistics]:421) - elements.dbx DATA 256 / 256 / 984 / 2</synopsis>
                
                <para>The log shows two entries for each index file: INDEX and DATA.
                    These correspond to the two page buffers used by each index file.
                    The INDEX buffer contains B+-tree pages, the DATA buffer caches 
                    data pages. The log also displays four values: The first specifies
                    the maximum size of the buffer, the second shows the number of pages
                    currently buffered. The last two values are the most important:
                    They tell us the number of page hits and number of page misses. The number
                    of page fails should always be rather low - much lower or equal to the 
                    number of hits. Otherwise a lot of disk io is generated.</para>

                <para>If you use Cocoon, you can also get buffer usage information from eXist's
                status generator. By default, you can find the status page at
                <ulink       url="http://localhost:8080/exist/status">http://localhost:8080/exist/status</ulink>.
                Choose "buffers" from the drop down list at top left.</para>

                <para>If you observe a large number of fails for an index file,
                    you should increase the amount of memory available for page
                    buffers. Beginning with version 1.0, the configuration file
                    has a global setting (attribute <option>cacheSize</option>
                    in element <option>db-connection</option>) for all page
                    buffers. Increase this to give more memory to each of the
                    buffers.</para>

                <para>If you run into OutOfMemoryExceptions after changing the
                    buffer size settings, you might have to increase the 
                    <option>-Xmx</option> setting for the Java virtual machine
                    which is specified in the shell scripts (see below). Additionally, increasing
                    the <option>free_mem_min</option> option in 
                    <sgmltag>db-connection</sgmltag> may help as well. This option 
                    specifies the amount of free memory (in
                    percent) which should be available to the Java virtual
                    machine before eXist starts to flush its internal caches.
                    During indexing, eXist caches index data in memory to avoid
                    frequent disk lookups. If the amount of free memory drops
                    below the defined limit, eXist will write all cached data to
                    disk and trigger the garbage collection.</para>
            </section>
			<section>
				<title>JVM Options</title>
				<para>If you run into OutOfMemory exceptions during indexing,
					you may consider changing the <option>-Xms</option> and 
					<option>-Xmx</option> settings for the Java virtual machine.
					These options define the minimum and maximum amount of
					memory that will be available to the JVM. If you have enough
					main memory, remove the -Xmx option.</para>
				<para>The -Xmx and -Xms options are set in the start scripts
					<command>bin/client.sh</command> and 
					<command>bin/startup.sh</command> or their corresponding 
					Windows counterparts.</para>
			</section>
        </section>
        <section>
			<title>Query Performance</title>
			<section>
				<title>General Remarks</title>
                <para>Some query engines have problems to evaluate ancestor/descendant 
                    relationships, so many people tend to replace <command>//</command> 
                    expressions by a chain of simple parent-child steps. Contrary to that,
                    eXist's indexing scheme allows to resolve ancestor/descendant relationships 
                    very efficiently. An expression like</para>
                <synopsis>/PLAY//SPEECH</synopsis>
                <para>will evaluate as fast or even faster than the equivalent expression:</para>
				<synopsis>/PLAY/ACT/SCENE/SPEECH</synopsis>
            </section>
            <section>
                <title>Use Fulltext-Extensions</title>
                <para>eXist offers a number of extensions to query the text 
                    content of a node (see the 
                    <ulink href="xpath.xml">XPath HowTo</ulink>). Most of those
                    extensions are index-based, while the standard XPath functions
                    like <command>contains()</command> or operators like <command>=</command>
                    are not.</para>
                    
                <note>
                    <para>There's one exception to this: equality comparisons may access the fulltext-
                    index in the background to restrict the number of candidate nodes.</para>
                </note>
                
                <para>However, in many cases, replacing exact match XPath functions with the
                    corresponding, index-based fulltext-search extensions will be easily
                    possible. For example, if we search for the author of an article, we could
                    do:</para>
                    
                <synopsis>//article[author='Marx, Karl']</synopsis>
                
                <para>Query performance will be quite slow. The <command>=</command> operator
                is not index-based. This means that the text value of each <sgmltag>author</sgmltag>
                tag has to be compared to the string literal. The XPath engine thus has to actually 
                load the <sgmltag>author</sgmltag> elements and their child nodes.</para>
                <para>Using eXist's extensions, we can reformulate the query as follows:</para>
                <synopsis>//article[near(author, 'Marx, Karl')]</synopsis>
                <para>This query will probably be much faster. The <command>near()</command> 
                function uses the fulltext index to select matching nodes. Thus not a single
                node has to be loaded. The whole query is processed just using index information.
                </para>
                <para>Using fulltext-extensions is also possible for attribute nodes. If you
                    have unique attribute values, you should consider to replace equality comparisons
                    by a fulltext query. For example, we may want to search for <sgmltag>div</sgmltag>
                    elements having a <option>type</option> attribute with value "introduction". We
                    thus replace the standard XPath expression:</para>
                <synopsis>//div[@type= 'introduction']</synopsis>
                <para>with:</para>
                <synopsis>//div[@type &amp;= 'introduction']</synopsis>
                <para>Which will produce the same results for our type of document, but performs
                    a magnitude faster.</para>
            </section>

            <section>
                <title>For-Expressions and Where Clauses</title>
                
                <para>Avoid nested for-expressions to iterate through large
                    sequences: eXist tries to evaluate expressions in one,
                    single step whenever possible. For example, the query</para>

                <synopsis>/PLAY//SPEECH[LINE &amp;= 'love']</synopsis>
                
                <para>is processed in a single step. Basically, the query engine
                    just retrieves the node sequences for all PLAY and SPEECH
                    elements from the index and applies an ancestor-descendant
                    join. Next, it loads all LINE elements, passes them to the
                    fulltext engine to get a filtered set, and does a
                    parent-child join using the SPEECH elements. All those
                    operations are just called once for the whole input
                    sequence.</para>

                <para>However, a nested for-expression forces the query
                    engine to split the processed sequences. For example,
                    consider the following query on the Shakespeare
                    plays:</para>

                <example>
                    <title>Nested For</title>
                    <programlisting><![CDATA[
for $play in /PLAY,
    $speech in $play//SPEECH[LINE &= 'love']
return
    <play title="{$play/TITLE}">
        {$speech}
    </play>
]]></programlisting>
                </example>

                <para>Internally, the query is translated as follows:</para>
                
                <example>
                    <title>Internal Representation of the Query</title>
                    <programlisting><![CDATA[
for $play in //PLAY
return
    for $speech in $play//SPEECH[LINE &= 'love']
    return
        <play title="{$play/TITLE}">
            {$speech}
        </play>
]]></programlisting>
                </example>
                
                <para>If you look at the internal representation, it becomes
                    clear that the subexpression $play//SPEECH[LINE &amp;=
                    'love'] is evaluated once for each invocation of the outer
                    return clause, i.e. 27 times
                    for the Shakespeare plays. This is not a problem for such
                    a small collection, but it makes a difference if you had,
                    let's say, 10000 plays instead of 27.</para>

                <para>Conclusion: while nested for-expressions are a powerful
                    feature in XQuery, you have to keep in mind that they might
                    be a performance killer if applied to a large
                    sequence of items.</para>

            </section>

            <section>
                <title>Increase index-depth</title>
                <para>If you are connected to a remote server via XMLRPC and retrieving results
                    takes too much time, consider increasing the <option>index-depth</option>
                    in the <sgmltag>indexer</sgmltag> section of the server configuration file. The
                    meaning of this setting is explained in the <ulink href="configuration.xml">
                    configuration guide</ulink>.</para>
                <para>By default, the parameter is set to 1. If your documents are highly
                    structured, setting this to 4 or 5 may yield result in better download times
                    for query results. Note that the setting will only apply to newly indexed files, not to your 
                    old ones.</para>
			</section>
        </section>
    </chapter>
</book>
